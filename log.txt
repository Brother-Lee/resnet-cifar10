I0607 08:18:59.886816  2187 solver.cpp:337] Iteration 0, Testing net (#0)
I0607 08:18:59.889542  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:19:01.477543  2187 solver.cpp:404]     Test net output #0: accuracy = 0.1
I0607 08:19:01.649302  2187 solver.cpp:228] Iteration 0, loss = 2.32299
I0607 08:19:01.649411  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 2.32299 (* 1 = 2.32299 loss)
I0607 08:19:01.649446  2187 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0607 08:19:23.692184  2187 solver.cpp:228] Iteration 100, loss = 1.75059
I0607 08:19:23.692289  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 1.75059 (* 1 = 1.75059 loss)
I0607 08:19:23.692306  2187 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0607 08:19:45.767680  2187 solver.cpp:228] Iteration 200, loss = 1.50658
I0607 08:19:45.767860  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 1.50658 (* 1 = 1.50658 loss)
I0607 08:19:45.767876  2187 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0607 08:20:07.971942  2187 solver.cpp:228] Iteration 300, loss = 1.39199
I0607 08:20:07.972033  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 1.39199 (* 1 = 1.39199 loss)
I0607 08:20:07.972048  2187 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0607 08:20:30.224156  2187 solver.cpp:228] Iteration 400, loss = 1.2422
I0607 08:20:30.224442  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 1.2422 (* 1 = 1.2422 loss)
I0607 08:20:30.224485  2187 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0607 08:20:52.514693  2187 solver.cpp:228] Iteration 500, loss = 1.05573
I0607 08:20:52.514802  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 1.05573 (* 1 = 1.05573 loss)
I0607 08:20:52.514818  2187 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0607 08:21:14.833045  2187 solver.cpp:228] Iteration 600, loss = 0.930261
I0607 08:21:14.833319  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.930261 (* 1 = 0.930261 loss)
I0607 08:21:14.833360  2187 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0607 08:21:37.629166  2187 solver.cpp:228] Iteration 700, loss = 0.980841
I0607 08:21:37.629329  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.980841 (* 1 = 0.980841 loss)
I0607 08:21:37.629356  2187 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0607 08:22:00.421537  2187 solver.cpp:228] Iteration 800, loss = 0.920001
I0607 08:22:00.421862  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.920001 (* 1 = 0.920001 loss)
I0607 08:22:00.421900  2187 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0607 08:22:22.598261  2187 solver.cpp:228] Iteration 900, loss = 1.00567
I0607 08:22:22.598371  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 1.00567 (* 1 = 1.00567 loss)
I0607 08:22:22.598387  2187 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0607 08:22:44.984375  2187 solver.cpp:337] Iteration 1000, Testing net (#0)
I0607 08:22:44.984786  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:22:46.566409  2187 solver.cpp:404]     Test net output #0: accuracy = 0.6657
I0607 08:22:46.743588  2187 solver.cpp:228] Iteration 1000, loss = 0.879825
I0607 08:22:46.743674  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.879825 (* 1 = 0.879825 loss)
I0607 08:22:46.743691  2187 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0607 08:23:09.352318  2187 solver.cpp:228] Iteration 1100, loss = 0.719849
I0607 08:23:09.352437  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.719849 (* 1 = 0.719849 loss)
I0607 08:23:09.352452  2187 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0607 08:23:31.983302  2187 solver.cpp:228] Iteration 1200, loss = 0.68593
I0607 08:23:31.983515  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.68593 (* 1 = 0.68593 loss)
I0607 08:23:31.983533  2187 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0607 08:23:54.308151  2187 solver.cpp:228] Iteration 1300, loss = 0.907923
I0607 08:23:54.308248  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.907923 (* 1 = 0.907923 loss)
I0607 08:23:54.308269  2187 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0607 08:24:16.739894  2187 solver.cpp:228] Iteration 1400, loss = 0.602145
I0607 08:24:16.740262  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.602145 (* 1 = 0.602145 loss)
I0607 08:24:16.740339  2187 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0607 08:24:39.216840  2187 solver.cpp:228] Iteration 1500, loss = 0.605499
I0607 08:24:39.216949  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.605499 (* 1 = 0.605499 loss)
I0607 08:24:39.216965  2187 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0607 08:25:02.089212  2187 solver.cpp:228] Iteration 1600, loss = 0.505945
I0607 08:25:02.089469  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.505945 (* 1 = 0.505945 loss)
I0607 08:25:02.089488  2187 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0607 08:25:25.038473  2187 solver.cpp:228] Iteration 1700, loss = 0.524013
I0607 08:25:25.038589  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.524013 (* 1 = 0.524013 loss)
I0607 08:25:25.038604  2187 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0607 08:25:47.700901  2187 solver.cpp:228] Iteration 1800, loss = 0.545133
I0607 08:25:47.701218  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.545133 (* 1 = 0.545133 loss)
I0607 08:25:47.701263  2187 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0607 08:26:10.130501  2187 solver.cpp:228] Iteration 1900, loss = 0.707867
I0607 08:26:10.130646  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.707867 (* 1 = 0.707867 loss)
I0607 08:26:10.130671  2187 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0607 08:26:32.664100  2187 solver.cpp:337] Iteration 2000, Testing net (#0)
I0607 08:26:32.664763  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:26:34.277935  2187 solver.cpp:404]     Test net output #0: accuracy = 0.6543
I0607 08:26:34.455099  2187 solver.cpp:228] Iteration 2000, loss = 0.581799
I0607 08:26:34.455201  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.581799 (* 1 = 0.581799 loss)
I0607 08:26:34.455219  2187 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0607 08:26:57.127733  2187 solver.cpp:228] Iteration 2100, loss = 0.402165
I0607 08:26:57.127851  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.402165 (* 1 = 0.402165 loss)
I0607 08:26:57.127867  2187 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0607 08:27:19.739529  2187 solver.cpp:228] Iteration 2200, loss = 0.486478
I0607 08:27:19.739817  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.486478 (* 1 = 0.486478 loss)
I0607 08:27:19.739858  2187 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0607 08:27:42.572232  2187 solver.cpp:228] Iteration 2300, loss = 0.641271
I0607 08:27:42.572365  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.641271 (* 1 = 0.641271 loss)
I0607 08:27:42.572388  2187 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0607 08:28:05.154530  2187 solver.cpp:228] Iteration 2400, loss = 0.459824
I0607 08:28:05.154805  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.459824 (* 1 = 0.459824 loss)
I0607 08:28:05.154836  2187 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0607 08:28:27.648422  2187 solver.cpp:228] Iteration 2500, loss = 0.447066
I0607 08:28:27.648533  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.447066 (* 1 = 0.447066 loss)
I0607 08:28:27.648551  2187 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0607 08:28:50.115083  2187 solver.cpp:228] Iteration 2600, loss = 0.430717
I0607 08:28:50.115363  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.430717 (* 1 = 0.430717 loss)
I0607 08:28:50.115391  2187 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0607 08:29:12.929572  2187 solver.cpp:228] Iteration 2700, loss = 0.654152
I0607 08:29:12.929692  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.654152 (* 1 = 0.654152 loss)
I0607 08:29:12.929709  2187 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0607 08:29:35.596386  2187 solver.cpp:228] Iteration 2800, loss = 0.344149
I0607 08:29:35.596684  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.344149 (* 1 = 0.344149 loss)
I0607 08:29:35.596714  2187 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0607 08:29:58.378152  2187 solver.cpp:228] Iteration 2900, loss = 0.273601
I0607 08:29:58.378252  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.273601 (* 1 = 0.273601 loss)
I0607 08:29:58.378268  2187 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0607 08:30:20.800366  2187 solver.cpp:337] Iteration 3000, Testing net (#0)
I0607 08:30:20.800781  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:30:22.403756  2187 solver.cpp:404]     Test net output #0: accuracy = 0.6391
I0607 08:30:22.578248  2187 solver.cpp:228] Iteration 3000, loss = 0.44838
I0607 08:30:22.578335  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.44838 (* 1 = 0.44838 loss)
I0607 08:30:22.578351  2187 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0607 08:30:45.490957  2187 solver.cpp:228] Iteration 3100, loss = 0.433487
I0607 08:30:45.491081  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.433487 (* 1 = 0.433487 loss)
I0607 08:30:45.491097  2187 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0607 08:31:08.085734  2187 solver.cpp:228] Iteration 3200, loss = 0.432289
I0607 08:31:08.086048  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.432289 (* 1 = 0.432289 loss)
I0607 08:31:08.086091  2187 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0607 08:31:30.908778  2187 solver.cpp:228] Iteration 3300, loss = 0.506675
I0607 08:31:30.908886  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.506675 (* 1 = 0.506675 loss)
I0607 08:31:30.908902  2187 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0607 08:31:53.456274  2187 solver.cpp:228] Iteration 3400, loss = 0.422108
I0607 08:31:53.456521  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.422108 (* 1 = 0.422108 loss)
I0607 08:31:53.456547  2187 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0607 08:32:16.442653  2187 solver.cpp:228] Iteration 3500, loss = 0.425903
I0607 08:32:16.442759  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.425903 (* 1 = 0.425903 loss)
I0607 08:32:16.442775  2187 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0607 08:32:39.956161  2187 solver.cpp:228] Iteration 3600, loss = 0.387706
I0607 08:32:39.956707  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.387706 (* 1 = 0.387706 loss)
I0607 08:32:39.956724  2187 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0607 08:33:02.512418  2187 solver.cpp:228] Iteration 3700, loss = 0.449634
I0607 08:33:02.512526  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.449634 (* 1 = 0.449634 loss)
I0607 08:33:02.512542  2187 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0607 08:33:24.950114  2187 solver.cpp:228] Iteration 3800, loss = 0.526284
I0607 08:33:24.950430  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.526284 (* 1 = 0.526284 loss)
I0607 08:33:24.950476  2187 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0607 08:33:47.518606  2187 solver.cpp:228] Iteration 3900, loss = 0.563579
I0607 08:33:47.518718  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.563579 (* 1 = 0.563579 loss)
I0607 08:33:47.518734  2187 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0607 08:34:10.064182  2187 solver.cpp:337] Iteration 4000, Testing net (#0)
I0607 08:34:10.064607  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:34:11.655093  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7918
I0607 08:34:11.840765  2187 solver.cpp:228] Iteration 4000, loss = 0.514896
I0607 08:34:11.840867  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.514896 (* 1 = 0.514896 loss)
I0607 08:34:11.840888  2187 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0607 08:34:34.399857  2187 solver.cpp:228] Iteration 4100, loss = 0.422286
I0607 08:34:34.399952  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.422286 (* 1 = 0.422286 loss)
I0607 08:34:34.399967  2187 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0607 08:34:56.921589  2187 solver.cpp:228] Iteration 4200, loss = 0.411016
I0607 08:34:56.921972  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.411016 (* 1 = 0.411016 loss)
I0607 08:34:56.922042  2187 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0607 08:35:19.470525  2187 solver.cpp:228] Iteration 4300, loss = 0.442909
I0607 08:35:19.470643  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.442909 (* 1 = 0.442909 loss)
I0607 08:35:19.470660  2187 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0607 08:35:42.269207  2187 solver.cpp:228] Iteration 4400, loss = 0.43736
I0607 08:35:42.269456  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.43736 (* 1 = 0.43736 loss)
I0607 08:35:42.269474  2187 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0607 08:36:04.727596  2187 solver.cpp:228] Iteration 4500, loss = 0.35346
I0607 08:36:04.727696  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.35346 (* 1 = 0.35346 loss)
I0607 08:36:04.727715  2187 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0607 08:36:27.197262  2187 solver.cpp:228] Iteration 4600, loss = 0.288517
I0607 08:36:27.197474  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.288517 (* 1 = 0.288517 loss)
I0607 08:36:27.197491  2187 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0607 08:36:49.718493  2187 solver.cpp:228] Iteration 4700, loss = 0.516526
I0607 08:36:49.718611  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.516526 (* 1 = 0.516526 loss)
I0607 08:36:49.718643  2187 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0607 08:37:12.348258  2187 solver.cpp:228] Iteration 4800, loss = 0.403937
I0607 08:37:12.348579  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.403937 (* 1 = 0.403937 loss)
I0607 08:37:12.348620  2187 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0607 08:37:34.650758  2187 solver.cpp:228] Iteration 4900, loss = 0.46713
I0607 08:37:34.650862  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.46713 (* 1 = 0.46713 loss)
I0607 08:37:34.650878  2187 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0607 08:37:56.885687  2187 solver.cpp:337] Iteration 5000, Testing net (#0)
I0607 08:37:56.886062  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:37:58.488494  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7099
I0607 08:37:58.658829  2187 solver.cpp:228] Iteration 5000, loss = 0.407944
I0607 08:37:58.658923  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.407944 (* 1 = 0.407944 loss)
I0607 08:37:58.658941  2187 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0607 08:38:21.112022  2187 solver.cpp:228] Iteration 5100, loss = 0.356215
I0607 08:38:21.112130  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.356215 (* 1 = 0.356215 loss)
I0607 08:38:21.112146  2187 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0607 08:38:43.741241  2187 solver.cpp:228] Iteration 5200, loss = 0.399854
I0607 08:38:43.741533  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.399854 (* 1 = 0.399854 loss)
I0607 08:38:43.741565  2187 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0607 08:39:06.175281  2187 solver.cpp:228] Iteration 5300, loss = 0.339469
I0607 08:39:06.175387  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.339469 (* 1 = 0.339469 loss)
I0607 08:39:06.175403  2187 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0607 08:39:28.491652  2187 solver.cpp:228] Iteration 5400, loss = 0.292884
I0607 08:39:28.491886  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.292884 (* 1 = 0.292884 loss)
I0607 08:39:28.491905  2187 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0607 08:39:50.941068  2187 solver.cpp:228] Iteration 5500, loss = 0.368793
I0607 08:39:50.941184  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.368793 (* 1 = 0.368793 loss)
I0607 08:39:50.941200  2187 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0607 08:40:13.583179  2187 solver.cpp:228] Iteration 5600, loss = 0.398895
I0607 08:40:13.583478  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.398895 (* 1 = 0.398895 loss)
I0607 08:40:13.583528  2187 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0607 08:40:36.223237  2187 solver.cpp:228] Iteration 5700, loss = 0.38249
I0607 08:40:36.223336  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.38249 (* 1 = 0.38249 loss)
I0607 08:40:36.223352  2187 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0607 08:40:58.757673  2187 solver.cpp:228] Iteration 5800, loss = 0.240245
I0607 08:40:58.758036  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.240245 (* 1 = 0.240245 loss)
I0607 08:40:58.758074  2187 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0607 08:41:21.303900  2187 solver.cpp:228] Iteration 5900, loss = 0.412361
I0607 08:41:21.304004  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.412361 (* 1 = 0.412361 loss)
I0607 08:41:21.304020  2187 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0607 08:41:44.550366  2187 solver.cpp:337] Iteration 6000, Testing net (#0)
I0607 08:41:44.551785  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:41:46.152215  2187 solver.cpp:404]     Test net output #0: accuracy = 0.6951
I0607 08:41:46.320061  2187 solver.cpp:228] Iteration 6000, loss = 0.249114
I0607 08:41:46.320214  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.249114 (* 1 = 0.249114 loss)
I0607 08:41:46.320247  2187 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0607 08:42:08.994309  2187 solver.cpp:228] Iteration 6100, loss = 0.441934
I0607 08:42:08.994417  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.441934 (* 1 = 0.441934 loss)
I0607 08:42:08.994433  2187 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0607 08:42:31.417785  2187 solver.cpp:228] Iteration 6200, loss = 0.249239
I0607 08:42:31.418083  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.249239 (* 1 = 0.249239 loss)
I0607 08:42:31.418126  2187 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0607 08:42:53.913161  2187 solver.cpp:228] Iteration 6300, loss = 0.507646
I0607 08:42:53.913277  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.507646 (* 1 = 0.507646 loss)
I0607 08:42:53.913295  2187 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0607 08:43:16.421458  2187 solver.cpp:228] Iteration 6400, loss = 0.286262
I0607 08:43:16.421708  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.286262 (* 1 = 0.286262 loss)
I0607 08:43:16.421747  2187 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0607 08:43:39.301100  2187 solver.cpp:228] Iteration 6500, loss = 0.278192
I0607 08:43:39.301218  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.278192 (* 1 = 0.278192 loss)
I0607 08:43:39.301236  2187 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0607 08:44:01.799651  2187 solver.cpp:228] Iteration 6600, loss = 0.328673
I0607 08:44:01.799926  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.328673 (* 1 = 0.328673 loss)
I0607 08:44:01.799947  2187 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0607 08:44:24.030270  2187 solver.cpp:228] Iteration 6700, loss = 0.45013
I0607 08:44:24.030374  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.45013 (* 1 = 0.45013 loss)
I0607 08:44:24.030390  2187 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0607 08:44:46.402788  2187 solver.cpp:228] Iteration 6800, loss = 0.442196
I0607 08:44:46.403069  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.442196 (* 1 = 0.442196 loss)
I0607 08:44:46.403113  2187 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0607 08:45:09.248718  2187 solver.cpp:228] Iteration 6900, loss = 0.332788
I0607 08:45:09.248836  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.332788 (* 1 = 0.332788 loss)
I0607 08:45:09.248853  2187 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0607 08:45:31.920276  2187 solver.cpp:337] Iteration 7000, Testing net (#0)
I0607 08:45:31.920672  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:45:33.503234  2187 solver.cpp:404]     Test net output #0: accuracy = 0.6887
I0607 08:45:33.680820  2187 solver.cpp:228] Iteration 7000, loss = 0.333258
I0607 08:45:33.680912  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.333258 (* 1 = 0.333258 loss)
I0607 08:45:33.680945  2187 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0607 08:45:56.121081  2187 solver.cpp:228] Iteration 7100, loss = 0.360957
I0607 08:45:56.121171  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.360957 (* 1 = 0.360957 loss)
I0607 08:45:56.121186  2187 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0607 08:46:18.569466  2187 solver.cpp:228] Iteration 7200, loss = 0.214326
I0607 08:46:18.569701  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.214326 (* 1 = 0.214326 loss)
I0607 08:46:18.569720  2187 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0607 08:46:41.421746  2187 solver.cpp:228] Iteration 7300, loss = 0.331456
I0607 08:46:41.421881  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.331456 (* 1 = 0.331456 loss)
I0607 08:46:41.421900  2187 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0607 08:47:04.218685  2187 solver.cpp:228] Iteration 7400, loss = 0.341942
I0607 08:47:04.218997  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.341942 (* 1 = 0.341942 loss)
I0607 08:47:04.219044  2187 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0607 08:47:26.638308  2187 solver.cpp:228] Iteration 7500, loss = 0.385498
I0607 08:47:26.638412  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.385498 (* 1 = 0.385498 loss)
I0607 08:47:26.638429  2187 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0607 08:47:48.953326  2187 solver.cpp:228] Iteration 7600, loss = 0.347592
I0607 08:47:48.953593  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.347592 (* 1 = 0.347592 loss)
I0607 08:47:48.953652  2187 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0607 08:48:11.436175  2187 solver.cpp:228] Iteration 7700, loss = 0.500005
I0607 08:48:11.436286  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.500005 (* 1 = 0.500005 loss)
I0607 08:48:11.436303  2187 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0607 08:48:34.075454  2187 solver.cpp:228] Iteration 7800, loss = 0.359765
I0607 08:48:34.075647  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.359765 (* 1 = 0.359765 loss)
I0607 08:48:34.075666  2187 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0607 08:48:56.521379  2187 solver.cpp:228] Iteration 7900, loss = 0.445286
I0607 08:48:56.521499  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.445286 (* 1 = 0.445286 loss)
I0607 08:48:56.521517  2187 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0607 08:49:17.434002  2187 solver.cpp:337] Iteration 8000, Testing net (#0)
I0607 08:49:17.434599  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:49:19.013979  2187 solver.cpp:404]     Test net output #0: accuracy = 0.5876
I0607 08:49:19.192327  2187 solver.cpp:228] Iteration 8000, loss = 0.326467
I0607 08:49:19.192421  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.326467 (* 1 = 0.326467 loss)
I0607 08:49:19.192438  2187 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0607 08:49:43.247166  2187 solver.cpp:228] Iteration 8100, loss = 0.497326
I0607 08:49:43.247350  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.497326 (* 1 = 0.497326 loss)
I0607 08:49:43.247370  2187 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0607 08:50:09.436810  2187 solver.cpp:228] Iteration 8200, loss = 0.296569
I0607 08:50:09.437021  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.296569 (* 1 = 0.296569 loss)
I0607 08:50:09.437046  2187 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0607 08:50:33.105782  2187 solver.cpp:228] Iteration 8300, loss = 0.366761
I0607 08:50:33.105885  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.366761 (* 1 = 0.366761 loss)
I0607 08:50:33.105901  2187 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0607 08:50:55.494191  2187 solver.cpp:228] Iteration 8400, loss = 0.40883
I0607 08:50:55.494443  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.40883 (* 1 = 0.40883 loss)
I0607 08:50:55.494462  2187 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0607 08:51:17.764178  2187 solver.cpp:228] Iteration 8500, loss = 0.407383
I0607 08:51:17.764279  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.407383 (* 1 = 0.407383 loss)
I0607 08:51:17.764295  2187 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0607 08:51:40.094817  2187 solver.cpp:228] Iteration 8600, loss = 0.386333
I0607 08:51:40.095177  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.386333 (* 1 = 0.386333 loss)
I0607 08:51:40.095209  2187 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0607 08:52:02.664000  2187 solver.cpp:228] Iteration 8700, loss = 0.39407
I0607 08:52:02.664137  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.39407 (* 1 = 0.39407 loss)
I0607 08:52:02.664158  2187 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0607 08:52:25.266464  2187 solver.cpp:228] Iteration 8800, loss = 0.481558
I0607 08:52:25.266723  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.481558 (* 1 = 0.481558 loss)
I0607 08:52:25.266764  2187 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0607 08:52:47.584137  2187 solver.cpp:228] Iteration 8900, loss = 0.269425
I0607 08:52:47.584241  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.269425 (* 1 = 0.269425 loss)
I0607 08:52:47.584259  2187 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0607 08:53:09.574676  2187 solver.cpp:337] Iteration 9000, Testing net (#0)
I0607 08:53:09.575927  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:53:11.151938  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7714
I0607 08:53:11.326527  2187 solver.cpp:228] Iteration 9000, loss = 0.301974
I0607 08:53:11.326616  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.301974 (* 1 = 0.301974 loss)
I0607 08:53:11.326633  2187 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0607 08:53:33.889652  2187 solver.cpp:228] Iteration 9100, loss = 0.308966
I0607 08:53:33.889777  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.308966 (* 1 = 0.308966 loss)
I0607 08:53:33.889796  2187 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0607 08:53:56.463011  2187 solver.cpp:228] Iteration 9200, loss = 0.342618
I0607 08:53:56.463294  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.342618 (* 1 = 0.342618 loss)
I0607 08:53:56.463333  2187 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0607 08:54:18.890013  2187 solver.cpp:228] Iteration 9300, loss = 0.417095
I0607 08:54:18.890132  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.417095 (* 1 = 0.417095 loss)
I0607 08:54:18.890149  2187 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0607 08:54:41.321341  2187 solver.cpp:228] Iteration 9400, loss = 0.306707
I0607 08:54:41.321630  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.306707 (* 1 = 0.306707 loss)
I0607 08:54:41.321677  2187 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0607 08:55:03.854931  2187 solver.cpp:228] Iteration 9500, loss = 0.401853
I0607 08:55:03.855047  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.401853 (* 1 = 0.401853 loss)
I0607 08:55:03.855064  2187 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0607 08:55:26.639957  2187 solver.cpp:228] Iteration 9600, loss = 0.404396
I0607 08:55:26.640239  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.404396 (* 1 = 0.404396 loss)
I0607 08:55:26.640282  2187 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0607 08:55:49.114928  2187 solver.cpp:228] Iteration 9700, loss = 0.381226
I0607 08:55:49.115032  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.381226 (* 1 = 0.381226 loss)
I0607 08:55:49.115049  2187 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0607 08:56:11.604465  2187 solver.cpp:228] Iteration 9800, loss = 0.288005
I0607 08:56:11.604677  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.288005 (* 1 = 0.288005 loss)
I0607 08:56:11.604694  2187 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0607 08:56:34.001763  2187 solver.cpp:228] Iteration 9900, loss = 0.280976
I0607 08:56:34.001884  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.280976 (* 1 = 0.280976 loss)
I0607 08:56:34.001934  2187 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0607 08:56:56.435528  2187 solver.cpp:454] Snapshotting to binary proto file snapshot/_iter_10000.caffemodel
I0607 08:56:56.455605  2187 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot/_iter_10000.solverstate
I0607 08:56:56.459966  2187 solver.cpp:337] Iteration 10000, Testing net (#0)
I0607 08:56:56.460222  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 08:56:58.047883  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7868
I0607 08:56:58.227107  2187 solver.cpp:228] Iteration 10000, loss = 0.327218
I0607 08:56:58.227191  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.327218 (* 1 = 0.327218 loss)
I0607 08:56:58.227213  2187 sgd_solver.cpp:106] Iteration 10000, lr = 0.1
I0607 08:57:20.741637  2187 solver.cpp:228] Iteration 10100, loss = 0.332708
I0607 08:57:20.741750  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.332708 (* 1 = 0.332708 loss)
I0607 08:57:20.741767  2187 sgd_solver.cpp:106] Iteration 10100, lr = 0.1
I0607 08:57:43.141474  2187 solver.cpp:228] Iteration 10200, loss = 0.302084
I0607 08:57:43.141763  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.302084 (* 1 = 0.302084 loss)
I0607 08:57:43.141805  2187 sgd_solver.cpp:106] Iteration 10200, lr = 0.1
I0607 08:58:05.628923  2187 solver.cpp:228] Iteration 10300, loss = 0.403548
I0607 08:58:05.629046  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.403548 (* 1 = 0.403548 loss)
I0607 08:58:05.629065  2187 sgd_solver.cpp:106] Iteration 10300, lr = 0.1
I0607 08:58:28.301017  2187 solver.cpp:228] Iteration 10400, loss = 0.311087
I0607 08:58:28.301278  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.311087 (* 1 = 0.311087 loss)
I0607 08:58:28.301307  2187 sgd_solver.cpp:106] Iteration 10400, lr = 0.1
I0607 08:58:50.776032  2187 solver.cpp:228] Iteration 10500, loss = 0.381337
I0607 08:58:50.776140  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.381337 (* 1 = 0.381337 loss)
I0607 08:58:50.776157  2187 sgd_solver.cpp:106] Iteration 10500, lr = 0.1
I0607 08:59:13.512413  2187 solver.cpp:228] Iteration 10600, loss = 0.275603
I0607 08:59:13.512683  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.275603 (* 1 = 0.275603 loss)
I0607 08:59:13.512722  2187 sgd_solver.cpp:106] Iteration 10600, lr = 0.1
I0607 08:59:36.057601  2187 solver.cpp:228] Iteration 10700, loss = 0.315171
I0607 08:59:36.057708  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.315171 (* 1 = 0.315171 loss)
I0607 08:59:36.057724  2187 sgd_solver.cpp:106] Iteration 10700, lr = 0.1
I0607 08:59:58.778146  2187 solver.cpp:228] Iteration 10800, loss = 0.324341
I0607 08:59:58.778481  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.324341 (* 1 = 0.324341 loss)
I0607 08:59:58.778528  2187 sgd_solver.cpp:106] Iteration 10800, lr = 0.1
I0607 09:00:21.315610  2187 solver.cpp:228] Iteration 10900, loss = 0.433734
I0607 09:00:21.315721  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.433734 (* 1 = 0.433734 loss)
I0607 09:00:21.315738  2187 sgd_solver.cpp:106] Iteration 10900, lr = 0.1
I0607 09:00:43.690661  2187 solver.cpp:337] Iteration 11000, Testing net (#0)
I0607 09:00:43.691357  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:00:45.286799  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7933
I0607 09:00:45.461585  2187 solver.cpp:228] Iteration 11000, loss = 0.30772
I0607 09:00:45.461668  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.30772 (* 1 = 0.30772 loss)
I0607 09:00:45.461691  2187 sgd_solver.cpp:106] Iteration 11000, lr = 0.1
I0607 09:01:07.956256  2187 solver.cpp:228] Iteration 11100, loss = 0.339022
I0607 09:01:07.956368  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.339022 (* 1 = 0.339022 loss)
I0607 09:01:07.956385  2187 sgd_solver.cpp:106] Iteration 11100, lr = 0.1
I0607 09:01:30.785889  2187 solver.cpp:228] Iteration 11200, loss = 0.398051
I0607 09:01:30.786283  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.398051 (* 1 = 0.398051 loss)
I0607 09:01:30.786330  2187 sgd_solver.cpp:106] Iteration 11200, lr = 0.1
I0607 09:01:53.290750  2187 solver.cpp:228] Iteration 11300, loss = 0.411285
I0607 09:01:53.290850  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.411285 (* 1 = 0.411285 loss)
I0607 09:01:53.290868  2187 sgd_solver.cpp:106] Iteration 11300, lr = 0.1
I0607 09:02:15.990674  2187 solver.cpp:228] Iteration 11400, loss = 0.347129
I0607 09:02:15.990869  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.347129 (* 1 = 0.347129 loss)
I0607 09:02:15.990888  2187 sgd_solver.cpp:106] Iteration 11400, lr = 0.1
I0607 09:02:38.573043  2187 solver.cpp:228] Iteration 11500, loss = 0.428877
I0607 09:02:38.573144  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.428877 (* 1 = 0.428877 loss)
I0607 09:02:38.573160  2187 sgd_solver.cpp:106] Iteration 11500, lr = 0.1
I0607 09:03:01.310060  2187 solver.cpp:228] Iteration 11600, loss = 0.347139
I0607 09:03:01.312844  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.347139 (* 1 = 0.347139 loss)
I0607 09:03:01.312875  2187 sgd_solver.cpp:106] Iteration 11600, lr = 0.1
I0607 09:03:23.760020  2187 solver.cpp:228] Iteration 11700, loss = 0.386075
I0607 09:03:23.760120  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.386075 (* 1 = 0.386075 loss)
I0607 09:03:23.760138  2187 sgd_solver.cpp:106] Iteration 11700, lr = 0.1
I0607 09:03:46.138547  2187 solver.cpp:228] Iteration 11800, loss = 0.392939
I0607 09:03:46.138741  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.392939 (* 1 = 0.392939 loss)
I0607 09:03:46.138757  2187 sgd_solver.cpp:106] Iteration 11800, lr = 0.1
I0607 09:04:08.566917  2187 solver.cpp:228] Iteration 11900, loss = 0.323906
I0607 09:04:08.567023  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.323906 (* 1 = 0.323906 loss)
I0607 09:04:08.567039  2187 sgd_solver.cpp:106] Iteration 11900, lr = 0.1
I0607 09:04:31.035361  2187 solver.cpp:337] Iteration 12000, Testing net (#0)
I0607 09:04:31.035799  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:04:32.669322  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7057
I0607 09:04:32.847220  2187 solver.cpp:228] Iteration 12000, loss = 0.51121
I0607 09:04:32.847307  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.51121 (* 1 = 0.51121 loss)
I0607 09:04:32.847328  2187 sgd_solver.cpp:106] Iteration 12000, lr = 0.1
I0607 09:04:55.369948  2187 solver.cpp:228] Iteration 12100, loss = 0.452239
I0607 09:04:55.370054  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.452239 (* 1 = 0.452239 loss)
I0607 09:04:55.370070  2187 sgd_solver.cpp:106] Iteration 12100, lr = 0.1
I0607 09:05:17.684919  2187 solver.cpp:228] Iteration 12200, loss = 0.259548
I0607 09:05:17.685101  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.259548 (* 1 = 0.259548 loss)
I0607 09:05:17.685117  2187 sgd_solver.cpp:106] Iteration 12200, lr = 0.1
I0607 09:05:40.158249  2187 solver.cpp:228] Iteration 12300, loss = 0.388005
I0607 09:05:40.158360  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.388006 (* 1 = 0.388006 loss)
I0607 09:05:40.158375  2187 sgd_solver.cpp:106] Iteration 12300, lr = 0.1
I0607 09:06:02.984199  2187 solver.cpp:228] Iteration 12400, loss = 0.231151
I0607 09:06:02.984421  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.231151 (* 1 = 0.231151 loss)
I0607 09:06:02.984441  2187 sgd_solver.cpp:106] Iteration 12400, lr = 0.1
I0607 09:06:25.608453  2187 solver.cpp:228] Iteration 12500, loss = 0.291216
I0607 09:06:25.608552  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.291216 (* 1 = 0.291216 loss)
I0607 09:06:25.608568  2187 sgd_solver.cpp:106] Iteration 12500, lr = 0.1
I0607 09:06:48.000208  2187 solver.cpp:228] Iteration 12600, loss = 0.267807
I0607 09:06:48.000557  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.267807 (* 1 = 0.267807 loss)
I0607 09:06:48.000605  2187 sgd_solver.cpp:106] Iteration 12600, lr = 0.1
I0607 09:07:10.548864  2187 solver.cpp:228] Iteration 12700, loss = 0.459582
I0607 09:07:10.548938  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.459582 (* 1 = 0.459582 loss)
I0607 09:07:10.548952  2187 sgd_solver.cpp:106] Iteration 12700, lr = 0.1
I0607 09:07:33.371840  2187 solver.cpp:228] Iteration 12800, loss = 0.30939
I0607 09:07:33.372187  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.30939 (* 1 = 0.30939 loss)
I0607 09:07:33.372248  2187 sgd_solver.cpp:106] Iteration 12800, lr = 0.1
I0607 09:07:55.938038  2187 solver.cpp:228] Iteration 12900, loss = 0.345166
I0607 09:07:55.938153  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.345166 (* 1 = 0.345166 loss)
I0607 09:07:55.938170  2187 sgd_solver.cpp:106] Iteration 12900, lr = 0.1
I0607 09:08:18.210212  2187 solver.cpp:337] Iteration 13000, Testing net (#0)
I0607 09:08:18.210865  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:08:19.808189  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8155
I0607 09:08:19.983597  2187 solver.cpp:228] Iteration 13000, loss = 0.304637
I0607 09:08:19.983683  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.304637 (* 1 = 0.304637 loss)
I0607 09:08:19.983722  2187 sgd_solver.cpp:106] Iteration 13000, lr = 0.1
I0607 09:08:42.380338  2187 solver.cpp:228] Iteration 13100, loss = 0.473187
I0607 09:08:42.380457  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.473187 (* 1 = 0.473187 loss)
I0607 09:08:42.380476  2187 sgd_solver.cpp:106] Iteration 13100, lr = 0.1
I0607 09:09:05.223583  2187 solver.cpp:228] Iteration 13200, loss = 0.182096
I0607 09:09:05.223866  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.182097 (* 1 = 0.182097 loss)
I0607 09:09:05.223913  2187 sgd_solver.cpp:106] Iteration 13200, lr = 0.1
I0607 09:09:27.724113  2187 solver.cpp:228] Iteration 13300, loss = 0.252752
I0607 09:09:27.724226  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.252752 (* 1 = 0.252752 loss)
I0607 09:09:27.724244  2187 sgd_solver.cpp:106] Iteration 13300, lr = 0.1
I0607 09:09:50.104992  2187 solver.cpp:228] Iteration 13400, loss = 0.30544
I0607 09:09:50.105271  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.30544 (* 1 = 0.30544 loss)
I0607 09:09:50.105314  2187 sgd_solver.cpp:106] Iteration 13400, lr = 0.1
I0607 09:10:12.496330  2187 solver.cpp:228] Iteration 13500, loss = 0.257947
I0607 09:10:12.496453  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.257947 (* 1 = 0.257947 loss)
I0607 09:10:12.496470  2187 sgd_solver.cpp:106] Iteration 13500, lr = 0.1
I0607 09:10:35.251631  2187 solver.cpp:228] Iteration 13600, loss = 0.268117
I0607 09:10:35.251920  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.268118 (* 1 = 0.268118 loss)
I0607 09:10:35.251957  2187 sgd_solver.cpp:106] Iteration 13600, lr = 0.1
I0607 09:10:57.779932  2187 solver.cpp:228] Iteration 13700, loss = 0.353908
I0607 09:10:57.780050  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.353908 (* 1 = 0.353908 loss)
I0607 09:10:57.780066  2187 sgd_solver.cpp:106] Iteration 13700, lr = 0.1
I0607 09:11:20.204156  2187 solver.cpp:228] Iteration 13800, loss = 0.286066
I0607 09:11:20.204393  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.286066 (* 1 = 0.286066 loss)
I0607 09:11:20.204429  2187 sgd_solver.cpp:106] Iteration 13800, lr = 0.1
I0607 09:11:42.592998  2187 solver.cpp:228] Iteration 13900, loss = 0.282196
I0607 09:11:42.593102  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.282196 (* 1 = 0.282196 loss)
I0607 09:11:42.593119  2187 sgd_solver.cpp:106] Iteration 13900, lr = 0.1
I0607 09:12:05.035133  2187 solver.cpp:337] Iteration 14000, Testing net (#0)
I0607 09:12:05.036350  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:12:06.616948  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8051
I0607 09:12:06.793493  2187 solver.cpp:228] Iteration 14000, loss = 0.424218
I0607 09:12:06.793586  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.424219 (* 1 = 0.424219 loss)
I0607 09:12:06.793606  2187 sgd_solver.cpp:106] Iteration 14000, lr = 0.1
I0607 09:12:29.188585  2187 solver.cpp:228] Iteration 14100, loss = 0.268342
I0607 09:12:29.188697  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.268342 (* 1 = 0.268342 loss)
I0607 09:12:29.188714  2187 sgd_solver.cpp:106] Iteration 14100, lr = 0.1
I0607 09:12:51.463286  2187 solver.cpp:228] Iteration 14200, loss = 0.236294
I0607 09:12:51.463521  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.236294 (* 1 = 0.236294 loss)
I0607 09:12:51.463541  2187 sgd_solver.cpp:106] Iteration 14200, lr = 0.1
I0607 09:13:13.838032  2187 solver.cpp:228] Iteration 14300, loss = 0.318841
I0607 09:13:13.838194  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.318841 (* 1 = 0.318841 loss)
I0607 09:13:13.838212  2187 sgd_solver.cpp:106] Iteration 14300, lr = 0.1
I0607 09:13:36.326184  2187 solver.cpp:228] Iteration 14400, loss = 0.315167
I0607 09:13:36.326406  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.315167 (* 1 = 0.315167 loss)
I0607 09:13:36.326424  2187 sgd_solver.cpp:106] Iteration 14400, lr = 0.1
I0607 09:13:58.594970  2187 solver.cpp:228] Iteration 14500, loss = 0.325626
I0607 09:13:58.595088  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.325626 (* 1 = 0.325626 loss)
I0607 09:13:58.595104  2187 sgd_solver.cpp:106] Iteration 14500, lr = 0.1
I0607 09:14:20.856439  2187 solver.cpp:228] Iteration 14600, loss = 0.332023
I0607 09:14:20.856664  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.332023 (* 1 = 0.332023 loss)
I0607 09:14:20.856684  2187 sgd_solver.cpp:106] Iteration 14600, lr = 0.1
I0607 09:14:43.180438  2187 solver.cpp:228] Iteration 14700, loss = 0.397468
I0607 09:14:43.180547  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.397468 (* 1 = 0.397468 loss)
I0607 09:14:43.180565  2187 sgd_solver.cpp:106] Iteration 14700, lr = 0.1
I0607 09:15:05.801169  2187 solver.cpp:228] Iteration 14800, loss = 0.279077
I0607 09:15:05.801574  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.279077 (* 1 = 0.279077 loss)
I0607 09:15:05.801641  2187 sgd_solver.cpp:106] Iteration 14800, lr = 0.1
I0607 09:15:28.108633  2187 solver.cpp:228] Iteration 14900, loss = 0.424824
I0607 09:15:28.108746  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.424824 (* 1 = 0.424824 loss)
I0607 09:15:28.108762  2187 sgd_solver.cpp:106] Iteration 14900, lr = 0.1
I0607 09:15:50.367084  2187 solver.cpp:337] Iteration 15000, Testing net (#0)
I0607 09:15:50.367743  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:15:51.956028  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7399
I0607 09:15:52.129869  2187 solver.cpp:228] Iteration 15000, loss = 0.246469
I0607 09:15:52.129956  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.246469 (* 1 = 0.246469 loss)
I0607 09:15:52.129981  2187 sgd_solver.cpp:106] Iteration 15000, lr = 0.1
I0607 09:16:14.385865  2187 solver.cpp:228] Iteration 15100, loss = 0.333162
I0607 09:16:14.386023  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.333162 (* 1 = 0.333162 loss)
I0607 09:16:14.386040  2187 sgd_solver.cpp:106] Iteration 15100, lr = 0.1
I0607 09:16:37.069221  2187 solver.cpp:228] Iteration 15200, loss = 0.259248
I0607 09:16:37.069443  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.259249 (* 1 = 0.259249 loss)
I0607 09:16:37.069464  2187 sgd_solver.cpp:106] Iteration 15200, lr = 0.1
I0607 09:16:59.524312  2187 solver.cpp:228] Iteration 15300, loss = 0.320659
I0607 09:16:59.524426  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.320659 (* 1 = 0.320659 loss)
I0607 09:16:59.524442  2187 sgd_solver.cpp:106] Iteration 15300, lr = 0.1
I0607 09:17:21.837788  2187 solver.cpp:228] Iteration 15400, loss = 0.296161
I0607 09:17:21.838166  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.296161 (* 1 = 0.296161 loss)
I0607 09:17:21.838212  2187 sgd_solver.cpp:106] Iteration 15400, lr = 0.1
I0607 09:17:44.038784  2187 solver.cpp:228] Iteration 15500, loss = 0.252487
I0607 09:17:44.038902  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.252487 (* 1 = 0.252487 loss)
I0607 09:17:44.038920  2187 sgd_solver.cpp:106] Iteration 15500, lr = 0.1
I0607 09:18:06.730583  2187 solver.cpp:228] Iteration 15600, loss = 0.310059
I0607 09:18:06.730891  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.310059 (* 1 = 0.310059 loss)
I0607 09:18:06.730936  2187 sgd_solver.cpp:106] Iteration 15600, lr = 0.1
I0607 09:18:29.354710  2187 solver.cpp:228] Iteration 15700, loss = 0.335047
I0607 09:18:29.354821  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.335047 (* 1 = 0.335047 loss)
I0607 09:18:29.354837  2187 sgd_solver.cpp:106] Iteration 15700, lr = 0.1
I0607 09:18:51.790743  2187 solver.cpp:228] Iteration 15800, loss = 0.329152
I0607 09:18:51.790977  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.329152 (* 1 = 0.329152 loss)
I0607 09:18:51.790997  2187 sgd_solver.cpp:106] Iteration 15800, lr = 0.1
I0607 09:19:14.106638  2187 solver.cpp:228] Iteration 15900, loss = 0.319011
I0607 09:19:14.106739  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.319011 (* 1 = 0.319011 loss)
I0607 09:19:14.106755  2187 sgd_solver.cpp:106] Iteration 15900, lr = 0.1
I0607 09:19:36.517786  2187 solver.cpp:337] Iteration 16000, Testing net (#0)
I0607 09:19:36.519491  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:19:38.130059  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7764
I0607 09:19:38.308920  2187 solver.cpp:228] Iteration 16000, loss = 0.199917
I0607 09:19:38.309020  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.199917 (* 1 = 0.199917 loss)
I0607 09:19:38.309041  2187 sgd_solver.cpp:106] Iteration 16000, lr = 0.1
I0607 09:20:00.932993  2187 solver.cpp:228] Iteration 16100, loss = 0.350667
I0607 09:20:00.933107  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.350667 (* 1 = 0.350667 loss)
I0607 09:20:00.933125  2187 sgd_solver.cpp:106] Iteration 16100, lr = 0.1
I0607 09:20:23.284085  2187 solver.cpp:228] Iteration 16200, loss = 0.246611
I0607 09:20:23.284394  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.246612 (* 1 = 0.246612 loss)
I0607 09:20:23.284437  2187 sgd_solver.cpp:106] Iteration 16200, lr = 0.1
I0607 09:20:45.608197  2187 solver.cpp:228] Iteration 16300, loss = 0.293167
I0607 09:20:45.608337  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.293167 (* 1 = 0.293167 loss)
I0607 09:20:45.608360  2187 sgd_solver.cpp:106] Iteration 16300, lr = 0.1
I0607 09:21:08.138905  2187 solver.cpp:228] Iteration 16400, loss = 0.238167
I0607 09:21:08.139165  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.238167 (* 1 = 0.238167 loss)
I0607 09:21:08.139194  2187 sgd_solver.cpp:106] Iteration 16400, lr = 0.1
I0607 09:21:30.859828  2187 solver.cpp:228] Iteration 16500, loss = 0.269725
I0607 09:21:30.859935  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.269725 (* 1 = 0.269725 loss)
I0607 09:21:30.859952  2187 sgd_solver.cpp:106] Iteration 16500, lr = 0.1
I0607 09:21:53.224815  2187 solver.cpp:228] Iteration 16600, loss = 0.307006
I0607 09:21:53.225039  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.307006 (* 1 = 0.307006 loss)
I0607 09:21:53.225057  2187 sgd_solver.cpp:106] Iteration 16600, lr = 0.1
I0607 09:22:15.577124  2187 solver.cpp:228] Iteration 16700, loss = 0.41276
I0607 09:22:15.577224  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.41276 (* 1 = 0.41276 loss)
I0607 09:22:15.577239  2187 sgd_solver.cpp:106] Iteration 16700, lr = 0.1
I0607 09:22:38.245664  2187 solver.cpp:228] Iteration 16800, loss = 0.182372
I0607 09:22:38.245987  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.182372 (* 1 = 0.182372 loss)
I0607 09:22:38.246022  2187 sgd_solver.cpp:106] Iteration 16800, lr = 0.1
I0607 09:23:01.009277  2187 solver.cpp:228] Iteration 16900, loss = 0.430543
I0607 09:23:01.009371  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.430543 (* 1 = 0.430543 loss)
I0607 09:23:01.009385  2187 sgd_solver.cpp:106] Iteration 16900, lr = 0.1
I0607 09:23:23.281503  2187 solver.cpp:337] Iteration 17000, Testing net (#0)
I0607 09:23:23.282163  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:23:24.867024  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7424
I0607 09:23:25.042801  2187 solver.cpp:228] Iteration 17000, loss = 0.220686
I0607 09:23:25.042892  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.220686 (* 1 = 0.220686 loss)
I0607 09:23:25.042912  2187 sgd_solver.cpp:106] Iteration 17000, lr = 0.1
I0607 09:23:47.362071  2187 solver.cpp:228] Iteration 17100, loss = 0.250218
I0607 09:23:47.362170  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.250218 (* 1 = 0.250218 loss)
I0607 09:23:47.362188  2187 sgd_solver.cpp:106] Iteration 17100, lr = 0.1
I0607 09:24:09.900070  2187 solver.cpp:228] Iteration 17200, loss = 0.219385
I0607 09:24:09.900367  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.219385 (* 1 = 0.219385 loss)
I0607 09:24:09.900404  2187 sgd_solver.cpp:106] Iteration 17200, lr = 0.1
I0607 09:24:32.811640  2187 solver.cpp:228] Iteration 17300, loss = 0.299608
I0607 09:24:32.811750  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.299608 (* 1 = 0.299608 loss)
I0607 09:24:32.811767  2187 sgd_solver.cpp:106] Iteration 17300, lr = 0.1
I0607 09:24:55.402043  2187 solver.cpp:228] Iteration 17400, loss = 0.208467
I0607 09:24:55.402304  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.208467 (* 1 = 0.208467 loss)
I0607 09:24:55.402344  2187 sgd_solver.cpp:106] Iteration 17400, lr = 0.1
I0607 09:25:17.741775  2187 solver.cpp:228] Iteration 17500, loss = 0.297664
I0607 09:25:17.741884  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.297664 (* 1 = 0.297664 loss)
I0607 09:25:17.741901  2187 sgd_solver.cpp:106] Iteration 17500, lr = 0.1
I0607 09:25:40.309463  2187 solver.cpp:228] Iteration 17600, loss = 0.313439
I0607 09:25:40.309715  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.313439 (* 1 = 0.313439 loss)
I0607 09:25:40.309747  2187 sgd_solver.cpp:106] Iteration 17600, lr = 0.1
I0607 09:26:02.979387  2187 solver.cpp:228] Iteration 17700, loss = 0.349686
I0607 09:26:02.979506  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.349686 (* 1 = 0.349686 loss)
I0607 09:26:02.979526  2187 sgd_solver.cpp:106] Iteration 17700, lr = 0.1
I0607 09:26:25.321498  2187 solver.cpp:228] Iteration 17800, loss = 0.19207
I0607 09:26:25.321723  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.19207 (* 1 = 0.19207 loss)
I0607 09:26:25.321741  2187 sgd_solver.cpp:106] Iteration 17800, lr = 0.1
I0607 09:26:47.589699  2187 solver.cpp:228] Iteration 17900, loss = 0.307334
I0607 09:26:47.589802  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.307334 (* 1 = 0.307334 loss)
I0607 09:26:47.589820  2187 sgd_solver.cpp:106] Iteration 17900, lr = 0.1
I0607 09:27:09.720904  2187 solver.cpp:337] Iteration 18000, Testing net (#0)
I0607 09:27:09.722174  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:27:11.300206  2187 solver.cpp:404]     Test net output #0: accuracy = 0.801
I0607 09:27:11.480197  2187 solver.cpp:228] Iteration 18000, loss = 0.490438
I0607 09:27:11.480293  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.490438 (* 1 = 0.490438 loss)
I0607 09:27:11.480316  2187 sgd_solver.cpp:106] Iteration 18000, lr = 0.1
I0607 09:27:34.026824  2187 solver.cpp:228] Iteration 18100, loss = 0.463188
I0607 09:27:34.026923  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.463188 (* 1 = 0.463188 loss)
I0607 09:27:34.026940  2187 sgd_solver.cpp:106] Iteration 18100, lr = 0.1
I0607 09:27:56.399986  2187 solver.cpp:228] Iteration 18200, loss = 0.357556
I0607 09:27:56.400377  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.357557 (* 1 = 0.357557 loss)
I0607 09:27:56.400424  2187 sgd_solver.cpp:106] Iteration 18200, lr = 0.1
I0607 09:28:18.642334  2187 solver.cpp:228] Iteration 18300, loss = 0.331317
I0607 09:28:18.642443  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.331317 (* 1 = 0.331317 loss)
I0607 09:28:18.642463  2187 sgd_solver.cpp:106] Iteration 18300, lr = 0.1
I0607 09:28:40.848492  2187 solver.cpp:228] Iteration 18400, loss = 0.408229
I0607 09:28:40.848748  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.408229 (* 1 = 0.408229 loss)
I0607 09:28:40.848769  2187 sgd_solver.cpp:106] Iteration 18400, lr = 0.1
I0607 09:29:03.212662  2187 solver.cpp:228] Iteration 18500, loss = 0.276392
I0607 09:29:03.212780  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.276392 (* 1 = 0.276392 loss)
I0607 09:29:03.212798  2187 sgd_solver.cpp:106] Iteration 18500, lr = 0.1
I0607 09:29:25.620707  2187 solver.cpp:228] Iteration 18600, loss = 0.333998
I0607 09:29:25.621208  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.333998 (* 1 = 0.333998 loss)
I0607 09:29:25.621304  2187 sgd_solver.cpp:106] Iteration 18600, lr = 0.1
I0607 09:29:48.015256  2187 solver.cpp:228] Iteration 18700, loss = 0.30257
I0607 09:29:48.015367  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.302571 (* 1 = 0.302571 loss)
I0607 09:29:48.015383  2187 sgd_solver.cpp:106] Iteration 18700, lr = 0.1
I0607 09:30:10.368288  2187 solver.cpp:228] Iteration 18800, loss = 0.4041
I0607 09:30:10.368470  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.4041 (* 1 = 0.4041 loss)
I0607 09:30:10.368489  2187 sgd_solver.cpp:106] Iteration 18800, lr = 0.1
I0607 09:30:32.863517  2187 solver.cpp:228] Iteration 18900, loss = 0.255968
I0607 09:30:32.863636  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.255968 (* 1 = 0.255968 loss)
I0607 09:30:32.863656  2187 sgd_solver.cpp:106] Iteration 18900, lr = 0.1
I0607 09:30:55.269639  2187 solver.cpp:337] Iteration 19000, Testing net (#0)
I0607 09:30:55.270030  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:30:56.887572  2187 solver.cpp:404]     Test net output #0: accuracy = 0.7859
I0607 09:30:57.068183  2187 solver.cpp:228] Iteration 19000, loss = 0.283922
I0607 09:30:57.068264  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.283922 (* 1 = 0.283922 loss)
I0607 09:30:57.068289  2187 sgd_solver.cpp:106] Iteration 19000, lr = 0.1
I0607 09:31:19.472214  2187 solver.cpp:228] Iteration 19100, loss = 0.341475
I0607 09:31:19.472317  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.341475 (* 1 = 0.341475 loss)
I0607 09:31:19.472332  2187 sgd_solver.cpp:106] Iteration 19100, lr = 0.1
I0607 09:31:41.904065  2187 solver.cpp:228] Iteration 19200, loss = 0.312353
I0607 09:31:41.904278  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.312353 (* 1 = 0.312353 loss)
I0607 09:31:41.904299  2187 sgd_solver.cpp:106] Iteration 19200, lr = 0.1
I0607 09:32:04.555913  2187 solver.cpp:228] Iteration 19300, loss = 0.336611
I0607 09:32:04.556021  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.336611 (* 1 = 0.336611 loss)
I0607 09:32:04.556038  2187 sgd_solver.cpp:106] Iteration 19300, lr = 0.1
I0607 09:32:27.258260  2187 solver.cpp:228] Iteration 19400, loss = 0.349301
I0607 09:32:27.258488  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.349301 (* 1 = 0.349301 loss)
I0607 09:32:27.258507  2187 sgd_solver.cpp:106] Iteration 19400, lr = 0.1
I0607 09:32:49.728575  2187 solver.cpp:228] Iteration 19500, loss = 0.430054
I0607 09:32:49.728672  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.430054 (* 1 = 0.430054 loss)
I0607 09:32:49.728688  2187 sgd_solver.cpp:106] Iteration 19500, lr = 0.1
I0607 09:33:12.049464  2187 solver.cpp:228] Iteration 19600, loss = 0.353582
I0607 09:33:12.049746  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.353582 (* 1 = 0.353582 loss)
I0607 09:33:12.049764  2187 sgd_solver.cpp:106] Iteration 19600, lr = 0.1
I0607 09:33:34.615716  2187 solver.cpp:228] Iteration 19700, loss = 0.327719
I0607 09:33:34.615821  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.327719 (* 1 = 0.327719 loss)
I0607 09:33:34.615839  2187 sgd_solver.cpp:106] Iteration 19700, lr = 0.1
I0607 09:33:57.139477  2187 solver.cpp:228] Iteration 19800, loss = 0.28423
I0607 09:33:57.139680  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.28423 (* 1 = 0.28423 loss)
I0607 09:33:57.139699  2187 sgd_solver.cpp:106] Iteration 19800, lr = 0.1
I0607 09:34:19.651609  2187 solver.cpp:228] Iteration 19900, loss = 0.416038
I0607 09:34:19.651691  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.416038 (* 1 = 0.416038 loss)
I0607 09:34:19.651705  2187 sgd_solver.cpp:106] Iteration 19900, lr = 0.1
I0607 09:34:41.735342  2187 solver.cpp:454] Snapshotting to binary proto file snapshot/_iter_20000.caffemodel
I0607 09:34:41.753687  2187 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot/_iter_20000.solverstate
I0607 09:34:41.756288  2187 solver.cpp:337] Iteration 20000, Testing net (#0)
I0607 09:34:41.756505  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:34:43.346726  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8388
I0607 09:34:43.525630  2187 solver.cpp:228] Iteration 20000, loss = 0.284361
I0607 09:34:43.525727  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.284361 (* 1 = 0.284361 loss)
I0607 09:34:43.525740  2187 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0607 09:35:05.972362  2187 solver.cpp:228] Iteration 20100, loss = 0.19089
I0607 09:35:05.972466  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.19089 (* 1 = 0.19089 loss)
I0607 09:35:05.972481  2187 sgd_solver.cpp:106] Iteration 20100, lr = 0.01
I0607 09:35:28.557597  2187 solver.cpp:228] Iteration 20200, loss = 0.0780786
I0607 09:35:28.569092  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0780788 (* 1 = 0.0780788 loss)
I0607 09:35:28.569135  2187 sgd_solver.cpp:106] Iteration 20200, lr = 0.01
I0607 09:35:51.238178  2187 solver.cpp:228] Iteration 20300, loss = 0.130006
I0607 09:35:51.238297  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.130006 (* 1 = 0.130006 loss)
I0607 09:35:51.238313  2187 sgd_solver.cpp:106] Iteration 20300, lr = 0.01
I0607 09:36:13.508585  2187 solver.cpp:228] Iteration 20400, loss = 0.0615105
I0607 09:36:13.508898  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0615106 (* 1 = 0.0615106 loss)
I0607 09:36:13.508942  2187 sgd_solver.cpp:106] Iteration 20400, lr = 0.01
I0607 09:36:35.849282  2187 solver.cpp:228] Iteration 20500, loss = 0.113987
I0607 09:36:35.849436  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.113987 (* 1 = 0.113987 loss)
I0607 09:36:35.849464  2187 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I0607 09:36:58.527767  2187 solver.cpp:228] Iteration 20600, loss = 0.0662234
I0607 09:36:58.528031  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0662236 (* 1 = 0.0662236 loss)
I0607 09:36:58.528074  2187 sgd_solver.cpp:106] Iteration 20600, lr = 0.01
I0607 09:37:21.205029  2187 solver.cpp:228] Iteration 20700, loss = 0.118956
I0607 09:37:21.205142  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.118956 (* 1 = 0.118956 loss)
I0607 09:37:21.205159  2187 sgd_solver.cpp:106] Iteration 20700, lr = 0.01
I0607 09:37:43.543849  2187 solver.cpp:228] Iteration 20800, loss = 0.106264
I0607 09:37:43.544055  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.106264 (* 1 = 0.106264 loss)
I0607 09:37:43.544073  2187 sgd_solver.cpp:106] Iteration 20800, lr = 0.01
I0607 09:38:06.924522  2187 solver.cpp:228] Iteration 20900, loss = 0.155919
I0607 09:38:06.924618  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.155919 (* 1 = 0.155919 loss)
I0607 09:38:06.924649  2187 sgd_solver.cpp:106] Iteration 20900, lr = 0.01
I0607 09:38:31.144011  2187 solver.cpp:337] Iteration 21000, Testing net (#0)
I0607 09:38:31.144498  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:38:32.991792  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9018
I0607 09:38:33.183327  2187 solver.cpp:228] Iteration 21000, loss = 0.124222
I0607 09:38:33.183418  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.124222 (* 1 = 0.124222 loss)
I0607 09:38:33.183435  2187 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I0607 09:38:58.416483  2187 solver.cpp:228] Iteration 21100, loss = 0.0672508
I0607 09:38:58.416581  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0672509 (* 1 = 0.0672509 loss)
I0607 09:38:58.416597  2187 sgd_solver.cpp:106] Iteration 21100, lr = 0.01
I0607 09:39:21.481552  2187 solver.cpp:228] Iteration 21200, loss = 0.0987603
I0607 09:39:21.481835  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0987604 (* 1 = 0.0987604 loss)
I0607 09:39:21.481884  2187 sgd_solver.cpp:106] Iteration 21200, lr = 0.01
I0607 09:39:44.132483  2187 solver.cpp:228] Iteration 21300, loss = 0.142638
I0607 09:39:44.132586  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.142639 (* 1 = 0.142639 loss)
I0607 09:39:44.132602  2187 sgd_solver.cpp:106] Iteration 21300, lr = 0.01
I0607 09:40:06.598162  2187 solver.cpp:228] Iteration 21400, loss = 0.119872
I0607 09:40:06.598433  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.119872 (* 1 = 0.119872 loss)
I0607 09:40:06.598479  2187 sgd_solver.cpp:106] Iteration 21400, lr = 0.01
I0607 09:40:28.953680  2187 solver.cpp:228] Iteration 21500, loss = 0.0860862
I0607 09:40:28.953781  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0860864 (* 1 = 0.0860864 loss)
I0607 09:40:28.953799  2187 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I0607 09:40:51.423579  2187 solver.cpp:228] Iteration 21600, loss = 0.0502838
I0607 09:40:51.423786  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0502839 (* 1 = 0.0502839 loss)
I0607 09:40:51.423806  2187 sgd_solver.cpp:106] Iteration 21600, lr = 0.01
I0607 09:41:13.985237  2187 solver.cpp:228] Iteration 21700, loss = 0.0801111
I0607 09:41:13.985350  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0801113 (* 1 = 0.0801113 loss)
I0607 09:41:13.985366  2187 sgd_solver.cpp:106] Iteration 21700, lr = 0.01
I0607 09:41:36.369578  2187 solver.cpp:228] Iteration 21800, loss = 0.117571
I0607 09:41:36.369833  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.117571 (* 1 = 0.117571 loss)
I0607 09:41:36.369884  2187 sgd_solver.cpp:106] Iteration 21800, lr = 0.01
I0607 09:41:58.605643  2187 solver.cpp:228] Iteration 21900, loss = 0.0535598
I0607 09:41:58.605758  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.05356 (* 1 = 0.05356 loss)
I0607 09:41:58.605775  2187 sgd_solver.cpp:106] Iteration 21900, lr = 0.01
I0607 09:42:20.709318  2187 solver.cpp:337] Iteration 22000, Testing net (#0)
I0607 09:42:20.709786  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:42:22.285025  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9017
I0607 09:42:22.451747  2187 solver.cpp:228] Iteration 22000, loss = 0.0789785
I0607 09:42:22.451843  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0789787 (* 1 = 0.0789787 loss)
I0607 09:42:22.451869  2187 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I0607 09:42:45.336863  2187 solver.cpp:228] Iteration 22100, loss = 0.0399607
I0607 09:42:45.336963  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0399608 (* 1 = 0.0399608 loss)
I0607 09:42:45.336982  2187 sgd_solver.cpp:106] Iteration 22100, lr = 0.01
I0607 09:43:07.747998  2187 solver.cpp:228] Iteration 22200, loss = 0.0576275
I0607 09:43:07.748342  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0576276 (* 1 = 0.0576276 loss)
I0607 09:43:07.748388  2187 sgd_solver.cpp:106] Iteration 22200, lr = 0.01
I0607 09:43:30.164063  2187 solver.cpp:228] Iteration 22300, loss = 0.0621225
I0607 09:43:30.164175  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0621226 (* 1 = 0.0621226 loss)
I0607 09:43:30.164191  2187 sgd_solver.cpp:106] Iteration 22300, lr = 0.01
I0607 09:43:52.490262  2187 solver.cpp:228] Iteration 22400, loss = 0.0535138
I0607 09:43:52.490510  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0535139 (* 1 = 0.0535139 loss)
I0607 09:43:52.490527  2187 sgd_solver.cpp:106] Iteration 22400, lr = 0.01
I0607 09:44:14.960631  2187 solver.cpp:228] Iteration 22500, loss = 0.0339373
I0607 09:44:14.960732  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0339374 (* 1 = 0.0339374 loss)
I0607 09:44:14.960749  2187 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I0607 09:44:37.574170  2187 solver.cpp:228] Iteration 22600, loss = 0.0733941
I0607 09:44:37.574455  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0733942 (* 1 = 0.0733942 loss)
I0607 09:44:37.574493  2187 sgd_solver.cpp:106] Iteration 22600, lr = 0.01
I0607 09:45:00.062104  2187 solver.cpp:228] Iteration 22700, loss = 0.0364117
I0607 09:45:00.062213  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0364118 (* 1 = 0.0364118 loss)
I0607 09:45:00.062229  2187 sgd_solver.cpp:106] Iteration 22700, lr = 0.01
I0607 09:45:22.441509  2187 solver.cpp:228] Iteration 22800, loss = 0.0653036
I0607 09:45:22.441915  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0653037 (* 1 = 0.0653037 loss)
I0607 09:45:22.441962  2187 sgd_solver.cpp:106] Iteration 22800, lr = 0.01
I0607 09:45:44.700662  2187 solver.cpp:228] Iteration 22900, loss = 0.0417457
I0607 09:45:44.700769  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0417458 (* 1 = 0.0417458 loss)
I0607 09:45:44.700785  2187 sgd_solver.cpp:106] Iteration 22900, lr = 0.01
I0607 09:46:06.926549  2187 solver.cpp:337] Iteration 23000, Testing net (#0)
I0607 09:46:06.927070  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:46:08.503319  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9024
I0607 09:46:08.676707  2187 solver.cpp:228] Iteration 23000, loss = 0.0452922
I0607 09:46:08.676800  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0452924 (* 1 = 0.0452924 loss)
I0607 09:46:08.676817  2187 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I0607 09:46:30.926417  2187 solver.cpp:228] Iteration 23100, loss = 0.0404714
I0607 09:46:30.926515  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0404715 (* 1 = 0.0404715 loss)
I0607 09:46:30.926530  2187 sgd_solver.cpp:106] Iteration 23100, lr = 0.01
I0607 09:46:52.999617  2187 solver.cpp:228] Iteration 23200, loss = 0.059613
I0607 09:46:52.999776  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0596131 (* 1 = 0.0596131 loss)
I0607 09:46:52.999794  2187 sgd_solver.cpp:106] Iteration 23200, lr = 0.01
I0607 09:47:15.340642  2187 solver.cpp:228] Iteration 23300, loss = 0.0538091
I0607 09:47:15.340828  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0538092 (* 1 = 0.0538092 loss)
I0607 09:47:15.340857  2187 sgd_solver.cpp:106] Iteration 23300, lr = 0.01
I0607 09:47:38.080734  2187 solver.cpp:228] Iteration 23400, loss = 0.0334108
I0607 09:47:38.080943  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.033411 (* 1 = 0.033411 loss)
I0607 09:47:38.080970  2187 sgd_solver.cpp:106] Iteration 23400, lr = 0.01
I0607 09:48:00.351014  2187 solver.cpp:228] Iteration 23500, loss = 0.0508329
I0607 09:48:00.351114  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.050833 (* 1 = 0.050833 loss)
I0607 09:48:00.351130  2187 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I0607 09:48:22.591449  2187 solver.cpp:228] Iteration 23600, loss = 0.0418327
I0607 09:48:22.593649  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0418328 (* 1 = 0.0418328 loss)
I0607 09:48:22.593672  2187 sgd_solver.cpp:106] Iteration 23600, lr = 0.01
I0607 09:48:45.042971  2187 solver.cpp:228] Iteration 23700, loss = 0.0224953
I0607 09:48:45.043081  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0224955 (* 1 = 0.0224955 loss)
I0607 09:48:45.043095  2187 sgd_solver.cpp:106] Iteration 23700, lr = 0.01
I0607 09:49:07.797232  2187 solver.cpp:228] Iteration 23800, loss = 0.0333732
I0607 09:49:07.797510  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0333734 (* 1 = 0.0333734 loss)
I0607 09:49:07.797531  2187 sgd_solver.cpp:106] Iteration 23800, lr = 0.01
I0607 09:49:30.186756  2187 solver.cpp:228] Iteration 23900, loss = 0.0262699
I0607 09:49:30.186856  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.02627 (* 1 = 0.02627 loss)
I0607 09:49:30.186872  2187 sgd_solver.cpp:106] Iteration 23900, lr = 0.01
I0607 09:49:52.265293  2187 solver.cpp:337] Iteration 24000, Testing net (#0)
I0607 09:49:52.265686  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:49:53.839969  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8976
I0607 09:49:54.015498  2187 solver.cpp:228] Iteration 24000, loss = 0.0221873
I0607 09:49:54.015584  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0221874 (* 1 = 0.0221874 loss)
I0607 09:49:54.015609  2187 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I0607 09:50:16.507943  2187 solver.cpp:228] Iteration 24100, loss = 0.0277157
I0607 09:50:16.508059  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0277158 (* 1 = 0.0277158 loss)
I0607 09:50:16.508077  2187 sgd_solver.cpp:106] Iteration 24100, lr = 0.01
I0607 09:50:39.208164  2187 solver.cpp:228] Iteration 24200, loss = 0.0236237
I0607 09:50:39.208372  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0236238 (* 1 = 0.0236238 loss)
I0607 09:50:39.208391  2187 sgd_solver.cpp:106] Iteration 24200, lr = 0.01
I0607 09:51:01.882387  2187 solver.cpp:228] Iteration 24300, loss = 0.0211916
I0607 09:51:01.882508  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0211917 (* 1 = 0.0211917 loss)
I0607 09:51:01.882541  2187 sgd_solver.cpp:106] Iteration 24300, lr = 0.01
I0607 09:51:24.263490  2187 solver.cpp:228] Iteration 24400, loss = 0.03534
I0607 09:51:24.263739  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0353401 (* 1 = 0.0353401 loss)
I0607 09:51:24.263757  2187 sgd_solver.cpp:106] Iteration 24400, lr = 0.01
I0607 09:51:46.616231  2187 solver.cpp:228] Iteration 24500, loss = 0.0196743
I0607 09:51:46.616343  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0196745 (* 1 = 0.0196745 loss)
I0607 09:51:46.616358  2187 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I0607 09:52:09.188480  2187 solver.cpp:228] Iteration 24600, loss = 0.0203373
I0607 09:52:09.188684  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0203374 (* 1 = 0.0203374 loss)
I0607 09:52:09.188704  2187 sgd_solver.cpp:106] Iteration 24600, lr = 0.01
I0607 09:52:31.912956  2187 solver.cpp:228] Iteration 24700, loss = 0.0341763
I0607 09:52:31.913060  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0341764 (* 1 = 0.0341764 loss)
I0607 09:52:31.913077  2187 sgd_solver.cpp:106] Iteration 24700, lr = 0.01
I0607 09:52:54.163826  2187 solver.cpp:228] Iteration 24800, loss = 0.0208635
I0607 09:52:54.164028  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0208636 (* 1 = 0.0208636 loss)
I0607 09:52:54.164044  2187 sgd_solver.cpp:106] Iteration 24800, lr = 0.01
I0607 09:53:16.537920  2187 solver.cpp:228] Iteration 24900, loss = 0.0324385
I0607 09:53:16.538034  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0324386 (* 1 = 0.0324386 loss)
I0607 09:53:16.538050  2187 sgd_solver.cpp:106] Iteration 24900, lr = 0.01
I0607 09:53:38.953001  2187 solver.cpp:337] Iteration 25000, Testing net (#0)
I0607 09:53:38.953672  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:53:40.551298  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8993
I0607 09:53:40.730911  2187 solver.cpp:228] Iteration 25000, loss = 0.0177595
I0607 09:53:40.731016  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0177596 (* 1 = 0.0177596 loss)
I0607 09:53:40.731036  2187 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I0607 09:54:03.314966  2187 solver.cpp:228] Iteration 25100, loss = 0.0249634
I0607 09:54:03.315068  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0249636 (* 1 = 0.0249636 loss)
I0607 09:54:03.315083  2187 sgd_solver.cpp:106] Iteration 25100, lr = 0.01
I0607 09:54:25.691926  2187 solver.cpp:228] Iteration 25200, loss = 0.0149459
I0607 09:54:25.692194  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0149461 (* 1 = 0.0149461 loss)
I0607 09:54:25.692211  2187 sgd_solver.cpp:106] Iteration 25200, lr = 0.01
I0607 09:54:46.244701  2187 solver.cpp:228] Iteration 25300, loss = 0.0138172
I0607 09:54:46.244792  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0138174 (* 1 = 0.0138174 loss)
I0607 09:54:46.244807  2187 sgd_solver.cpp:106] Iteration 25300, lr = 0.01
I0607 09:55:06.248193  2187 solver.cpp:228] Iteration 25400, loss = 0.0172636
I0607 09:55:06.248397  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0172637 (* 1 = 0.0172637 loss)
I0607 09:55:06.248414  2187 sgd_solver.cpp:106] Iteration 25400, lr = 0.01
I0607 09:55:28.053947  2187 solver.cpp:228] Iteration 25500, loss = 0.0108218
I0607 09:55:28.054059  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0108219 (* 1 = 0.0108219 loss)
I0607 09:55:28.054075  2187 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I0607 09:55:50.576565  2187 solver.cpp:228] Iteration 25600, loss = 0.0318027
I0607 09:55:50.576879  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0318029 (* 1 = 0.0318029 loss)
I0607 09:55:50.576917  2187 sgd_solver.cpp:106] Iteration 25600, lr = 0.01
I0607 09:56:12.931676  2187 solver.cpp:228] Iteration 25700, loss = 0.0355801
I0607 09:56:12.931807  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0355802 (* 1 = 0.0355802 loss)
I0607 09:56:12.931823  2187 sgd_solver.cpp:106] Iteration 25700, lr = 0.01
I0607 09:56:35.443189  2187 solver.cpp:228] Iteration 25800, loss = 0.00799943
I0607 09:56:35.443487  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00799957 (* 1 = 0.00799957 loss)
I0607 09:56:35.443529  2187 sgd_solver.cpp:106] Iteration 25800, lr = 0.01
I0607 09:56:57.880002  2187 solver.cpp:228] Iteration 25900, loss = 0.0168447
I0607 09:56:57.880120  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0168449 (* 1 = 0.0168449 loss)
I0607 09:56:57.880138  2187 sgd_solver.cpp:106] Iteration 25900, lr = 0.01
I0607 09:57:20.207849  2187 solver.cpp:337] Iteration 26000, Testing net (#0)
I0607 09:57:20.209576  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 09:57:21.793752  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8999
I0607 09:57:21.971025  2187 solver.cpp:228] Iteration 26000, loss = 0.00957408
I0607 09:57:21.971117  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00957422 (* 1 = 0.00957422 loss)
I0607 09:57:21.971134  2187 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I0607 09:57:44.385722  2187 solver.cpp:228] Iteration 26100, loss = 0.00992112
I0607 09:57:44.385831  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00992126 (* 1 = 0.00992126 loss)
I0607 09:57:44.385848  2187 sgd_solver.cpp:106] Iteration 26100, lr = 0.01
I0607 09:58:06.869369  2187 solver.cpp:228] Iteration 26200, loss = 0.0180418
I0607 09:58:06.869673  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.018042 (* 1 = 0.018042 loss)
I0607 09:58:06.869719  2187 sgd_solver.cpp:106] Iteration 26200, lr = 0.01
I0607 09:58:29.352188  2187 solver.cpp:228] Iteration 26300, loss = 0.0125094
I0607 09:58:29.352296  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0125096 (* 1 = 0.0125096 loss)
I0607 09:58:29.352311  2187 sgd_solver.cpp:106] Iteration 26300, lr = 0.01
I0607 09:58:52.008133  2187 solver.cpp:228] Iteration 26400, loss = 0.00811708
I0607 09:58:52.008379  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00811722 (* 1 = 0.00811722 loss)
I0607 09:58:52.008404  2187 sgd_solver.cpp:106] Iteration 26400, lr = 0.01
I0607 09:59:14.400709  2187 solver.cpp:228] Iteration 26500, loss = 0.0104159
I0607 09:59:14.400820  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0104161 (* 1 = 0.0104161 loss)
I0607 09:59:14.400837  2187 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I0607 09:59:36.891999  2187 solver.cpp:228] Iteration 26600, loss = 0.00526861
I0607 09:59:36.892345  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00526875 (* 1 = 0.00526875 loss)
I0607 09:59:36.892385  2187 sgd_solver.cpp:106] Iteration 26600, lr = 0.01
I0607 09:59:59.274282  2187 solver.cpp:228] Iteration 26700, loss = 0.00417338
I0607 09:59:59.274408  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00417351 (* 1 = 0.00417351 loss)
I0607 09:59:59.274426  2187 sgd_solver.cpp:106] Iteration 26700, lr = 0.01
I0607 10:00:21.926216  2187 solver.cpp:228] Iteration 26800, loss = 0.0122511
I0607 10:00:21.926472  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0122513 (* 1 = 0.0122513 loss)
I0607 10:00:21.926491  2187 sgd_solver.cpp:106] Iteration 26800, lr = 0.01
I0607 10:00:44.433221  2187 solver.cpp:228] Iteration 26900, loss = 0.00689567
I0607 10:00:44.433327  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00689581 (* 1 = 0.00689581 loss)
I0607 10:00:44.433344  2187 sgd_solver.cpp:106] Iteration 26900, lr = 0.01
I0607 10:01:06.831248  2187 solver.cpp:337] Iteration 27000, Testing net (#0)
I0607 10:01:06.831887  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:01:08.448684  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8978
I0607 10:01:08.617408  2187 solver.cpp:228] Iteration 27000, loss = 0.0151206
I0607 10:01:08.617506  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0151208 (* 1 = 0.0151208 loss)
I0607 10:01:08.617527  2187 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I0607 10:01:31.063068  2187 solver.cpp:228] Iteration 27100, loss = 0.00671372
I0607 10:01:31.063170  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00671385 (* 1 = 0.00671385 loss)
I0607 10:01:31.063185  2187 sgd_solver.cpp:106] Iteration 27100, lr = 0.01
I0607 10:01:53.582950  2187 solver.cpp:228] Iteration 27200, loss = 0.0105447
I0607 10:01:53.583119  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0105448 (* 1 = 0.0105448 loss)
I0607 10:01:53.583138  2187 sgd_solver.cpp:106] Iteration 27200, lr = 0.01
I0607 10:02:16.348212  2187 solver.cpp:228] Iteration 27300, loss = 0.00958479
I0607 10:02:16.348312  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00958492 (* 1 = 0.00958492 loss)
I0607 10:02:16.348328  2187 sgd_solver.cpp:106] Iteration 27300, lr = 0.01
I0607 10:02:38.774350  2187 solver.cpp:228] Iteration 27400, loss = 0.0107611
I0607 10:02:38.774652  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0107612 (* 1 = 0.0107612 loss)
I0607 10:02:38.774682  2187 sgd_solver.cpp:106] Iteration 27400, lr = 0.01
I0607 10:03:01.228720  2187 solver.cpp:228] Iteration 27500, loss = 0.00808161
I0607 10:03:01.228832  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00808174 (* 1 = 0.00808174 loss)
I0607 10:03:01.228847  2187 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I0607 10:03:23.545651  2187 solver.cpp:228] Iteration 27600, loss = 0.00735596
I0607 10:03:23.545938  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0073561 (* 1 = 0.0073561 loss)
I0607 10:03:23.545999  2187 sgd_solver.cpp:106] Iteration 27600, lr = 0.01
I0607 10:03:46.381685  2187 solver.cpp:228] Iteration 27700, loss = 0.0231807
I0607 10:03:46.381800  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0231809 (* 1 = 0.0231809 loss)
I0607 10:03:46.381819  2187 sgd_solver.cpp:106] Iteration 27700, lr = 0.01
I0607 10:04:08.826540  2187 solver.cpp:228] Iteration 27800, loss = 0.0136189
I0607 10:04:08.826855  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.013619 (* 1 = 0.013619 loss)
I0607 10:04:08.826905  2187 sgd_solver.cpp:106] Iteration 27800, lr = 0.01
I0607 10:04:31.282135  2187 solver.cpp:228] Iteration 27900, loss = 0.00585806
I0607 10:04:31.282241  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00585819 (* 1 = 0.00585819 loss)
I0607 10:04:31.282263  2187 sgd_solver.cpp:106] Iteration 27900, lr = 0.01
I0607 10:04:53.502971  2187 solver.cpp:337] Iteration 28000, Testing net (#0)
I0607 10:04:53.503629  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:04:54.948308  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8979
I0607 10:04:55.102489  2187 solver.cpp:228] Iteration 28000, loss = 0.00555164
I0607 10:04:55.102563  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00555177 (* 1 = 0.00555177 loss)
I0607 10:04:55.102583  2187 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I0607 10:05:17.890805  2187 solver.cpp:228] Iteration 28100, loss = 0.0121402
I0607 10:05:17.890897  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0121403 (* 1 = 0.0121403 loss)
I0607 10:05:17.890913  2187 sgd_solver.cpp:106] Iteration 28100, lr = 0.01
I0607 10:05:40.319319  2187 solver.cpp:228] Iteration 28200, loss = 0.00549544
I0607 10:05:40.319605  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00549558 (* 1 = 0.00549558 loss)
I0607 10:05:40.319630  2187 sgd_solver.cpp:106] Iteration 28200, lr = 0.01
I0607 10:06:02.795613  2187 solver.cpp:228] Iteration 28300, loss = 0.0156388
I0607 10:06:02.795696  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.015639 (* 1 = 0.015639 loss)
I0607 10:06:02.795711  2187 sgd_solver.cpp:106] Iteration 28300, lr = 0.01
I0607 10:06:25.072150  2187 solver.cpp:228] Iteration 28400, loss = 0.00514294
I0607 10:06:25.072340  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00514307 (* 1 = 0.00514307 loss)
I0607 10:06:25.072358  2187 sgd_solver.cpp:106] Iteration 28400, lr = 0.01
I0607 10:06:47.868540  2187 solver.cpp:228] Iteration 28500, loss = 0.00526985
I0607 10:06:47.868640  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00526999 (* 1 = 0.00526999 loss)
I0607 10:06:47.868657  2187 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I0607 10:07:10.393970  2187 solver.cpp:228] Iteration 28600, loss = 0.0099585
I0607 10:07:10.394204  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00995863 (* 1 = 0.00995863 loss)
I0607 10:07:10.394225  2187 sgd_solver.cpp:106] Iteration 28600, lr = 0.01
I0607 10:07:33.003448  2187 solver.cpp:228] Iteration 28700, loss = 0.00676123
I0607 10:07:33.003554  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00676136 (* 1 = 0.00676136 loss)
I0607 10:07:33.003571  2187 sgd_solver.cpp:106] Iteration 28700, lr = 0.01
I0607 10:07:55.427713  2187 solver.cpp:228] Iteration 28800, loss = 0.00569572
I0607 10:07:55.428063  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00569585 (* 1 = 0.00569585 loss)
I0607 10:07:55.428105  2187 sgd_solver.cpp:106] Iteration 28800, lr = 0.01
I0607 10:08:17.979358  2187 solver.cpp:228] Iteration 28900, loss = 0.00698609
I0607 10:08:17.979506  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00698622 (* 1 = 0.00698622 loss)
I0607 10:08:17.979528  2187 sgd_solver.cpp:106] Iteration 28900, lr = 0.01
I0607 10:08:40.427088  2187 solver.cpp:337] Iteration 29000, Testing net (#0)
I0607 10:08:40.427525  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:08:42.006461  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8969
I0607 10:08:42.180683  2187 solver.cpp:228] Iteration 29000, loss = 0.00886939
I0607 10:08:42.180775  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00886952 (* 1 = 0.00886952 loss)
I0607 10:08:42.180794  2187 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I0607 10:09:04.515138  2187 solver.cpp:228] Iteration 29100, loss = 0.00817535
I0607 10:09:04.515244  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00817547 (* 1 = 0.00817547 loss)
I0607 10:09:04.515276  2187 sgd_solver.cpp:106] Iteration 29100, lr = 0.01
I0607 10:09:27.092010  2187 solver.cpp:228] Iteration 29200, loss = 0.00476527
I0607 10:09:27.092314  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0047654 (* 1 = 0.0047654 loss)
I0607 10:09:27.092332  2187 sgd_solver.cpp:106] Iteration 29200, lr = 0.01
I0607 10:09:49.610740  2187 solver.cpp:228] Iteration 29300, loss = 0.00939752
I0607 10:09:49.610841  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00939765 (* 1 = 0.00939765 loss)
I0607 10:09:49.610857  2187 sgd_solver.cpp:106] Iteration 29300, lr = 0.01
I0607 10:10:12.372684  2187 solver.cpp:228] Iteration 29400, loss = 0.00475883
I0607 10:10:12.372997  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00475896 (* 1 = 0.00475896 loss)
I0607 10:10:12.373041  2187 sgd_solver.cpp:106] Iteration 29400, lr = 0.01
I0607 10:10:34.760367  2187 solver.cpp:228] Iteration 29500, loss = 0.0132662
I0607 10:10:34.760476  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0132664 (* 1 = 0.0132664 loss)
I0607 10:10:34.760493  2187 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I0607 10:10:57.245678  2187 solver.cpp:228] Iteration 29600, loss = 0.0108291
I0607 10:10:57.245888  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0108293 (* 1 = 0.0108293 loss)
I0607 10:10:57.245906  2187 sgd_solver.cpp:106] Iteration 29600, lr = 0.01
I0607 10:11:19.779599  2187 solver.cpp:228] Iteration 29700, loss = 0.0165942
I0607 10:11:19.779714  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0165943 (* 1 = 0.0165943 loss)
I0607 10:11:19.779732  2187 sgd_solver.cpp:106] Iteration 29700, lr = 0.01
I0607 10:11:42.490557  2187 solver.cpp:228] Iteration 29800, loss = 0.00682187
I0607 10:11:42.490880  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00682201 (* 1 = 0.00682201 loss)
I0607 10:11:42.490923  2187 sgd_solver.cpp:106] Iteration 29800, lr = 0.01
I0607 10:12:04.916365  2187 solver.cpp:228] Iteration 29900, loss = 0.00688645
I0607 10:12:04.916462  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00688658 (* 1 = 0.00688658 loss)
I0607 10:12:04.916476  2187 sgd_solver.cpp:106] Iteration 29900, lr = 0.01
I0607 10:12:28.383127  2187 solver.cpp:454] Snapshotting to binary proto file snapshot/_iter_30000.caffemodel
I0607 10:12:28.393144  2187 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot/_iter_30000.solverstate
I0607 10:12:28.395565  2187 solver.cpp:337] Iteration 30000, Testing net (#0)
I0607 10:12:28.396654  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:12:30.236843  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8992
I0607 10:12:30.445935  2187 solver.cpp:228] Iteration 30000, loss = 0.00428032
I0607 10:12:30.446079  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00428045 (* 1 = 0.00428045 loss)
I0607 10:12:30.446096  2187 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I0607 10:12:54.670284  2187 solver.cpp:228] Iteration 30100, loss = 0.00548639
I0607 10:12:54.670394  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00548653 (* 1 = 0.00548653 loss)
I0607 10:12:54.670411  2187 sgd_solver.cpp:106] Iteration 30100, lr = 0.01
I0607 10:13:18.664589  2187 solver.cpp:228] Iteration 30200, loss = 0.00433612
I0607 10:13:18.664809  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00433626 (* 1 = 0.00433626 loss)
I0607 10:13:18.664826  2187 sgd_solver.cpp:106] Iteration 30200, lr = 0.01
I0607 10:13:42.361053  2187 solver.cpp:228] Iteration 30300, loss = 0.00932914
I0607 10:13:42.361176  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00932927 (* 1 = 0.00932927 loss)
I0607 10:13:42.361209  2187 sgd_solver.cpp:106] Iteration 30300, lr = 0.01
I0607 10:14:05.177335  2187 solver.cpp:228] Iteration 30400, loss = 0.00569287
I0607 10:14:05.177660  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.005693 (* 1 = 0.005693 loss)
I0607 10:14:05.177708  2187 sgd_solver.cpp:106] Iteration 30400, lr = 0.01
I0607 10:14:27.786700  2187 solver.cpp:228] Iteration 30500, loss = 0.00519437
I0607 10:14:27.786808  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0051945 (* 1 = 0.0051945 loss)
I0607 10:14:27.786824  2187 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I0607 10:14:50.210517  2187 solver.cpp:228] Iteration 30600, loss = 0.00644191
I0607 10:14:50.210830  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00644204 (* 1 = 0.00644204 loss)
I0607 10:14:50.210872  2187 sgd_solver.cpp:106] Iteration 30600, lr = 0.01
I0607 10:15:12.567298  2187 solver.cpp:228] Iteration 30700, loss = 0.00688286
I0607 10:15:12.567420  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00688299 (* 1 = 0.00688299 loss)
I0607 10:15:12.567436  2187 sgd_solver.cpp:106] Iteration 30700, lr = 0.01
I0607 10:15:35.086792  2187 solver.cpp:228] Iteration 30800, loss = 0.00506718
I0607 10:15:35.087029  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00506731 (* 1 = 0.00506731 loss)
I0607 10:15:35.087070  2187 sgd_solver.cpp:106] Iteration 30800, lr = 0.01
I0607 10:15:57.974084  2187 solver.cpp:228] Iteration 30900, loss = 0.00927406
I0607 10:15:57.974200  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00927419 (* 1 = 0.00927419 loss)
I0607 10:15:57.974216  2187 sgd_solver.cpp:106] Iteration 30900, lr = 0.01
I0607 10:16:20.022975  2187 solver.cpp:337] Iteration 31000, Testing net (#0)
I0607 10:16:20.023593  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:16:21.628274  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8951
I0607 10:16:21.803779  2187 solver.cpp:228] Iteration 31000, loss = 0.00504518
I0607 10:16:21.803876  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00504531 (* 1 = 0.00504531 loss)
I0607 10:16:21.803896  2187 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I0607 10:16:44.315240  2187 solver.cpp:228] Iteration 31100, loss = 0.00583144
I0607 10:16:44.315346  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00583157 (* 1 = 0.00583157 loss)
I0607 10:16:44.315361  2187 sgd_solver.cpp:106] Iteration 31100, lr = 0.01
I0607 10:17:06.803073  2187 solver.cpp:228] Iteration 31200, loss = 0.0069345
I0607 10:17:06.803380  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00693463 (* 1 = 0.00693463 loss)
I0607 10:17:06.803418  2187 sgd_solver.cpp:106] Iteration 31200, lr = 0.01
I0607 10:17:29.670408  2187 solver.cpp:228] Iteration 31300, loss = 0.00776113
I0607 10:17:29.670528  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00776126 (* 1 = 0.00776126 loss)
I0607 10:17:29.670545  2187 sgd_solver.cpp:106] Iteration 31300, lr = 0.01
I0607 10:17:52.139868  2187 solver.cpp:228] Iteration 31400, loss = 0.00746718
I0607 10:17:52.140152  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00746731 (* 1 = 0.00746731 loss)
I0607 10:17:52.140194  2187 sgd_solver.cpp:106] Iteration 31400, lr = 0.01
I0607 10:18:14.460140  2187 solver.cpp:228] Iteration 31500, loss = 0.0109627
I0607 10:18:14.460242  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0109628 (* 1 = 0.0109628 loss)
I0607 10:18:14.460258  2187 sgd_solver.cpp:106] Iteration 31500, lr = 0.01
I0607 10:18:34.435461  2187 solver.cpp:228] Iteration 31600, loss = 0.0093225
I0607 10:18:34.435664  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00932263 (* 1 = 0.00932263 loss)
I0607 10:18:34.435683  2187 sgd_solver.cpp:106] Iteration 31600, lr = 0.01
I0607 10:18:56.812697  2187 solver.cpp:228] Iteration 31700, loss = 0.00788316
I0607 10:18:56.812803  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00788329 (* 1 = 0.00788329 loss)
I0607 10:18:56.812819  2187 sgd_solver.cpp:106] Iteration 31700, lr = 0.01
I0607 10:19:19.393093  2187 solver.cpp:228] Iteration 31800, loss = 0.0123281
I0607 10:19:19.393479  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0123282 (* 1 = 0.0123282 loss)
I0607 10:19:19.393537  2187 sgd_solver.cpp:106] Iteration 31800, lr = 0.01
I0607 10:19:41.436339  2187 solver.cpp:228] Iteration 31900, loss = 0.0101691
I0607 10:19:41.436450  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0101692 (* 1 = 0.0101692 loss)
I0607 10:19:41.436467  2187 sgd_solver.cpp:106] Iteration 31900, lr = 0.01
I0607 10:20:03.302304  2187 solver.cpp:337] Iteration 32000, Testing net (#0)
I0607 10:20:03.302703  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:20:04.872953  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8731
I0607 10:20:05.048349  2187 solver.cpp:228] Iteration 32000, loss = 0.0136836
I0607 10:20:05.048434  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0136837 (* 1 = 0.0136837 loss)
I0607 10:20:05.048454  2187 sgd_solver.cpp:106] Iteration 32000, lr = 0.01
I0607 10:20:27.321282  2187 solver.cpp:228] Iteration 32100, loss = 0.0664984
I0607 10:20:27.321382  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0664985 (* 1 = 0.0664985 loss)
I0607 10:20:27.321398  2187 sgd_solver.cpp:106] Iteration 32100, lr = 0.01
I0607 10:20:49.994879  2187 solver.cpp:228] Iteration 32200, loss = 0.0411545
I0607 10:20:49.995118  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0411547 (* 1 = 0.0411547 loss)
I0607 10:20:49.995137  2187 sgd_solver.cpp:106] Iteration 32200, lr = 0.01
I0607 10:21:12.397677  2187 solver.cpp:228] Iteration 32300, loss = 0.0591774
I0607 10:21:12.397773  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0591776 (* 1 = 0.0591776 loss)
I0607 10:21:12.397789  2187 sgd_solver.cpp:106] Iteration 32300, lr = 0.01
I0607 10:21:34.704506  2187 solver.cpp:228] Iteration 32400, loss = 0.0850578
I0607 10:21:34.704766  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0850579 (* 1 = 0.0850579 loss)
I0607 10:21:34.704803  2187 sgd_solver.cpp:106] Iteration 32400, lr = 0.01
I0607 10:21:56.967598  2187 solver.cpp:228] Iteration 32500, loss = 0.0521608
I0607 10:21:56.967700  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.052161 (* 1 = 0.052161 loss)
I0607 10:21:56.967713  2187 sgd_solver.cpp:106] Iteration 32500, lr = 0.01
I0607 10:22:19.539269  2187 solver.cpp:228] Iteration 32600, loss = 0.0748033
I0607 10:22:19.540366  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0748034 (* 1 = 0.0748034 loss)
I0607 10:22:19.540385  2187 sgd_solver.cpp:106] Iteration 32600, lr = 0.01
I0607 10:22:41.982580  2187 solver.cpp:228] Iteration 32700, loss = 0.0484411
I0607 10:22:41.982688  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0484412 (* 1 = 0.0484412 loss)
I0607 10:22:41.982705  2187 sgd_solver.cpp:106] Iteration 32700, lr = 0.01
I0607 10:23:03.972486  2187 solver.cpp:228] Iteration 32800, loss = 0.0706116
I0607 10:23:03.972697  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0706118 (* 1 = 0.0706118 loss)
I0607 10:23:03.972714  2187 sgd_solver.cpp:106] Iteration 32800, lr = 0.01
I0607 10:23:26.250087  2187 solver.cpp:228] Iteration 32900, loss = 0.0480695
I0607 10:23:26.250180  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0480697 (* 1 = 0.0480697 loss)
I0607 10:23:26.250196  2187 sgd_solver.cpp:106] Iteration 32900, lr = 0.01
I0607 10:23:48.717823  2187 solver.cpp:337] Iteration 33000, Testing net (#0)
I0607 10:23:48.720799  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:23:50.364598  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8802
I0607 10:23:50.543020  2187 solver.cpp:228] Iteration 33000, loss = 0.0635609
I0607 10:23:50.543118  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0635611 (* 1 = 0.0635611 loss)
I0607 10:23:50.543139  2187 sgd_solver.cpp:106] Iteration 33000, lr = 0.01
I0607 10:24:12.996183  2187 solver.cpp:228] Iteration 33100, loss = 0.0685016
I0607 10:24:12.996279  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0685017 (* 1 = 0.0685017 loss)
I0607 10:24:12.996294  2187 sgd_solver.cpp:106] Iteration 33100, lr = 0.01
I0607 10:24:35.283720  2187 solver.cpp:228] Iteration 33200, loss = 0.0230533
I0607 10:24:35.284085  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0230535 (* 1 = 0.0230535 loss)
I0607 10:24:35.284124  2187 sgd_solver.cpp:106] Iteration 33200, lr = 0.01
I0607 10:24:57.719447  2187 solver.cpp:228] Iteration 33300, loss = 0.0600156
I0607 10:24:57.719559  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0600157 (* 1 = 0.0600157 loss)
I0607 10:24:57.719578  2187 sgd_solver.cpp:106] Iteration 33300, lr = 0.01
I0607 10:25:20.390991  2187 solver.cpp:228] Iteration 33400, loss = 0.0716622
I0607 10:25:20.391278  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0716623 (* 1 = 0.0716623 loss)
I0607 10:25:20.391305  2187 sgd_solver.cpp:106] Iteration 33400, lr = 0.01
I0607 10:25:42.767083  2187 solver.cpp:228] Iteration 33500, loss = 0.049
I0607 10:25:42.767189  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0490001 (* 1 = 0.0490001 loss)
I0607 10:25:42.767206  2187 sgd_solver.cpp:106] Iteration 33500, lr = 0.01
I0607 10:26:05.016031  2187 solver.cpp:228] Iteration 33600, loss = 0.0320517
I0607 10:26:05.016337  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0320518 (* 1 = 0.0320518 loss)
I0607 10:26:05.019446  2187 sgd_solver.cpp:106] Iteration 33600, lr = 0.01
I0607 10:26:27.295894  2187 solver.cpp:228] Iteration 33700, loss = 0.130759
I0607 10:26:27.296005  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.130759 (* 1 = 0.130759 loss)
I0607 10:26:27.296021  2187 sgd_solver.cpp:106] Iteration 33700, lr = 0.01
I0607 10:26:49.933996  2187 solver.cpp:228] Iteration 33800, loss = 0.0425931
I0607 10:26:49.934240  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0425931 (* 1 = 0.0425931 loss)
I0607 10:26:49.934264  2187 sgd_solver.cpp:106] Iteration 33800, lr = 0.01
I0607 10:27:12.343914  2187 solver.cpp:228] Iteration 33900, loss = 0.0172939
I0607 10:27:12.344022  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.017294 (* 1 = 0.017294 loss)
I0607 10:27:12.344038  2187 sgd_solver.cpp:106] Iteration 33900, lr = 0.01
I0607 10:27:34.340070  2187 solver.cpp:337] Iteration 34000, Testing net (#0)
I0607 10:27:34.340431  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:27:35.919276  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8723
I0607 10:27:36.091464  2187 solver.cpp:228] Iteration 34000, loss = 0.066388
I0607 10:27:36.091554  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0663881 (* 1 = 0.0663881 loss)
I0607 10:27:36.091573  2187 sgd_solver.cpp:106] Iteration 34000, lr = 0.01
I0607 10:27:58.475198  2187 solver.cpp:228] Iteration 34100, loss = 0.0537418
I0607 10:27:58.475323  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0537419 (* 1 = 0.0537419 loss)
I0607 10:27:58.475339  2187 sgd_solver.cpp:106] Iteration 34100, lr = 0.01
I0607 10:28:21.261198  2187 solver.cpp:228] Iteration 34200, loss = 0.0454528
I0607 10:28:21.261492  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0454529 (* 1 = 0.0454529 loss)
I0607 10:28:21.261518  2187 sgd_solver.cpp:106] Iteration 34200, lr = 0.01
I0607 10:28:43.706476  2187 solver.cpp:228] Iteration 34300, loss = 0.0320629
I0607 10:28:43.706588  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.032063 (* 1 = 0.032063 loss)
I0607 10:28:43.706604  2187 sgd_solver.cpp:106] Iteration 34300, lr = 0.01
I0607 10:29:05.966763  2187 solver.cpp:228] Iteration 34400, loss = 0.0462403
I0607 10:29:05.967031  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0462404 (* 1 = 0.0462404 loss)
I0607 10:29:05.967073  2187 sgd_solver.cpp:106] Iteration 34400, lr = 0.01
I0607 10:29:28.547219  2187 solver.cpp:228] Iteration 34500, loss = 0.0338131
I0607 10:29:28.547335  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0338132 (* 1 = 0.0338132 loss)
I0607 10:29:28.547353  2187 sgd_solver.cpp:106] Iteration 34500, lr = 0.01
I0607 10:29:51.187209  2187 solver.cpp:228] Iteration 34600, loss = 0.0558377
I0607 10:29:51.187582  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0558378 (* 1 = 0.0558378 loss)
I0607 10:29:51.187619  2187 sgd_solver.cpp:106] Iteration 34600, lr = 0.01
I0607 10:30:13.575435  2187 solver.cpp:228] Iteration 34700, loss = 0.0637093
I0607 10:30:13.575544  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0637093 (* 1 = 0.0637093 loss)
I0607 10:30:13.575561  2187 sgd_solver.cpp:106] Iteration 34700, lr = 0.01
I0607 10:30:35.804946  2187 solver.cpp:228] Iteration 34800, loss = 0.0226388
I0607 10:30:35.805233  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0226388 (* 1 = 0.0226388 loss)
I0607 10:30:35.805254  2187 sgd_solver.cpp:106] Iteration 34800, lr = 0.01
I0607 10:30:58.437700  2187 solver.cpp:228] Iteration 34900, loss = 0.0212035
I0607 10:30:58.437808  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0212036 (* 1 = 0.0212036 loss)
I0607 10:30:58.437824  2187 sgd_solver.cpp:106] Iteration 34900, lr = 0.01
I0607 10:31:21.005344  2187 solver.cpp:337] Iteration 35000, Testing net (#0)
I0607 10:31:21.006083  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:31:22.608721  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8785
I0607 10:31:22.778789  2187 solver.cpp:228] Iteration 35000, loss = 0.023969
I0607 10:31:22.778875  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0239691 (* 1 = 0.0239691 loss)
I0607 10:31:22.778892  2187 sgd_solver.cpp:106] Iteration 35000, lr = 0.01
I0607 10:31:45.048679  2187 solver.cpp:228] Iteration 35100, loss = 0.0501815
I0607 10:31:45.048784  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0501816 (* 1 = 0.0501816 loss)
I0607 10:31:45.048801  2187 sgd_solver.cpp:106] Iteration 35100, lr = 0.01
I0607 10:32:07.297037  2187 solver.cpp:228] Iteration 35200, loss = 0.0459417
I0607 10:32:07.297287  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0459417 (* 1 = 0.0459417 loss)
I0607 10:32:07.297304  2187 sgd_solver.cpp:106] Iteration 35200, lr = 0.01
I0607 10:32:30.003103  2187 solver.cpp:228] Iteration 35300, loss = 0.041189
I0607 10:32:30.003211  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0411891 (* 1 = 0.0411891 loss)
I0607 10:32:30.003227  2187 sgd_solver.cpp:106] Iteration 35300, lr = 0.01
I0607 10:32:52.578023  2187 solver.cpp:228] Iteration 35400, loss = 0.0365218
I0607 10:32:52.578341  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0365219 (* 1 = 0.0365219 loss)
I0607 10:32:52.578375  2187 sgd_solver.cpp:106] Iteration 35400, lr = 0.01
I0607 10:33:14.963721  2187 solver.cpp:228] Iteration 35500, loss = 0.0580808
I0607 10:33:14.963855  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0580808 (* 1 = 0.0580808 loss)
I0607 10:33:14.963872  2187 sgd_solver.cpp:106] Iteration 35500, lr = 0.01
I0607 10:33:37.161967  2187 solver.cpp:228] Iteration 35600, loss = 0.0536019
I0607 10:33:37.163728  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0536019 (* 1 = 0.0536019 loss)
I0607 10:33:37.163748  2187 sgd_solver.cpp:106] Iteration 35600, lr = 0.01
I0607 10:33:59.868734  2187 solver.cpp:228] Iteration 35700, loss = 0.0363956
I0607 10:33:59.868859  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0363957 (* 1 = 0.0363957 loss)
I0607 10:33:59.868875  2187 sgd_solver.cpp:106] Iteration 35700, lr = 0.01
I0607 10:34:22.561363  2187 solver.cpp:228] Iteration 35800, loss = 0.0309841
I0607 10:34:22.561568  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0309842 (* 1 = 0.0309842 loss)
I0607 10:34:22.561585  2187 sgd_solver.cpp:106] Iteration 35800, lr = 0.01
I0607 10:34:45.012121  2187 solver.cpp:228] Iteration 35900, loss = 0.0573053
I0607 10:34:45.012208  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0573054 (* 1 = 0.0573054 loss)
I0607 10:34:45.012223  2187 sgd_solver.cpp:106] Iteration 35900, lr = 0.01
I0607 10:35:07.134516  2187 solver.cpp:337] Iteration 36000, Testing net (#0)
I0607 10:35:07.136348  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:35:08.781350  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8747
I0607 10:35:08.965812  2187 solver.cpp:228] Iteration 36000, loss = 0.0602564
I0607 10:35:08.965922  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0602565 (* 1 = 0.0602565 loss)
I0607 10:35:08.965947  2187 sgd_solver.cpp:106] Iteration 36000, lr = 0.01
I0607 10:35:31.707293  2187 solver.cpp:228] Iteration 36100, loss = 0.0215097
I0607 10:35:31.707403  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0215098 (* 1 = 0.0215098 loss)
I0607 10:35:31.707418  2187 sgd_solver.cpp:106] Iteration 36100, lr = 0.01
I0607 10:35:54.236282  2187 solver.cpp:228] Iteration 36200, loss = 0.0499234
I0607 10:35:54.236577  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0499234 (* 1 = 0.0499234 loss)
I0607 10:35:54.236606  2187 sgd_solver.cpp:106] Iteration 36200, lr = 0.01
I0607 10:36:16.592625  2187 solver.cpp:228] Iteration 36300, loss = 0.0566938
I0607 10:36:16.592733  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0566938 (* 1 = 0.0566938 loss)
I0607 10:36:16.592749  2187 sgd_solver.cpp:106] Iteration 36300, lr = 0.01
I0607 10:36:38.949023  2187 solver.cpp:228] Iteration 36400, loss = 0.0550475
I0607 10:36:38.949267  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0550475 (* 1 = 0.0550475 loss)
I0607 10:36:38.949286  2187 sgd_solver.cpp:106] Iteration 36400, lr = 0.01
I0607 10:37:01.694036  2187 solver.cpp:228] Iteration 36500, loss = 0.0287518
I0607 10:37:01.694147  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0287518 (* 1 = 0.0287518 loss)
I0607 10:37:01.694164  2187 sgd_solver.cpp:106] Iteration 36500, lr = 0.01
I0607 10:37:24.257925  2187 solver.cpp:228] Iteration 36600, loss = 0.0407905
I0607 10:37:24.258119  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0407905 (* 1 = 0.0407905 loss)
I0607 10:37:24.258136  2187 sgd_solver.cpp:106] Iteration 36600, lr = 0.01
I0607 10:37:46.654841  2187 solver.cpp:228] Iteration 36700, loss = 0.026441
I0607 10:37:46.654949  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.026441 (* 1 = 0.026441 loss)
I0607 10:37:46.654968  2187 sgd_solver.cpp:106] Iteration 36700, lr = 0.01
I0607 10:38:08.839789  2187 solver.cpp:228] Iteration 36800, loss = 0.0867099
I0607 10:38:08.840049  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0867099 (* 1 = 0.0867099 loss)
I0607 10:38:08.840070  2187 sgd_solver.cpp:106] Iteration 36800, lr = 0.01
I0607 10:38:31.454478  2187 solver.cpp:228] Iteration 36900, loss = 0.0283259
I0607 10:38:31.454593  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0283259 (* 1 = 0.0283259 loss)
I0607 10:38:31.454609  2187 sgd_solver.cpp:106] Iteration 36900, lr = 0.01
I0607 10:38:53.848340  2187 solver.cpp:337] Iteration 37000, Testing net (#0)
I0607 10:38:53.849053  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:38:55.444833  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8749
I0607 10:38:55.621430  2187 solver.cpp:228] Iteration 37000, loss = 0.0621253
I0607 10:38:55.621526  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0621254 (* 1 = 0.0621254 loss)
I0607 10:38:55.621544  2187 sgd_solver.cpp:106] Iteration 37000, lr = 0.01
I0607 10:39:18.020572  2187 solver.cpp:228] Iteration 37100, loss = 0.0334813
I0607 10:39:18.020679  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0334814 (* 1 = 0.0334814 loss)
I0607 10:39:18.020695  2187 sgd_solver.cpp:106] Iteration 37100, lr = 0.01
I0607 10:39:40.362668  2187 solver.cpp:228] Iteration 37200, loss = 0.0216445
I0607 10:39:40.362926  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0216445 (* 1 = 0.0216445 loss)
I0607 10:39:40.362944  2187 sgd_solver.cpp:106] Iteration 37200, lr = 0.01
I0607 10:40:03.010725  2187 solver.cpp:228] Iteration 37300, loss = 0.0381901
I0607 10:40:03.010834  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0381901 (* 1 = 0.0381901 loss)
I0607 10:40:03.010867  2187 sgd_solver.cpp:106] Iteration 37300, lr = 0.01
I0607 10:40:25.568980  2187 solver.cpp:228] Iteration 37400, loss = 0.0275348
I0607 10:40:25.569339  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0275348 (* 1 = 0.0275348 loss)
I0607 10:40:25.569386  2187 sgd_solver.cpp:106] Iteration 37400, lr = 0.01
I0607 10:40:47.960748  2187 solver.cpp:228] Iteration 37500, loss = 0.0383421
I0607 10:40:47.960855  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0383421 (* 1 = 0.0383421 loss)
I0607 10:40:47.960870  2187 sgd_solver.cpp:106] Iteration 37500, lr = 0.01
I0607 10:41:10.269824  2187 solver.cpp:228] Iteration 37600, loss = 0.0134585
I0607 10:41:10.270011  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0134585 (* 1 = 0.0134585 loss)
I0607 10:41:10.270036  2187 sgd_solver.cpp:106] Iteration 37600, lr = 0.01
I0607 10:41:32.846742  2187 solver.cpp:228] Iteration 37700, loss = 0.0419848
I0607 10:41:32.846855  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0419849 (* 1 = 0.0419849 loss)
I0607 10:41:32.846871  2187 sgd_solver.cpp:106] Iteration 37700, lr = 0.01
I0607 10:41:55.356863  2187 solver.cpp:228] Iteration 37800, loss = 0.0264834
I0607 10:41:55.357137  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0264835 (* 1 = 0.0264835 loss)
I0607 10:41:55.357167  2187 sgd_solver.cpp:106] Iteration 37800, lr = 0.01
I0607 10:42:17.789346  2187 solver.cpp:228] Iteration 37900, loss = 0.0795483
I0607 10:42:17.789438  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0795483 (* 1 = 0.0795483 loss)
I0607 10:42:17.789453  2187 sgd_solver.cpp:106] Iteration 37900, lr = 0.01
I0607 10:42:40.112150  2187 solver.cpp:337] Iteration 38000, Testing net (#0)
I0607 10:42:40.112627  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:42:41.679764  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8841
I0607 10:42:41.854532  2187 solver.cpp:228] Iteration 38000, loss = 0.0269886
I0607 10:42:41.854627  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0269886 (* 1 = 0.0269886 loss)
I0607 10:42:41.854645  2187 sgd_solver.cpp:106] Iteration 38000, lr = 0.01
I0607 10:43:04.441285  2187 solver.cpp:228] Iteration 38100, loss = 0.0788472
I0607 10:43:04.441401  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0788472 (* 1 = 0.0788472 loss)
I0607 10:43:04.441417  2187 sgd_solver.cpp:106] Iteration 38100, lr = 0.01
I0607 10:43:26.836187  2187 solver.cpp:228] Iteration 38200, loss = 0.0680108
I0607 10:43:26.836369  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0680108 (* 1 = 0.0680108 loss)
I0607 10:43:26.836386  2187 sgd_solver.cpp:106] Iteration 38200, lr = 0.01
I0607 10:43:49.185083  2187 solver.cpp:228] Iteration 38300, loss = 0.0533434
I0607 10:43:49.185183  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0533434 (* 1 = 0.0533434 loss)
I0607 10:43:49.185197  2187 sgd_solver.cpp:106] Iteration 38300, lr = 0.01
I0607 10:44:11.638420  2187 solver.cpp:228] Iteration 38400, loss = 0.0431669
I0607 10:44:11.642076  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0431669 (* 1 = 0.0431669 loss)
I0607 10:44:11.642117  2187 sgd_solver.cpp:106] Iteration 38400, lr = 0.01
I0607 10:44:34.239629  2187 solver.cpp:228] Iteration 38500, loss = 0.0612659
I0607 10:44:34.239768  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0612659 (* 1 = 0.0612659 loss)
I0607 10:44:34.239785  2187 sgd_solver.cpp:106] Iteration 38500, lr = 0.01
I0607 10:44:56.846024  2187 solver.cpp:228] Iteration 38600, loss = 0.0365169
I0607 10:44:56.846258  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.036517 (* 1 = 0.036517 loss)
I0607 10:44:56.849900  2187 sgd_solver.cpp:106] Iteration 38600, lr = 0.01
I0607 10:45:19.355350  2187 solver.cpp:228] Iteration 38700, loss = 0.0529403
I0607 10:45:19.355437  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0529404 (* 1 = 0.0529404 loss)
I0607 10:45:19.355456  2187 sgd_solver.cpp:106] Iteration 38700, lr = 0.01
I0607 10:45:41.528924  2187 solver.cpp:228] Iteration 38800, loss = 0.0717836
I0607 10:45:41.529247  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0717836 (* 1 = 0.0717836 loss)
I0607 10:45:41.529264  2187 sgd_solver.cpp:106] Iteration 38800, lr = 0.01
I0607 10:46:04.239271  2187 solver.cpp:228] Iteration 38900, loss = 0.051263
I0607 10:46:04.239387  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.051263 (* 1 = 0.051263 loss)
I0607 10:46:04.239404  2187 sgd_solver.cpp:106] Iteration 38900, lr = 0.01
I0607 10:46:26.567545  2187 solver.cpp:337] Iteration 39000, Testing net (#0)
I0607 10:46:26.567976  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:46:28.148890  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8797
I0607 10:46:28.322399  2187 solver.cpp:228] Iteration 39000, loss = 0.0396821
I0607 10:46:28.322484  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0396822 (* 1 = 0.0396822 loss)
I0607 10:46:28.322501  2187 sgd_solver.cpp:106] Iteration 39000, lr = 0.01
I0607 10:46:50.715189  2187 solver.cpp:228] Iteration 39100, loss = 0.0608425
I0607 10:46:50.715292  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0608425 (* 1 = 0.0608425 loss)
I0607 10:46:50.715306  2187 sgd_solver.cpp:106] Iteration 39100, lr = 0.01
I0607 10:47:13.111809  2187 solver.cpp:228] Iteration 39200, loss = 0.0381238
I0607 10:47:13.112035  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0381238 (* 1 = 0.0381238 loss)
I0607 10:47:13.112052  2187 sgd_solver.cpp:106] Iteration 39200, lr = 0.01
I0607 10:47:35.750723  2187 solver.cpp:228] Iteration 39300, loss = 0.0705235
I0607 10:47:35.750830  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0705235 (* 1 = 0.0705235 loss)
I0607 10:47:35.750847  2187 sgd_solver.cpp:106] Iteration 39300, lr = 0.01
I0607 10:47:58.194916  2187 solver.cpp:228] Iteration 39400, loss = 0.0356044
I0607 10:47:58.195205  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0356044 (* 1 = 0.0356044 loss)
I0607 10:47:58.195242  2187 sgd_solver.cpp:106] Iteration 39400, lr = 0.01
I0607 10:48:20.664682  2187 solver.cpp:228] Iteration 39500, loss = 0.033844
I0607 10:48:20.664788  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.033844 (* 1 = 0.033844 loss)
I0607 10:48:20.664803  2187 sgd_solver.cpp:106] Iteration 39500, lr = 0.01
I0607 10:48:43.098640  2187 solver.cpp:228] Iteration 39600, loss = 0.0209109
I0607 10:48:43.098940  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0209109 (* 1 = 0.0209109 loss)
I0607 10:48:43.098971  2187 sgd_solver.cpp:106] Iteration 39600, lr = 0.01
I0607 10:49:05.868515  2187 solver.cpp:228] Iteration 39700, loss = 0.0262598
I0607 10:49:05.868625  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0262598 (* 1 = 0.0262598 loss)
I0607 10:49:05.868641  2187 sgd_solver.cpp:106] Iteration 39700, lr = 0.01
I0607 10:49:28.278790  2187 solver.cpp:228] Iteration 39800, loss = 0.0236287
I0607 10:49:28.280153  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0236287 (* 1 = 0.0236287 loss)
I0607 10:49:28.280169  2187 sgd_solver.cpp:106] Iteration 39800, lr = 0.01
I0607 10:49:50.696821  2187 solver.cpp:228] Iteration 39900, loss = 0.0422045
I0607 10:49:50.696925  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0422045 (* 1 = 0.0422045 loss)
I0607 10:49:50.696941  2187 sgd_solver.cpp:106] Iteration 39900, lr = 0.01
I0607 10:50:12.929329  2187 solver.cpp:454] Snapshotting to binary proto file snapshot/_iter_40000.caffemodel
I0607 10:50:12.941380  2187 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot/_iter_40000.solverstate
I0607 10:50:12.945474  2187 solver.cpp:337] Iteration 40000, Testing net (#0)
I0607 10:50:12.945792  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:50:14.564985  2187 solver.cpp:404]     Test net output #0: accuracy = 0.882
I0607 10:50:14.747668  2187 solver.cpp:228] Iteration 40000, loss = 0.0306874
I0607 10:50:14.747762  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0306874 (* 1 = 0.0306874 loss)
I0607 10:50:14.747776  2187 sgd_solver.cpp:106] Iteration 40000, lr = 0.001
I0607 10:50:37.188568  2187 solver.cpp:228] Iteration 40100, loss = 0.0138853
I0607 10:50:37.188673  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0138853 (* 1 = 0.0138853 loss)
I0607 10:50:37.188688  2187 sgd_solver.cpp:106] Iteration 40100, lr = 0.001
I0607 10:50:59.605895  2187 solver.cpp:228] Iteration 40200, loss = 0.0219951
I0607 10:50:59.606232  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0219951 (* 1 = 0.0219951 loss)
I0607 10:50:59.606278  2187 sgd_solver.cpp:106] Iteration 40200, lr = 0.001
I0607 10:51:22.027788  2187 solver.cpp:228] Iteration 40300, loss = 0.0125828
I0607 10:51:22.027891  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0125828 (* 1 = 0.0125828 loss)
I0607 10:51:22.027907  2187 sgd_solver.cpp:106] Iteration 40300, lr = 0.001
I0607 10:51:44.532666  2187 solver.cpp:228] Iteration 40400, loss = 0.0101583
I0607 10:51:44.532970  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0101583 (* 1 = 0.0101583 loss)
I0607 10:51:44.533016  2187 sgd_solver.cpp:106] Iteration 40400, lr = 0.001
I0607 10:52:07.148442  2187 solver.cpp:228] Iteration 40500, loss = 0.00987965
I0607 10:52:07.148561  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00987964 (* 1 = 0.00987964 loss)
I0607 10:52:07.148577  2187 sgd_solver.cpp:106] Iteration 40500, lr = 0.001
I0607 10:52:29.549391  2187 solver.cpp:228] Iteration 40600, loss = 0.0163792
I0607 10:52:29.549680  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0163792 (* 1 = 0.0163792 loss)
I0607 10:52:29.549721  2187 sgd_solver.cpp:106] Iteration 40600, lr = 0.001
I0607 10:52:51.878772  2187 solver.cpp:228] Iteration 40700, loss = 0.0138188
I0607 10:52:51.878862  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0138188 (* 1 = 0.0138188 loss)
I0607 10:52:51.878877  2187 sgd_solver.cpp:106] Iteration 40700, lr = 0.001
I0607 10:53:15.624172  2187 solver.cpp:228] Iteration 40800, loss = 0.010253
I0607 10:53:15.624441  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.010253 (* 1 = 0.010253 loss)
I0607 10:53:15.624465  2187 sgd_solver.cpp:106] Iteration 40800, lr = 0.001
I0607 10:53:39.904583  2187 solver.cpp:228] Iteration 40900, loss = 0.010748
I0607 10:53:39.904701  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.010748 (* 1 = 0.010748 loss)
I0607 10:53:39.904716  2187 sgd_solver.cpp:106] Iteration 40900, lr = 0.001
I0607 10:54:03.341749  2187 solver.cpp:337] Iteration 41000, Testing net (#0)
I0607 10:54:03.342869  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:54:04.921021  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8995
I0607 10:54:05.094193  2187 solver.cpp:228] Iteration 41000, loss = 0.0074315
I0607 10:54:05.094305  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00743148 (* 1 = 0.00743148 loss)
I0607 10:54:05.094326  2187 sgd_solver.cpp:106] Iteration 41000, lr = 0.001
I0607 10:54:27.802465  2187 solver.cpp:228] Iteration 41100, loss = 0.00660786
I0607 10:54:27.802582  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00660785 (* 1 = 0.00660785 loss)
I0607 10:54:27.802600  2187 sgd_solver.cpp:106] Iteration 41100, lr = 0.001
I0607 10:54:50.349261  2187 solver.cpp:228] Iteration 41200, loss = 0.00939301
I0607 10:54:50.349457  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00939301 (* 1 = 0.00939301 loss)
I0607 10:54:50.349473  2187 sgd_solver.cpp:106] Iteration 41200, lr = 0.001
I0607 10:55:12.724591  2187 solver.cpp:228] Iteration 41300, loss = 0.00603774
I0607 10:55:12.724691  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00603773 (* 1 = 0.00603773 loss)
I0607 10:55:12.724707  2187 sgd_solver.cpp:106] Iteration 41300, lr = 0.001
I0607 10:55:35.069864  2187 solver.cpp:228] Iteration 41400, loss = 0.0072719
I0607 10:55:35.070130  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00727189 (* 1 = 0.00727189 loss)
I0607 10:55:35.070147  2187 sgd_solver.cpp:106] Iteration 41400, lr = 0.001
I0607 10:55:57.428339  2187 solver.cpp:228] Iteration 41500, loss = 0.00412785
I0607 10:55:57.428434  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00412785 (* 1 = 0.00412785 loss)
I0607 10:55:57.428452  2187 sgd_solver.cpp:106] Iteration 41500, lr = 0.001
I0607 10:56:19.711073  2187 solver.cpp:228] Iteration 41600, loss = 0.00860278
I0607 10:56:19.711383  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00860277 (* 1 = 0.00860277 loss)
I0607 10:56:19.711400  2187 sgd_solver.cpp:106] Iteration 41600, lr = 0.001
I0607 10:56:42.080096  2187 solver.cpp:228] Iteration 41700, loss = 0.00361209
I0607 10:56:42.080189  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00361209 (* 1 = 0.00361209 loss)
I0607 10:56:42.080205  2187 sgd_solver.cpp:106] Iteration 41700, lr = 0.001
I0607 10:57:04.471487  2187 solver.cpp:228] Iteration 41800, loss = 0.0124084
I0607 10:57:04.471771  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0124084 (* 1 = 0.0124084 loss)
I0607 10:57:04.471807  2187 sgd_solver.cpp:106] Iteration 41800, lr = 0.001
I0607 10:57:26.883313  2187 solver.cpp:228] Iteration 41900, loss = 0.00576452
I0607 10:57:26.883421  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00576451 (* 1 = 0.00576451 loss)
I0607 10:57:26.883438  2187 sgd_solver.cpp:106] Iteration 41900, lr = 0.001
I0607 10:57:49.234912  2187 solver.cpp:337] Iteration 42000, Testing net (#0)
I0607 10:57:49.235304  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 10:57:50.813344  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9027
I0607 10:57:50.991523  2187 solver.cpp:228] Iteration 42000, loss = 0.00528352
I0607 10:57:50.991616  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00528351 (* 1 = 0.00528351 loss)
I0607 10:57:50.991639  2187 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0607 10:58:13.544059  2187 solver.cpp:228] Iteration 42100, loss = 0.0116718
I0607 10:58:13.544178  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0116718 (* 1 = 0.0116718 loss)
I0607 10:58:13.544195  2187 sgd_solver.cpp:106] Iteration 42100, lr = 0.001
I0607 10:58:36.202898  2187 solver.cpp:228] Iteration 42200, loss = 0.00554517
I0607 10:58:36.203196  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00554516 (* 1 = 0.00554516 loss)
I0607 10:58:36.203234  2187 sgd_solver.cpp:106] Iteration 42200, lr = 0.001
I0607 10:58:58.750907  2187 solver.cpp:228] Iteration 42300, loss = 0.00686135
I0607 10:58:58.751024  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00686134 (* 1 = 0.00686134 loss)
I0607 10:58:58.751041  2187 sgd_solver.cpp:106] Iteration 42300, lr = 0.001
I0607 10:59:21.429932  2187 solver.cpp:228] Iteration 42400, loss = 0.00809649
I0607 10:59:21.430207  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00809649 (* 1 = 0.00809649 loss)
I0607 10:59:21.430243  2187 sgd_solver.cpp:106] Iteration 42400, lr = 0.001
I0607 10:59:43.965921  2187 solver.cpp:228] Iteration 42500, loss = 0.00587597
I0607 10:59:43.966037  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00587597 (* 1 = 0.00587597 loss)
I0607 10:59:43.966053  2187 sgd_solver.cpp:106] Iteration 42500, lr = 0.001
I0607 11:00:06.644543  2187 solver.cpp:228] Iteration 42600, loss = 0.00656196
I0607 11:00:06.644798  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00656195 (* 1 = 0.00656195 loss)
I0607 11:00:06.644842  2187 sgd_solver.cpp:106] Iteration 42600, lr = 0.001
I0607 11:00:29.161782  2187 solver.cpp:228] Iteration 42700, loss = 0.00393333
I0607 11:00:29.161892  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00393332 (* 1 = 0.00393332 loss)
I0607 11:00:29.161909  2187 sgd_solver.cpp:106] Iteration 42700, lr = 0.001
I0607 11:00:51.673861  2187 solver.cpp:228] Iteration 42800, loss = 0.00590867
I0607 11:00:51.674119  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00590866 (* 1 = 0.00590866 loss)
I0607 11:00:51.674140  2187 sgd_solver.cpp:106] Iteration 42800, lr = 0.001
I0607 11:01:15.399483  2187 solver.cpp:228] Iteration 42900, loss = 0.00559744
I0607 11:01:15.399595  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00559743 (* 1 = 0.00559743 loss)
I0607 11:01:15.399612  2187 sgd_solver.cpp:106] Iteration 42900, lr = 0.001
I0607 11:01:38.623908  2187 solver.cpp:337] Iteration 43000, Testing net (#0)
I0607 11:01:38.624862  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:01:40.327119  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9001
I0607 11:01:40.504571  2187 solver.cpp:228] Iteration 43000, loss = 0.00609854
I0607 11:01:40.504714  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00609853 (* 1 = 0.00609853 loss)
I0607 11:01:40.504737  2187 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I0607 11:02:02.037953  2187 solver.cpp:228] Iteration 43100, loss = 0.00325107
I0607 11:02:02.038050  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00325106 (* 1 = 0.00325106 loss)
I0607 11:02:02.038065  2187 sgd_solver.cpp:106] Iteration 43100, lr = 0.001
I0607 11:02:22.609115  2187 solver.cpp:228] Iteration 43200, loss = 0.00649759
I0607 11:02:22.609593  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00649758 (* 1 = 0.00649758 loss)
I0607 11:02:22.609618  2187 sgd_solver.cpp:106] Iteration 43200, lr = 0.001
I0607 11:02:45.656668  2187 solver.cpp:228] Iteration 43300, loss = 0.00355839
I0607 11:02:45.656780  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00355838 (* 1 = 0.00355838 loss)
I0607 11:02:45.656795  2187 sgd_solver.cpp:106] Iteration 43300, lr = 0.001
I0607 11:03:08.249421  2187 solver.cpp:228] Iteration 43400, loss = 0.00535355
I0607 11:03:08.249723  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00535354 (* 1 = 0.00535354 loss)
I0607 11:03:08.249764  2187 sgd_solver.cpp:106] Iteration 43400, lr = 0.001
I0607 11:03:30.865427  2187 solver.cpp:228] Iteration 43500, loss = 0.00385765
I0607 11:03:30.865553  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00385764 (* 1 = 0.00385764 loss)
I0607 11:03:30.865571  2187 sgd_solver.cpp:106] Iteration 43500, lr = 0.001
I0607 11:03:53.476346  2187 solver.cpp:228] Iteration 43600, loss = 0.00323965
I0607 11:03:53.476649  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00323964 (* 1 = 0.00323964 loss)
I0607 11:03:53.476702  2187 sgd_solver.cpp:106] Iteration 43600, lr = 0.001
I0607 11:04:15.776944  2187 solver.cpp:228] Iteration 43700, loss = 0.00515099
I0607 11:04:15.777051  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00515098 (* 1 = 0.00515098 loss)
I0607 11:04:15.777067  2187 sgd_solver.cpp:106] Iteration 43700, lr = 0.001
I0607 11:04:38.004518  2187 solver.cpp:228] Iteration 43800, loss = 0.00251188
I0607 11:04:38.004787  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00251187 (* 1 = 0.00251187 loss)
I0607 11:04:38.004824  2187 sgd_solver.cpp:106] Iteration 43800, lr = 0.001
I0607 11:05:00.384629  2187 solver.cpp:228] Iteration 43900, loss = 0.00402946
I0607 11:05:00.384748  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00402945 (* 1 = 0.00402945 loss)
I0607 11:05:00.384766  2187 sgd_solver.cpp:106] Iteration 43900, lr = 0.001
I0607 11:05:22.463693  2187 solver.cpp:337] Iteration 44000, Testing net (#0)
I0607 11:05:22.464694  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:05:24.052639  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9013
I0607 11:05:24.232728  2187 solver.cpp:228] Iteration 44000, loss = 0.00431831
I0607 11:05:24.232825  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0043183 (* 1 = 0.0043183 loss)
I0607 11:05:24.232843  2187 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I0607 11:05:46.546106  2187 solver.cpp:228] Iteration 44100, loss = 0.00261592
I0607 11:05:46.546241  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00261591 (* 1 = 0.00261591 loss)
I0607 11:05:46.546259  2187 sgd_solver.cpp:106] Iteration 44100, lr = 0.001
I0607 11:06:08.730515  2187 solver.cpp:228] Iteration 44200, loss = 0.00406601
I0607 11:06:08.731943  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.004066 (* 1 = 0.004066 loss)
I0607 11:06:08.731986  2187 sgd_solver.cpp:106] Iteration 44200, lr = 0.001
I0607 11:06:31.193825  2187 solver.cpp:228] Iteration 44300, loss = 0.00504795
I0607 11:06:31.193990  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00504794 (* 1 = 0.00504794 loss)
I0607 11:06:31.194023  2187 sgd_solver.cpp:106] Iteration 44300, lr = 0.001
I0607 11:06:53.631750  2187 solver.cpp:228] Iteration 44400, loss = 0.00544191
I0607 11:06:53.631963  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0054419 (* 1 = 0.0054419 loss)
I0607 11:06:53.631981  2187 sgd_solver.cpp:106] Iteration 44400, lr = 0.001
I0607 11:07:16.073421  2187 solver.cpp:228] Iteration 44500, loss = 0.00515921
I0607 11:07:16.073528  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0051592 (* 1 = 0.0051592 loss)
I0607 11:07:16.073544  2187 sgd_solver.cpp:106] Iteration 44500, lr = 0.001
I0607 11:07:38.538764  2187 solver.cpp:228] Iteration 44600, loss = 0.00217765
I0607 11:07:38.539037  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00217764 (* 1 = 0.00217764 loss)
I0607 11:07:38.539083  2187 sgd_solver.cpp:106] Iteration 44600, lr = 0.001
I0607 11:08:00.844432  2187 solver.cpp:228] Iteration 44700, loss = 0.00526024
I0607 11:08:00.844549  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00526022 (* 1 = 0.00526022 loss)
I0607 11:08:00.844566  2187 sgd_solver.cpp:106] Iteration 44700, lr = 0.001
I0607 11:08:23.198186  2187 solver.cpp:228] Iteration 44800, loss = 0.0103651
I0607 11:08:23.198505  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0103651 (* 1 = 0.0103651 loss)
I0607 11:08:23.198554  2187 sgd_solver.cpp:106] Iteration 44800, lr = 0.001
I0607 11:08:44.570626  2187 solver.cpp:228] Iteration 44900, loss = 0.00568873
I0607 11:08:44.570721  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00568871 (* 1 = 0.00568871 loss)
I0607 11:08:44.570739  2187 sgd_solver.cpp:106] Iteration 44900, lr = 0.001
I0607 11:09:05.626837  2187 solver.cpp:337] Iteration 45000, Testing net (#0)
I0607 11:09:05.627560  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:09:07.197443  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8997
I0607 11:09:07.377269  2187 solver.cpp:228] Iteration 45000, loss = 0.00384676
I0607 11:09:07.377401  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00384675 (* 1 = 0.00384675 loss)
I0607 11:09:07.377431  2187 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0607 11:09:29.561993  2187 solver.cpp:228] Iteration 45100, loss = 0.00450258
I0607 11:09:29.562116  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00450256 (* 1 = 0.00450256 loss)
I0607 11:09:29.562152  2187 sgd_solver.cpp:106] Iteration 45100, lr = 0.001
I0607 11:09:51.721302  2187 solver.cpp:228] Iteration 45200, loss = 0.00294573
I0607 11:09:51.721621  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00294572 (* 1 = 0.00294572 loss)
I0607 11:09:51.721640  2187 sgd_solver.cpp:106] Iteration 45200, lr = 0.001
I0607 11:10:14.177688  2187 solver.cpp:228] Iteration 45300, loss = 0.0027866
I0607 11:10:14.177800  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00278659 (* 1 = 0.00278659 loss)
I0607 11:10:14.177816  2187 sgd_solver.cpp:106] Iteration 45300, lr = 0.001
I0607 11:10:36.482710  2187 solver.cpp:228] Iteration 45400, loss = 0.00468263
I0607 11:10:36.482969  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00468261 (* 1 = 0.00468261 loss)
I0607 11:10:36.482988  2187 sgd_solver.cpp:106] Iteration 45400, lr = 0.001
I0607 11:10:58.920423  2187 solver.cpp:228] Iteration 45500, loss = 0.00506067
I0607 11:10:58.920590  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00506066 (* 1 = 0.00506066 loss)
I0607 11:10:58.920617  2187 sgd_solver.cpp:106] Iteration 45500, lr = 0.001
I0607 11:11:21.405992  2187 solver.cpp:228] Iteration 45600, loss = 0.00286214
I0607 11:11:21.406322  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00286212 (* 1 = 0.00286212 loss)
I0607 11:11:21.406345  2187 sgd_solver.cpp:106] Iteration 45600, lr = 0.001
I0607 11:11:43.658083  2187 solver.cpp:228] Iteration 45700, loss = 0.00307997
I0607 11:11:43.658187  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00307995 (* 1 = 0.00307995 loss)
I0607 11:11:43.658203  2187 sgd_solver.cpp:106] Iteration 45700, lr = 0.001
I0607 11:12:05.645110  2187 solver.cpp:228] Iteration 45800, loss = 0.00500332
I0607 11:12:05.645406  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00500331 (* 1 = 0.00500331 loss)
I0607 11:12:05.645444  2187 sgd_solver.cpp:106] Iteration 45800, lr = 0.001
I0607 11:12:27.957746  2187 solver.cpp:228] Iteration 45900, loss = 0.00669554
I0607 11:12:27.957841  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00669553 (* 1 = 0.00669553 loss)
I0607 11:12:27.957855  2187 sgd_solver.cpp:106] Iteration 45900, lr = 0.001
I0607 11:12:50.249850  2187 solver.cpp:337] Iteration 46000, Testing net (#0)
I0607 11:12:50.250488  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:12:51.829187  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8985
I0607 11:12:52.007325  2187 solver.cpp:228] Iteration 46000, loss = 0.00208035
I0607 11:12:52.007419  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00208033 (* 1 = 0.00208033 loss)
I0607 11:12:52.007437  2187 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I0607 11:13:14.329686  2187 solver.cpp:228] Iteration 46100, loss = 0.00426483
I0607 11:13:14.329783  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00426482 (* 1 = 0.00426482 loss)
I0607 11:13:14.329797  2187 sgd_solver.cpp:106] Iteration 46100, lr = 0.001
I0607 11:13:36.523438  2187 solver.cpp:228] Iteration 46200, loss = 0.00259389
I0607 11:13:36.523749  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00259388 (* 1 = 0.00259388 loss)
I0607 11:13:36.523790  2187 sgd_solver.cpp:106] Iteration 46200, lr = 0.001
I0607 11:13:59.063133  2187 solver.cpp:228] Iteration 46300, loss = 0.00264886
I0607 11:13:59.063241  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00264885 (* 1 = 0.00264885 loss)
I0607 11:13:59.063257  2187 sgd_solver.cpp:106] Iteration 46300, lr = 0.001
I0607 11:14:21.490000  2187 solver.cpp:228] Iteration 46400, loss = 0.00309037
I0607 11:14:21.490268  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00309036 (* 1 = 0.00309036 loss)
I0607 11:14:21.490299  2187 sgd_solver.cpp:106] Iteration 46400, lr = 0.001
I0607 11:14:43.899737  2187 solver.cpp:228] Iteration 46500, loss = 0.00308078
I0607 11:14:43.899863  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00308076 (* 1 = 0.00308076 loss)
I0607 11:14:43.899878  2187 sgd_solver.cpp:106] Iteration 46500, lr = 0.001
I0607 11:15:06.197212  2187 solver.cpp:228] Iteration 46600, loss = 0.00548875
I0607 11:15:06.197510  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00548873 (* 1 = 0.00548873 loss)
I0607 11:15:06.197549  2187 sgd_solver.cpp:106] Iteration 46600, lr = 0.001
I0607 11:15:28.750607  2187 solver.cpp:228] Iteration 46700, loss = 0.00305632
I0607 11:15:28.750710  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0030563 (* 1 = 0.0030563 loss)
I0607 11:15:28.750726  2187 sgd_solver.cpp:106] Iteration 46700, lr = 0.001
I0607 11:15:51.406435  2187 solver.cpp:228] Iteration 46800, loss = 0.00275838
I0607 11:15:51.406766  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00275837 (* 1 = 0.00275837 loss)
I0607 11:15:51.406810  2187 sgd_solver.cpp:106] Iteration 46800, lr = 0.001
I0607 11:16:13.639138  2187 solver.cpp:228] Iteration 46900, loss = 0.00241467
I0607 11:16:13.639253  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00241465 (* 1 = 0.00241465 loss)
I0607 11:16:13.639271  2187 sgd_solver.cpp:106] Iteration 46900, lr = 0.001
I0607 11:16:35.741328  2187 solver.cpp:337] Iteration 47000, Testing net (#0)
I0607 11:16:35.742377  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:16:37.305536  2187 solver.cpp:404]     Test net output #0: accuracy = 0.901
I0607 11:16:37.479423  2187 solver.cpp:228] Iteration 47000, loss = 0.00292335
I0607 11:16:37.479496  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00292334 (* 1 = 0.00292334 loss)
I0607 11:16:37.479512  2187 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I0607 11:17:00.178416  2187 solver.cpp:228] Iteration 47100, loss = 0.0029777
I0607 11:17:00.178532  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00297768 (* 1 = 0.00297768 loss)
I0607 11:17:00.178549  2187 sgd_solver.cpp:106] Iteration 47100, lr = 0.001
I0607 11:17:22.747644  2187 solver.cpp:228] Iteration 47200, loss = 0.00473908
I0607 11:17:22.747892  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00473907 (* 1 = 0.00473907 loss)
I0607 11:17:22.747934  2187 sgd_solver.cpp:106] Iteration 47200, lr = 0.001
I0607 11:17:45.085443  2187 solver.cpp:228] Iteration 47300, loss = 0.00280545
I0607 11:17:45.085553  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00280544 (* 1 = 0.00280544 loss)
I0607 11:17:45.085571  2187 sgd_solver.cpp:106] Iteration 47300, lr = 0.001
I0607 11:18:07.310318  2187 solver.cpp:228] Iteration 47400, loss = 0.00251689
I0607 11:18:07.310595  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00251687 (* 1 = 0.00251687 loss)
I0607 11:18:07.310639  2187 sgd_solver.cpp:106] Iteration 47400, lr = 0.001
I0607 11:18:29.895212  2187 solver.cpp:228] Iteration 47500, loss = 0.00368896
I0607 11:18:29.895362  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00368894 (* 1 = 0.00368894 loss)
I0607 11:18:29.895386  2187 sgd_solver.cpp:106] Iteration 47500, lr = 0.001
I0607 11:18:52.520792  2187 solver.cpp:228] Iteration 47600, loss = 0.00616982
I0607 11:18:52.521170  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00616981 (* 1 = 0.00616981 loss)
I0607 11:18:52.521201  2187 sgd_solver.cpp:106] Iteration 47600, lr = 0.001
I0607 11:19:15.123780  2187 solver.cpp:228] Iteration 47700, loss = 0.00300277
I0607 11:19:15.123878  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00300275 (* 1 = 0.00300275 loss)
I0607 11:19:15.123893  2187 sgd_solver.cpp:106] Iteration 47700, lr = 0.001
I0607 11:19:37.438443  2187 solver.cpp:228] Iteration 47800, loss = 0.00424668
I0607 11:19:37.438724  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00424666 (* 1 = 0.00424666 loss)
I0607 11:19:37.438760  2187 sgd_solver.cpp:106] Iteration 47800, lr = 0.001
I0607 11:19:59.780845  2187 solver.cpp:228] Iteration 47900, loss = 0.00513025
I0607 11:19:59.780947  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00513023 (* 1 = 0.00513023 loss)
I0607 11:19:59.780963  2187 sgd_solver.cpp:106] Iteration 47900, lr = 0.001
I0607 11:20:21.014271  2187 solver.cpp:337] Iteration 48000, Testing net (#0)
I0607 11:20:21.014647  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:20:22.481894  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9022
I0607 11:20:22.656910  2187 solver.cpp:228] Iteration 48000, loss = 0.00227888
I0607 11:20:22.656996  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00227886 (* 1 = 0.00227886 loss)
I0607 11:20:22.657013  2187 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0607 11:20:45.235983  2187 solver.cpp:228] Iteration 48100, loss = 0.00473684
I0607 11:20:45.236093  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00473682 (* 1 = 0.00473682 loss)
I0607 11:20:45.236107  2187 sgd_solver.cpp:106] Iteration 48100, lr = 0.001
I0607 11:21:07.669486  2187 solver.cpp:228] Iteration 48200, loss = 0.00695221
I0607 11:21:07.669833  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00695219 (* 1 = 0.00695219 loss)
I0607 11:21:07.669878  2187 sgd_solver.cpp:106] Iteration 48200, lr = 0.001
I0607 11:21:30.017071  2187 solver.cpp:228] Iteration 48300, loss = 0.00279433
I0607 11:21:30.017174  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00279431 (* 1 = 0.00279431 loss)
I0607 11:21:30.017189  2187 sgd_solver.cpp:106] Iteration 48300, lr = 0.001
I0607 11:21:52.468813  2187 solver.cpp:228] Iteration 48400, loss = 0.00411482
I0607 11:21:52.469080  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00411481 (* 1 = 0.00411481 loss)
I0607 11:21:52.469141  2187 sgd_solver.cpp:106] Iteration 48400, lr = 0.001
I0607 11:22:15.236688  2187 solver.cpp:228] Iteration 48500, loss = 0.00295894
I0607 11:22:15.236811  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00295893 (* 1 = 0.00295893 loss)
I0607 11:22:15.236827  2187 sgd_solver.cpp:106] Iteration 48500, lr = 0.001
I0607 11:22:37.699264  2187 solver.cpp:228] Iteration 48600, loss = 0.00371615
I0607 11:22:37.699432  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00371613 (* 1 = 0.00371613 loss)
I0607 11:22:37.699471  2187 sgd_solver.cpp:106] Iteration 48600, lr = 0.001
I0607 11:23:00.075532  2187 solver.cpp:228] Iteration 48700, loss = 0.00351535
I0607 11:23:00.075636  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00351533 (* 1 = 0.00351533 loss)
I0607 11:23:00.075652  2187 sgd_solver.cpp:106] Iteration 48700, lr = 0.001
I0607 11:23:22.415503  2187 solver.cpp:228] Iteration 48800, loss = 0.00252738
I0607 11:23:22.415683  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00252737 (* 1 = 0.00252737 loss)
I0607 11:23:22.415701  2187 sgd_solver.cpp:106] Iteration 48800, lr = 0.001
I0607 11:23:45.847669  2187 solver.cpp:228] Iteration 48900, loss = 0.00178883
I0607 11:23:45.847787  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00178881 (* 1 = 0.00178881 loss)
I0607 11:23:45.847805  2187 sgd_solver.cpp:106] Iteration 48900, lr = 0.001
I0607 11:24:08.245254  2187 solver.cpp:337] Iteration 49000, Testing net (#0)
I0607 11:24:08.245784  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:24:09.821388  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8986
I0607 11:24:09.997310  2187 solver.cpp:228] Iteration 49000, loss = 0.00331547
I0607 11:24:09.997401  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00331546 (* 1 = 0.00331546 loss)
I0607 11:24:09.997421  2187 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I0607 11:24:32.343502  2187 solver.cpp:228] Iteration 49100, loss = 0.00548039
I0607 11:24:32.343608  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00548038 (* 1 = 0.00548038 loss)
I0607 11:24:32.343624  2187 sgd_solver.cpp:106] Iteration 49100, lr = 0.001
I0607 11:24:54.719560  2187 solver.cpp:228] Iteration 49200, loss = 0.00322273
I0607 11:24:54.719816  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00322272 (* 1 = 0.00322272 loss)
I0607 11:24:54.719842  2187 sgd_solver.cpp:106] Iteration 49200, lr = 0.001
I0607 11:25:17.625922  2187 solver.cpp:228] Iteration 49300, loss = 0.00341115
I0607 11:25:17.626022  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00341114 (* 1 = 0.00341114 loss)
I0607 11:25:17.626039  2187 sgd_solver.cpp:106] Iteration 49300, lr = 0.001
I0607 11:25:39.312364  2187 solver.cpp:228] Iteration 49400, loss = 0.00297333
I0607 11:25:39.312672  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00297332 (* 1 = 0.00297332 loss)
I0607 11:25:39.312717  2187 sgd_solver.cpp:106] Iteration 49400, lr = 0.001
I0607 11:26:02.074548  2187 solver.cpp:228] Iteration 49500, loss = 0.00290316
I0607 11:26:02.074648  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00290314 (* 1 = 0.00290314 loss)
I0607 11:26:02.074683  2187 sgd_solver.cpp:106] Iteration 49500, lr = 0.001
I0607 11:26:24.552573  2187 solver.cpp:228] Iteration 49600, loss = 0.00479568
I0607 11:26:24.552932  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00479566 (* 1 = 0.00479566 loss)
I0607 11:26:24.552989  2187 sgd_solver.cpp:106] Iteration 49600, lr = 0.001
I0607 11:26:47.080117  2187 solver.cpp:228] Iteration 49700, loss = 0.00266169
I0607 11:26:47.080252  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00266167 (* 1 = 0.00266167 loss)
I0607 11:26:47.080268  2187 sgd_solver.cpp:106] Iteration 49700, lr = 0.001
I0607 11:27:09.591897  2187 solver.cpp:228] Iteration 49800, loss = 0.0041433
I0607 11:27:09.592173  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00414328 (* 1 = 0.00414328 loss)
I0607 11:27:09.592213  2187 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0607 11:27:31.986136  2187 solver.cpp:228] Iteration 49900, loss = 0.00350755
I0607 11:27:31.986258  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00350754 (* 1 = 0.00350754 loss)
I0607 11:27:31.986280  2187 sgd_solver.cpp:106] Iteration 49900, lr = 0.001
I0607 11:27:54.180014  2187 solver.cpp:454] Snapshotting to binary proto file snapshot/_iter_50000.caffemodel
I0607 11:27:54.194825  2187 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot/_iter_50000.solverstate
I0607 11:27:54.199146  2187 solver.cpp:337] Iteration 50000, Testing net (#0)
I0607 11:27:54.200229  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:27:55.773305  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9039
I0607 11:27:55.953217  2187 solver.cpp:228] Iteration 50000, loss = 0.00306478
I0607 11:27:55.953304  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00306477 (* 1 = 0.00306477 loss)
I0607 11:27:55.953318  2187 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0607 11:28:18.376458  2187 solver.cpp:228] Iteration 50100, loss = 0.00338184
I0607 11:28:18.376560  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00338183 (* 1 = 0.00338183 loss)
I0607 11:28:18.376576  2187 sgd_solver.cpp:106] Iteration 50100, lr = 0.001
I0607 11:28:40.641705  2187 solver.cpp:228] Iteration 50200, loss = 0.00381561
I0607 11:28:40.641983  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0038156 (* 1 = 0.0038156 loss)
I0607 11:28:40.642019  2187 sgd_solver.cpp:106] Iteration 50200, lr = 0.001
I0607 11:29:02.740795  2187 solver.cpp:228] Iteration 50300, loss = 0.00333036
I0607 11:29:02.740983  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00333035 (* 1 = 0.00333035 loss)
I0607 11:29:02.741041  2187 sgd_solver.cpp:106] Iteration 50300, lr = 0.001
I0607 11:29:25.106896  2187 solver.cpp:228] Iteration 50400, loss = 0.00487258
I0607 11:29:25.107820  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00487256 (* 1 = 0.00487256 loss)
I0607 11:29:25.107838  2187 sgd_solver.cpp:106] Iteration 50400, lr = 0.001
I0607 11:29:47.443261  2187 solver.cpp:228] Iteration 50500, loss = 0.00293452
I0607 11:29:47.443359  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00293451 (* 1 = 0.00293451 loss)
I0607 11:29:47.443375  2187 sgd_solver.cpp:106] Iteration 50500, lr = 0.001
I0607 11:30:09.802786  2187 solver.cpp:228] Iteration 50600, loss = 0.0023394
I0607 11:30:09.803110  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00233939 (* 1 = 0.00233939 loss)
I0607 11:30:09.803150  2187 sgd_solver.cpp:106] Iteration 50600, lr = 0.001
I0607 11:30:32.062491  2187 solver.cpp:228] Iteration 50700, loss = 0.00315114
I0607 11:30:32.062628  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00315113 (* 1 = 0.00315113 loss)
I0607 11:30:32.062649  2187 sgd_solver.cpp:106] Iteration 50700, lr = 0.001
I0607 11:30:54.251374  2187 solver.cpp:228] Iteration 50800, loss = 0.00380712
I0607 11:30:54.251685  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00380711 (* 1 = 0.00380711 loss)
I0607 11:30:54.251718  2187 sgd_solver.cpp:106] Iteration 50800, lr = 0.001
I0607 11:31:16.662396  2187 solver.cpp:228] Iteration 50900, loss = 0.00236088
I0607 11:31:16.662511  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00236087 (* 1 = 0.00236087 loss)
I0607 11:31:16.662529  2187 sgd_solver.cpp:106] Iteration 50900, lr = 0.001
I0607 11:31:38.861980  2187 solver.cpp:337] Iteration 51000, Testing net (#0)
I0607 11:31:38.862606  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:31:40.425046  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9012
I0607 11:31:40.600251  2187 solver.cpp:228] Iteration 51000, loss = 0.00208786
I0607 11:31:40.600342  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00208785 (* 1 = 0.00208785 loss)
I0607 11:31:40.600360  2187 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0607 11:32:02.217407  2187 solver.cpp:228] Iteration 51100, loss = 0.00404254
I0607 11:32:02.217520  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00404253 (* 1 = 0.00404253 loss)
I0607 11:32:02.217535  2187 sgd_solver.cpp:106] Iteration 51100, lr = 0.001
I0607 11:32:24.612211  2187 solver.cpp:228] Iteration 51200, loss = 0.00344974
I0607 11:32:24.612521  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00344973 (* 1 = 0.00344973 loss)
I0607 11:32:24.612556  2187 sgd_solver.cpp:106] Iteration 51200, lr = 0.001
I0607 11:32:47.004412  2187 solver.cpp:228] Iteration 51300, loss = 0.00349999
I0607 11:32:47.004526  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00349998 (* 1 = 0.00349998 loss)
I0607 11:32:47.004542  2187 sgd_solver.cpp:106] Iteration 51300, lr = 0.001
I0607 11:33:09.515523  2187 solver.cpp:228] Iteration 51400, loss = 0.00533341
I0607 11:33:09.515714  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00533339 (* 1 = 0.00533339 loss)
I0607 11:33:09.515733  2187 sgd_solver.cpp:106] Iteration 51400, lr = 0.001
I0607 11:33:31.889778  2187 solver.cpp:228] Iteration 51500, loss = 0.00237289
I0607 11:33:31.889889  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00237287 (* 1 = 0.00237287 loss)
I0607 11:33:31.889904  2187 sgd_solver.cpp:106] Iteration 51500, lr = 0.001
I0607 11:33:54.347661  2187 solver.cpp:228] Iteration 51600, loss = 0.00432184
I0607 11:33:54.347796  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00432183 (* 1 = 0.00432183 loss)
I0607 11:33:54.347812  2187 sgd_solver.cpp:106] Iteration 51600, lr = 0.001
I0607 11:34:16.983566  2187 solver.cpp:228] Iteration 51700, loss = 0.00261236
I0607 11:34:16.983672  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00261235 (* 1 = 0.00261235 loss)
I0607 11:34:16.983688  2187 sgd_solver.cpp:106] Iteration 51700, lr = 0.001
I0607 11:34:39.533781  2187 solver.cpp:228] Iteration 51800, loss = 0.00361857
I0607 11:34:39.534093  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00361856 (* 1 = 0.00361856 loss)
I0607 11:34:39.534138  2187 sgd_solver.cpp:106] Iteration 51800, lr = 0.001
I0607 11:35:02.035678  2187 solver.cpp:228] Iteration 51900, loss = 0.00361327
I0607 11:35:02.035789  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00361326 (* 1 = 0.00361326 loss)
I0607 11:35:02.035806  2187 sgd_solver.cpp:106] Iteration 51900, lr = 0.001
I0607 11:35:24.433553  2187 solver.cpp:337] Iteration 52000, Testing net (#0)
I0607 11:35:24.434165  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:35:25.991471  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9022
I0607 11:35:26.169415  2187 solver.cpp:228] Iteration 52000, loss = 0.00365483
I0607 11:35:26.169502  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00365481 (* 1 = 0.00365481 loss)
I0607 11:35:26.169515  2187 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I0607 11:35:48.591704  2187 solver.cpp:228] Iteration 52100, loss = 0.00277721
I0607 11:35:48.591807  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00277719 (* 1 = 0.00277719 loss)
I0607 11:35:48.591822  2187 sgd_solver.cpp:106] Iteration 52100, lr = 0.001
I0607 11:36:11.028502  2187 solver.cpp:228] Iteration 52200, loss = 0.0034852
I0607 11:36:11.028843  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00348519 (* 1 = 0.00348519 loss)
I0607 11:36:11.028879  2187 sgd_solver.cpp:106] Iteration 52200, lr = 0.001
I0607 11:36:33.447959  2187 solver.cpp:228] Iteration 52300, loss = 0.00304428
I0607 11:36:33.448061  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00304427 (* 1 = 0.00304427 loss)
I0607 11:36:33.448076  2187 sgd_solver.cpp:106] Iteration 52300, lr = 0.001
I0607 11:36:55.886315  2187 solver.cpp:228] Iteration 52400, loss = 0.00326363
I0607 11:36:55.886618  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00326362 (* 1 = 0.00326362 loss)
I0607 11:36:55.886663  2187 sgd_solver.cpp:106] Iteration 52400, lr = 0.001
I0607 11:37:15.998005  2187 solver.cpp:228] Iteration 52500, loss = 0.00343321
I0607 11:37:15.998095  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0034332 (* 1 = 0.0034332 loss)
I0607 11:37:15.998111  2187 sgd_solver.cpp:106] Iteration 52500, lr = 0.001
I0607 11:37:37.602527  2187 solver.cpp:228] Iteration 52600, loss = 0.002188
I0607 11:37:37.602756  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00218798 (* 1 = 0.00218798 loss)
I0607 11:37:37.602777  2187 sgd_solver.cpp:106] Iteration 52600, lr = 0.001
I0607 11:38:01.528735  2187 solver.cpp:228] Iteration 52700, loss = 0.00426865
I0607 11:38:01.528888  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00426864 (* 1 = 0.00426864 loss)
I0607 11:38:01.528908  2187 sgd_solver.cpp:106] Iteration 52700, lr = 0.001
I0607 11:38:25.172590  2187 solver.cpp:228] Iteration 52800, loss = 0.00295923
I0607 11:38:25.172921  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00295922 (* 1 = 0.00295922 loss)
I0607 11:38:25.172966  2187 sgd_solver.cpp:106] Iteration 52800, lr = 0.001
I0607 11:38:48.107944  2187 solver.cpp:228] Iteration 52900, loss = 0.00286661
I0607 11:38:48.108052  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0028666 (* 1 = 0.0028666 loss)
I0607 11:38:48.108068  2187 sgd_solver.cpp:106] Iteration 52900, lr = 0.001
I0607 11:39:10.784605  2187 solver.cpp:337] Iteration 53000, Testing net (#0)
I0607 11:39:10.785277  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:39:12.369513  2187 solver.cpp:404]     Test net output #0: accuracy = 0.902
I0607 11:39:12.543346  2187 solver.cpp:228] Iteration 53000, loss = 0.00608134
I0607 11:39:12.543445  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00608133 (* 1 = 0.00608133 loss)
I0607 11:39:12.543465  2187 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I0607 11:39:35.014413  2187 solver.cpp:228] Iteration 53100, loss = 0.00342129
I0607 11:39:35.014519  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00342128 (* 1 = 0.00342128 loss)
I0607 11:39:35.014538  2187 sgd_solver.cpp:106] Iteration 53100, lr = 0.001
I0607 11:39:57.455195  2187 solver.cpp:228] Iteration 53200, loss = 0.00196895
I0607 11:39:57.455422  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00196894 (* 1 = 0.00196894 loss)
I0607 11:39:57.455441  2187 sgd_solver.cpp:106] Iteration 53200, lr = 0.001
I0607 11:40:19.789176  2187 solver.cpp:228] Iteration 53300, loss = 0.00277845
I0607 11:40:19.789314  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00277844 (* 1 = 0.00277844 loss)
I0607 11:40:19.789336  2187 sgd_solver.cpp:106] Iteration 53300, lr = 0.001
I0607 11:40:42.092119  2187 solver.cpp:228] Iteration 53400, loss = 0.00290956
I0607 11:40:42.098093  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00290955 (* 1 = 0.00290955 loss)
I0607 11:40:42.098131  2187 sgd_solver.cpp:106] Iteration 53400, lr = 0.001
I0607 11:41:04.355334  2187 solver.cpp:228] Iteration 53500, loss = 0.00227722
I0607 11:41:04.355444  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00227721 (* 1 = 0.00227721 loss)
I0607 11:41:04.355460  2187 sgd_solver.cpp:106] Iteration 53500, lr = 0.001
I0607 11:41:26.784657  2187 solver.cpp:228] Iteration 53600, loss = 0.00211172
I0607 11:41:26.784991  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00211171 (* 1 = 0.00211171 loss)
I0607 11:41:26.785014  2187 sgd_solver.cpp:106] Iteration 53600, lr = 0.001
I0607 11:41:49.166538  2187 solver.cpp:228] Iteration 53700, loss = 0.0028786
I0607 11:41:49.166651  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00287858 (* 1 = 0.00287858 loss)
I0607 11:41:49.166668  2187 sgd_solver.cpp:106] Iteration 53700, lr = 0.001
I0607 11:42:11.559267  2187 solver.cpp:228] Iteration 53800, loss = 0.00229124
I0607 11:42:11.559566  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00229123 (* 1 = 0.00229123 loss)
I0607 11:42:11.559608  2187 sgd_solver.cpp:106] Iteration 53800, lr = 0.001
I0607 11:42:33.841614  2187 solver.cpp:228] Iteration 53900, loss = 0.00206049
I0607 11:42:33.841708  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00206048 (* 1 = 0.00206048 loss)
I0607 11:42:33.841723  2187 sgd_solver.cpp:106] Iteration 53900, lr = 0.001
I0607 11:42:55.894359  2187 solver.cpp:337] Iteration 54000, Testing net (#0)
I0607 11:42:55.895000  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:42:57.471973  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9044
I0607 11:42:57.645761  2187 solver.cpp:228] Iteration 54000, loss = 0.00364709
I0607 11:42:57.645856  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00364708 (* 1 = 0.00364708 loss)
I0607 11:42:57.645875  2187 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0607 11:43:20.223870  2187 solver.cpp:228] Iteration 54100, loss = 0.00612418
I0607 11:43:20.223980  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00612417 (* 1 = 0.00612417 loss)
I0607 11:43:20.223995  2187 sgd_solver.cpp:106] Iteration 54100, lr = 0.001
I0607 11:43:42.873375  2187 solver.cpp:228] Iteration 54200, loss = 0.00289267
I0607 11:43:42.873687  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00289265 (* 1 = 0.00289265 loss)
I0607 11:43:42.873733  2187 sgd_solver.cpp:106] Iteration 54200, lr = 0.001
I0607 11:44:05.021325  2187 solver.cpp:228] Iteration 54300, loss = 0.00220952
I0607 11:44:05.021440  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00220951 (* 1 = 0.00220951 loss)
I0607 11:44:05.021456  2187 sgd_solver.cpp:106] Iteration 54300, lr = 0.001
I0607 11:44:27.413727  2187 solver.cpp:228] Iteration 54400, loss = 0.00300374
I0607 11:44:27.413949  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00300373 (* 1 = 0.00300373 loss)
I0607 11:44:27.413969  2187 sgd_solver.cpp:106] Iteration 54400, lr = 0.001
I0607 11:44:50.068277  2187 solver.cpp:228] Iteration 54500, loss = 0.00216357
I0607 11:44:50.068383  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00216356 (* 1 = 0.00216356 loss)
I0607 11:44:50.068399  2187 sgd_solver.cpp:106] Iteration 54500, lr = 0.001
I0607 11:45:12.668854  2187 solver.cpp:228] Iteration 54600, loss = 0.00209509
I0607 11:45:12.669128  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00209507 (* 1 = 0.00209507 loss)
I0607 11:45:12.669162  2187 sgd_solver.cpp:106] Iteration 54600, lr = 0.001
I0607 11:45:35.656673  2187 solver.cpp:228] Iteration 54700, loss = 0.00443539
I0607 11:45:35.656787  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00443537 (* 1 = 0.00443537 loss)
I0607 11:45:35.656805  2187 sgd_solver.cpp:106] Iteration 54700, lr = 0.001
I0607 11:45:58.464010  2187 solver.cpp:228] Iteration 54800, loss = 0.00325338
I0607 11:45:58.464210  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00325337 (* 1 = 0.00325337 loss)
I0607 11:45:58.464227  2187 sgd_solver.cpp:106] Iteration 54800, lr = 0.001
I0607 11:46:20.759567  2187 solver.cpp:228] Iteration 54900, loss = 0.00306655
I0607 11:46:20.759670  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00306653 (* 1 = 0.00306653 loss)
I0607 11:46:20.759692  2187 sgd_solver.cpp:106] Iteration 54900, lr = 0.001
I0607 11:46:42.789912  2187 solver.cpp:337] Iteration 55000, Testing net (#0)
I0607 11:46:42.790611  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:46:44.361007  2187 solver.cpp:404]     Test net output #0: accuracy = 0.903
I0607 11:46:44.536933  2187 solver.cpp:228] Iteration 55000, loss = 0.00303316
I0607 11:46:44.537020  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00303315 (* 1 = 0.00303315 loss)
I0607 11:46:44.537034  2187 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0607 11:47:07.015594  2187 solver.cpp:228] Iteration 55100, loss = 0.00270425
I0607 11:47:07.015692  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00270424 (* 1 = 0.00270424 loss)
I0607 11:47:07.015708  2187 sgd_solver.cpp:106] Iteration 55100, lr = 0.001
I0607 11:47:29.613154  2187 solver.cpp:228] Iteration 55200, loss = 0.00295002
I0607 11:47:29.613474  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00295001 (* 1 = 0.00295001 loss)
I0607 11:47:29.613517  2187 sgd_solver.cpp:106] Iteration 55200, lr = 0.001
I0607 11:47:52.053665  2187 solver.cpp:228] Iteration 55300, loss = 0.00280472
I0607 11:47:52.053768  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00280471 (* 1 = 0.00280471 loss)
I0607 11:47:52.053786  2187 sgd_solver.cpp:106] Iteration 55300, lr = 0.001
I0607 11:48:14.510246  2187 solver.cpp:228] Iteration 55400, loss = 0.00271708
I0607 11:48:14.510432  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00271706 (* 1 = 0.00271706 loss)
I0607 11:48:14.510459  2187 sgd_solver.cpp:106] Iteration 55400, lr = 0.001
I0607 11:48:37.021539  2187 solver.cpp:228] Iteration 55500, loss = 0.00224903
I0607 11:48:37.021652  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00224902 (* 1 = 0.00224902 loss)
I0607 11:48:37.021667  2187 sgd_solver.cpp:106] Iteration 55500, lr = 0.001
I0607 11:48:58.675297  2187 solver.cpp:228] Iteration 55600, loss = 0.00501519
I0607 11:48:58.675540  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00501518 (* 1 = 0.00501518 loss)
I0607 11:48:58.675577  2187 sgd_solver.cpp:106] Iteration 55600, lr = 0.001
I0607 11:49:19.824038  2187 solver.cpp:228] Iteration 55700, loss = 0.00212559
I0607 11:49:19.824194  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00212558 (* 1 = 0.00212558 loss)
I0607 11:49:19.824211  2187 sgd_solver.cpp:106] Iteration 55700, lr = 0.001
I0607 11:49:42.622406  2187 solver.cpp:228] Iteration 55800, loss = 0.00599742
I0607 11:49:42.622726  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00599741 (* 1 = 0.00599741 loss)
I0607 11:49:42.622794  2187 sgd_solver.cpp:106] Iteration 55800, lr = 0.001
I0607 11:50:05.374476  2187 solver.cpp:228] Iteration 55900, loss = 0.00332256
I0607 11:50:05.374583  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00332255 (* 1 = 0.00332255 loss)
I0607 11:50:05.374599  2187 sgd_solver.cpp:106] Iteration 55900, lr = 0.001
I0607 11:50:27.565073  2187 solver.cpp:337] Iteration 56000, Testing net (#0)
I0607 11:50:27.565608  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:50:29.130942  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9015
I0607 11:50:29.309772  2187 solver.cpp:228] Iteration 56000, loss = 0.00268707
I0607 11:50:29.309867  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00268706 (* 1 = 0.00268706 loss)
I0607 11:50:29.309888  2187 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I0607 11:50:51.636466  2187 solver.cpp:228] Iteration 56100, loss = 0.00328149
I0607 11:50:51.636564  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00328148 (* 1 = 0.00328148 loss)
I0607 11:50:51.636577  2187 sgd_solver.cpp:106] Iteration 56100, lr = 0.001
I0607 11:51:13.982844  2187 solver.cpp:228] Iteration 56200, loss = 0.00351389
I0607 11:51:13.983170  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00351387 (* 1 = 0.00351387 loss)
I0607 11:51:13.983225  2187 sgd_solver.cpp:106] Iteration 56200, lr = 0.001
I0607 11:51:36.353698  2187 solver.cpp:228] Iteration 56300, loss = 0.00165211
I0607 11:51:36.353801  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00165209 (* 1 = 0.00165209 loss)
I0607 11:51:36.353818  2187 sgd_solver.cpp:106] Iteration 56300, lr = 0.001
I0607 11:51:58.786725  2187 solver.cpp:228] Iteration 56400, loss = 0.00203985
I0607 11:51:58.786924  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00203984 (* 1 = 0.00203984 loss)
I0607 11:51:58.786941  2187 sgd_solver.cpp:106] Iteration 56400, lr = 0.001
I0607 11:52:21.366864  2187 solver.cpp:228] Iteration 56500, loss = 0.00281487
I0607 11:52:21.366960  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00281486 (* 1 = 0.00281486 loss)
I0607 11:52:21.366991  2187 sgd_solver.cpp:106] Iteration 56500, lr = 0.001
I0607 11:52:43.846331  2187 solver.cpp:228] Iteration 56600, loss = 0.00492689
I0607 11:52:43.846561  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00492688 (* 1 = 0.00492688 loss)
I0607 11:52:43.846583  2187 sgd_solver.cpp:106] Iteration 56600, lr = 0.001
I0607 11:53:06.322763  2187 solver.cpp:228] Iteration 56700, loss = 0.00283962
I0607 11:53:06.322885  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00283961 (* 1 = 0.00283961 loss)
I0607 11:53:06.322904  2187 sgd_solver.cpp:106] Iteration 56700, lr = 0.001
I0607 11:53:28.858412  2187 solver.cpp:228] Iteration 56800, loss = 0.00189096
I0607 11:53:28.858680  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00189095 (* 1 = 0.00189095 loss)
I0607 11:53:28.858724  2187 sgd_solver.cpp:106] Iteration 56800, lr = 0.001
I0607 11:53:51.384006  2187 solver.cpp:228] Iteration 56900, loss = 0.00258911
I0607 11:53:51.384120  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00258909 (* 1 = 0.00258909 loss)
I0607 11:53:51.384140  2187 sgd_solver.cpp:106] Iteration 56900, lr = 0.001
I0607 11:54:14.056385  2187 solver.cpp:337] Iteration 57000, Testing net (#0)
I0607 11:54:14.057075  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:54:15.646108  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9023
I0607 11:54:15.823968  2187 solver.cpp:228] Iteration 57000, loss = 0.00321157
I0607 11:54:15.824121  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00321156 (* 1 = 0.00321156 loss)
I0607 11:54:15.824156  2187 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0607 11:54:38.453945  2187 solver.cpp:228] Iteration 57100, loss = 0.00311965
I0607 11:54:38.454051  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00311964 (* 1 = 0.00311964 loss)
I0607 11:54:38.454069  2187 sgd_solver.cpp:106] Iteration 57100, lr = 0.001
I0607 11:55:00.945425  2187 solver.cpp:228] Iteration 57200, loss = 0.00232338
I0607 11:55:00.945719  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00232337 (* 1 = 0.00232337 loss)
I0607 11:55:00.945765  2187 sgd_solver.cpp:106] Iteration 57200, lr = 0.001
I0607 11:55:23.358773  2187 solver.cpp:228] Iteration 57300, loss = 0.00347483
I0607 11:55:23.358880  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00347482 (* 1 = 0.00347482 loss)
I0607 11:55:23.358896  2187 sgd_solver.cpp:106] Iteration 57300, lr = 0.001
I0607 11:55:43.768481  2187 solver.cpp:228] Iteration 57400, loss = 0.0020735
I0607 11:55:43.768743  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00207348 (* 1 = 0.00207348 loss)
I0607 11:55:43.768795  2187 sgd_solver.cpp:106] Iteration 57400, lr = 0.001
I0607 11:56:03.867102  2187 solver.cpp:228] Iteration 57500, loss = 0.00186614
I0607 11:56:03.867197  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00186613 (* 1 = 0.00186613 loss)
I0607 11:56:03.867213  2187 sgd_solver.cpp:106] Iteration 57500, lr = 0.001
I0607 11:56:26.265389  2187 solver.cpp:228] Iteration 57600, loss = 0.00360541
I0607 11:56:26.265604  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00360539 (* 1 = 0.00360539 loss)
I0607 11:56:26.265627  2187 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0607 11:56:48.853866  2187 solver.cpp:228] Iteration 57700, loss = 0.00291702
I0607 11:56:48.853974  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00291701 (* 1 = 0.00291701 loss)
I0607 11:56:48.853989  2187 sgd_solver.cpp:106] Iteration 57700, lr = 0.001
I0607 11:57:11.675966  2187 solver.cpp:228] Iteration 57800, loss = 0.00398027
I0607 11:57:11.676226  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00398026 (* 1 = 0.00398026 loss)
I0607 11:57:11.676265  2187 sgd_solver.cpp:106] Iteration 57800, lr = 0.001
I0607 11:57:35.000831  2187 solver.cpp:228] Iteration 57900, loss = 0.00232305
I0607 11:57:35.000988  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00232303 (* 1 = 0.00232303 loss)
I0607 11:57:35.001034  2187 sgd_solver.cpp:106] Iteration 57900, lr = 0.001
I0607 11:57:58.894886  2187 solver.cpp:337] Iteration 58000, Testing net (#0)
I0607 11:57:58.895412  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 11:58:00.593588  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8996
I0607 11:58:00.772341  2187 solver.cpp:228] Iteration 58000, loss = 0.00281608
I0607 11:58:00.772454  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00281607 (* 1 = 0.00281607 loss)
I0607 11:58:00.772478  2187 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I0607 11:58:23.908532  2187 solver.cpp:228] Iteration 58100, loss = 0.00291199
I0607 11:58:23.908660  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00291197 (* 1 = 0.00291197 loss)
I0607 11:58:23.908685  2187 sgd_solver.cpp:106] Iteration 58100, lr = 0.001
I0607 11:58:46.555181  2187 solver.cpp:228] Iteration 58200, loss = 0.00278347
I0607 11:58:46.555529  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00278346 (* 1 = 0.00278346 loss)
I0607 11:58:46.555586  2187 sgd_solver.cpp:106] Iteration 58200, lr = 0.001
I0607 11:59:09.073017  2187 solver.cpp:228] Iteration 58300, loss = 0.00432383
I0607 11:59:09.073169  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00432382 (* 1 = 0.00432382 loss)
I0607 11:59:09.073187  2187 sgd_solver.cpp:106] Iteration 58300, lr = 0.001
I0607 11:59:31.434164  2187 solver.cpp:228] Iteration 58400, loss = 0.00312726
I0607 11:59:31.434659  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00312725 (* 1 = 0.00312725 loss)
I0607 11:59:31.434772  2187 sgd_solver.cpp:106] Iteration 58400, lr = 0.001
I0607 11:59:54.070541  2187 solver.cpp:228] Iteration 58500, loss = 0.00455047
I0607 11:59:54.070631  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00455046 (* 1 = 0.00455046 loss)
I0607 11:59:54.070647  2187 sgd_solver.cpp:106] Iteration 58500, lr = 0.001
I0607 12:00:16.980633  2187 solver.cpp:228] Iteration 58600, loss = 0.00507398
I0607 12:00:16.980983  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00507397 (* 1 = 0.00507397 loss)
I0607 12:00:16.981022  2187 sgd_solver.cpp:106] Iteration 58600, lr = 0.001
I0607 12:00:40.557662  2187 solver.cpp:228] Iteration 58700, loss = 0.00468292
I0607 12:00:40.557813  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00468291 (* 1 = 0.00468291 loss)
I0607 12:00:40.557832  2187 sgd_solver.cpp:106] Iteration 58700, lr = 0.001
I0607 12:01:03.924146  2187 solver.cpp:228] Iteration 58800, loss = 0.00289916
I0607 12:01:03.924427  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00289914 (* 1 = 0.00289914 loss)
I0607 12:01:03.924448  2187 sgd_solver.cpp:106] Iteration 58800, lr = 0.001
I0607 12:01:25.270808  2187 solver.cpp:228] Iteration 58900, loss = 0.00336535
I0607 12:01:25.270910  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00336533 (* 1 = 0.00336533 loss)
I0607 12:01:25.270927  2187 sgd_solver.cpp:106] Iteration 58900, lr = 0.001
I0607 12:01:47.745576  2187 solver.cpp:337] Iteration 59000, Testing net (#0)
I0607 12:01:47.746318  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:01:49.352437  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8997
I0607 12:01:49.526509  2187 solver.cpp:228] Iteration 59000, loss = 0.00217116
I0607 12:01:49.526602  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00217115 (* 1 = 0.00217115 loss)
I0607 12:01:49.526618  2187 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I0607 12:02:12.162302  2187 solver.cpp:228] Iteration 59100, loss = 0.00280735
I0607 12:02:12.162415  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00280734 (* 1 = 0.00280734 loss)
I0607 12:02:12.162431  2187 sgd_solver.cpp:106] Iteration 59100, lr = 0.001
I0607 12:02:34.956385  2187 solver.cpp:228] Iteration 59200, loss = 0.0029478
I0607 12:02:34.956677  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00294779 (* 1 = 0.00294779 loss)
I0607 12:02:34.956717  2187 sgd_solver.cpp:106] Iteration 59200, lr = 0.001
I0607 12:02:57.591603  2187 solver.cpp:228] Iteration 59300, loss = 0.00256351
I0607 12:02:57.591707  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0025635 (* 1 = 0.0025635 loss)
I0607 12:02:57.591725  2187 sgd_solver.cpp:106] Iteration 59300, lr = 0.001
I0607 12:03:20.361090  2187 solver.cpp:228] Iteration 59400, loss = 0.00358242
I0607 12:03:20.361380  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00358241 (* 1 = 0.00358241 loss)
I0607 12:03:20.361426  2187 sgd_solver.cpp:106] Iteration 59400, lr = 0.001
I0607 12:03:43.432704  2187 solver.cpp:228] Iteration 59500, loss = 0.00279522
I0607 12:03:43.432870  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0027952 (* 1 = 0.0027952 loss)
I0607 12:03:43.432888  2187 sgd_solver.cpp:106] Iteration 59500, lr = 0.001
I0607 12:04:06.432989  2187 solver.cpp:228] Iteration 59600, loss = 0.00325861
I0607 12:04:06.433394  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0032586 (* 1 = 0.0032586 loss)
I0607 12:04:06.433436  2187 sgd_solver.cpp:106] Iteration 59600, lr = 0.001
I0607 12:04:29.634791  2187 solver.cpp:228] Iteration 59700, loss = 0.00309903
I0607 12:04:29.634953  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00309901 (* 1 = 0.00309901 loss)
I0607 12:04:29.634973  2187 sgd_solver.cpp:106] Iteration 59700, lr = 0.001
I0607 12:04:52.323623  2187 solver.cpp:228] Iteration 59800, loss = 0.00404488
I0607 12:04:52.323907  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00404486 (* 1 = 0.00404486 loss)
I0607 12:04:52.323950  2187 sgd_solver.cpp:106] Iteration 59800, lr = 0.001
I0607 12:05:14.862048  2187 solver.cpp:228] Iteration 59900, loss = 0.00177546
I0607 12:05:14.862160  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00177544 (* 1 = 0.00177544 loss)
I0607 12:05:14.862177  2187 sgd_solver.cpp:106] Iteration 59900, lr = 0.001
I0607 12:05:37.174690  2187 solver.cpp:454] Snapshotting to binary proto file snapshot/_iter_60000.caffemodel
I0607 12:05:37.187299  2187 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot/_iter_60000.solverstate
I0607 12:05:37.191834  2187 solver.cpp:337] Iteration 60000, Testing net (#0)
I0607 12:05:37.192145  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:05:38.767738  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9009
I0607 12:05:38.941050  2187 solver.cpp:228] Iteration 60000, loss = 0.00205267
I0607 12:05:38.941125  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00205265 (* 1 = 0.00205265 loss)
I0607 12:05:38.941141  2187 sgd_solver.cpp:106] Iteration 60000, lr = 0.0001
I0607 12:06:01.380892  2187 solver.cpp:228] Iteration 60100, loss = 0.00356849
I0607 12:06:01.381000  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00356847 (* 1 = 0.00356847 loss)
I0607 12:06:01.381022  2187 sgd_solver.cpp:106] Iteration 60100, lr = 0.0001
I0607 12:06:23.736964  2187 solver.cpp:228] Iteration 60200, loss = 0.00240417
I0607 12:06:23.737368  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00240416 (* 1 = 0.00240416 loss)
I0607 12:06:23.737427  2187 sgd_solver.cpp:106] Iteration 60200, lr = 0.0001
I0607 12:06:45.935528  2187 solver.cpp:228] Iteration 60300, loss = 0.00277944
I0607 12:06:45.935664  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00277943 (* 1 = 0.00277943 loss)
I0607 12:06:45.935684  2187 sgd_solver.cpp:106] Iteration 60300, lr = 0.0001
I0607 12:07:08.179920  2187 solver.cpp:228] Iteration 60400, loss = 0.00226397
I0607 12:07:08.180119  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00226396 (* 1 = 0.00226396 loss)
I0607 12:07:08.180136  2187 sgd_solver.cpp:106] Iteration 60400, lr = 0.0001
I0607 12:07:30.475251  2187 solver.cpp:228] Iteration 60500, loss = 0.00190951
I0607 12:07:30.475424  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00190949 (* 1 = 0.00190949 loss)
I0607 12:07:30.475445  2187 sgd_solver.cpp:106] Iteration 60500, lr = 0.0001
I0607 12:07:51.684967  2187 solver.cpp:228] Iteration 60600, loss = 0.00308011
I0607 12:07:51.685248  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0030801 (* 1 = 0.0030801 loss)
I0607 12:07:51.688480  2187 sgd_solver.cpp:106] Iteration 60600, lr = 0.0001
I0607 12:08:14.175868  2187 solver.cpp:228] Iteration 60700, loss = 0.00315331
I0607 12:08:14.175979  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0031533 (* 1 = 0.0031533 loss)
I0607 12:08:14.175998  2187 sgd_solver.cpp:106] Iteration 60700, lr = 0.0001
I0607 12:08:36.485172  2187 solver.cpp:228] Iteration 60800, loss = 0.00434843
I0607 12:08:36.485479  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00434842 (* 1 = 0.00434842 loss)
I0607 12:08:36.485525  2187 sgd_solver.cpp:106] Iteration 60800, lr = 0.0001
I0607 12:08:58.813632  2187 solver.cpp:228] Iteration 60900, loss = 0.00298424
I0607 12:08:58.813761  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00298423 (* 1 = 0.00298423 loss)
I0607 12:08:58.813783  2187 sgd_solver.cpp:106] Iteration 60900, lr = 0.0001
I0607 12:09:21.230134  2187 solver.cpp:337] Iteration 61000, Testing net (#0)
I0607 12:09:21.230712  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:09:22.841358  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9003
I0607 12:09:23.022655  2187 solver.cpp:228] Iteration 61000, loss = 0.00291292
I0607 12:09:23.022756  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0029129 (* 1 = 0.0029129 loss)
I0607 12:09:23.022778  2187 sgd_solver.cpp:106] Iteration 61000, lr = 0.0001
I0607 12:09:45.475832  2187 solver.cpp:228] Iteration 61100, loss = 0.00219047
I0607 12:09:45.475961  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00219045 (* 1 = 0.00219045 loss)
I0607 12:09:45.475985  2187 sgd_solver.cpp:106] Iteration 61100, lr = 0.0001
I0607 12:10:07.848327  2187 solver.cpp:228] Iteration 61200, loss = 0.00420868
I0607 12:10:07.848724  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00420866 (* 1 = 0.00420866 loss)
I0607 12:10:07.848778  2187 sgd_solver.cpp:106] Iteration 61200, lr = 0.0001
I0607 12:10:30.299751  2187 solver.cpp:228] Iteration 61300, loss = 0.00212693
I0607 12:10:30.299854  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00212692 (* 1 = 0.00212692 loss)
I0607 12:10:30.299868  2187 sgd_solver.cpp:106] Iteration 61300, lr = 0.0001
I0607 12:10:52.769534  2187 solver.cpp:228] Iteration 61400, loss = 0.0024044
I0607 12:10:52.769662  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00240439 (* 1 = 0.00240439 loss)
I0607 12:10:52.769681  2187 sgd_solver.cpp:106] Iteration 61400, lr = 0.0001
I0607 12:11:15.544561  2187 solver.cpp:228] Iteration 61500, loss = 0.00183377
I0607 12:11:15.544682  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00183376 (* 1 = 0.00183376 loss)
I0607 12:11:15.544699  2187 sgd_solver.cpp:106] Iteration 61500, lr = 0.0001
I0607 12:11:39.510313  2187 solver.cpp:228] Iteration 61600, loss = 0.00193108
I0607 12:11:39.510727  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00193107 (* 1 = 0.00193107 loss)
I0607 12:11:39.510787  2187 sgd_solver.cpp:106] Iteration 61600, lr = 0.0001
I0607 12:12:03.549768  2187 solver.cpp:228] Iteration 61700, loss = 0.00148128
I0607 12:12:03.549873  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00148127 (* 1 = 0.00148127 loss)
I0607 12:12:03.549890  2187 sgd_solver.cpp:106] Iteration 61700, lr = 0.0001
I0607 12:12:26.992238  2187 solver.cpp:228] Iteration 61800, loss = 0.00340172
I0607 12:12:26.992492  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00340171 (* 1 = 0.00340171 loss)
I0607 12:12:26.992518  2187 sgd_solver.cpp:106] Iteration 61800, lr = 0.0001
I0607 12:12:50.521806  2187 solver.cpp:228] Iteration 61900, loss = 0.0016743
I0607 12:12:50.521909  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00167429 (* 1 = 0.00167429 loss)
I0607 12:12:50.521944  2187 sgd_solver.cpp:106] Iteration 61900, lr = 0.0001
I0607 12:13:12.168861  2187 solver.cpp:337] Iteration 62000, Testing net (#0)
I0607 12:13:12.169518  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:13:13.748683  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9028
I0607 12:13:13.923604  2187 solver.cpp:228] Iteration 62000, loss = 0.00187502
I0607 12:13:13.923704  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00187501 (* 1 = 0.00187501 loss)
I0607 12:13:13.923733  2187 sgd_solver.cpp:106] Iteration 62000, lr = 0.0001
I0607 12:13:36.287293  2187 solver.cpp:228] Iteration 62100, loss = 0.00186953
I0607 12:13:36.287398  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00186952 (* 1 = 0.00186952 loss)
I0607 12:13:36.287415  2187 sgd_solver.cpp:106] Iteration 62100, lr = 0.0001
I0607 12:13:58.627763  2187 solver.cpp:228] Iteration 62200, loss = 0.00332798
I0607 12:13:58.628077  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00332797 (* 1 = 0.00332797 loss)
I0607 12:13:58.628125  2187 sgd_solver.cpp:106] Iteration 62200, lr = 0.0001
I0607 12:14:21.416995  2187 solver.cpp:228] Iteration 62300, loss = 0.00189508
I0607 12:14:21.417096  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00189507 (* 1 = 0.00189507 loss)
I0607 12:14:21.417112  2187 sgd_solver.cpp:106] Iteration 62300, lr = 0.0001
I0607 12:14:44.628684  2187 solver.cpp:228] Iteration 62400, loss = 0.00448474
I0607 12:14:44.628991  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00448473 (* 1 = 0.00448473 loss)
I0607 12:14:44.629043  2187 sgd_solver.cpp:106] Iteration 62400, lr = 0.0001
I0607 12:15:07.980525  2187 solver.cpp:228] Iteration 62500, loss = 0.00203074
I0607 12:15:07.980633  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00203073 (* 1 = 0.00203073 loss)
I0607 12:15:07.980650  2187 sgd_solver.cpp:106] Iteration 62500, lr = 0.0001
I0607 12:15:31.221802  2187 solver.cpp:228] Iteration 62600, loss = 0.00442186
I0607 12:15:31.222154  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00442185 (* 1 = 0.00442185 loss)
I0607 12:15:31.222190  2187 sgd_solver.cpp:106] Iteration 62600, lr = 0.0001
I0607 12:15:53.644867  2187 solver.cpp:228] Iteration 62700, loss = 0.00235407
I0607 12:15:53.644973  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00235406 (* 1 = 0.00235406 loss)
I0607 12:15:53.644989  2187 sgd_solver.cpp:106] Iteration 62700, lr = 0.0001
I0607 12:16:15.980515  2187 solver.cpp:228] Iteration 62800, loss = 0.00392536
I0607 12:16:15.980723  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00392535 (* 1 = 0.00392535 loss)
I0607 12:16:15.980746  2187 sgd_solver.cpp:106] Iteration 62800, lr = 0.0001
I0607 12:16:38.327879  2187 solver.cpp:228] Iteration 62900, loss = 0.00298239
I0607 12:16:38.327982  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00298238 (* 1 = 0.00298238 loss)
I0607 12:16:38.328001  2187 sgd_solver.cpp:106] Iteration 62900, lr = 0.0001
I0607 12:17:00.523308  2187 solver.cpp:337] Iteration 63000, Testing net (#0)
I0607 12:17:00.523972  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:17:02.096520  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8998
I0607 12:17:02.272565  2187 solver.cpp:228] Iteration 63000, loss = 0.00242391
I0607 12:17:02.272662  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0024239 (* 1 = 0.0024239 loss)
I0607 12:17:02.272685  2187 sgd_solver.cpp:106] Iteration 63000, lr = 0.0001
I0607 12:17:24.583477  2187 solver.cpp:228] Iteration 63100, loss = 0.00608344
I0607 12:17:24.583585  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00608343 (* 1 = 0.00608343 loss)
I0607 12:17:24.583602  2187 sgd_solver.cpp:106] Iteration 63100, lr = 0.0001
I0607 12:17:47.008312  2187 solver.cpp:228] Iteration 63200, loss = 0.0022963
I0607 12:17:47.008596  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00229629 (* 1 = 0.00229629 loss)
I0607 12:17:47.008636  2187 sgd_solver.cpp:106] Iteration 63200, lr = 0.0001
I0607 12:18:09.407382  2187 solver.cpp:228] Iteration 63300, loss = 0.00282072
I0607 12:18:09.407517  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00282071 (* 1 = 0.00282071 loss)
I0607 12:18:09.407541  2187 sgd_solver.cpp:106] Iteration 63300, lr = 0.0001
I0607 12:18:31.931104  2187 solver.cpp:228] Iteration 63400, loss = 0.00181795
I0607 12:18:31.931437  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00181794 (* 1 = 0.00181794 loss)
I0607 12:18:31.931485  2187 sgd_solver.cpp:106] Iteration 63400, lr = 0.0001
I0607 12:18:54.352715  2187 solver.cpp:228] Iteration 63500, loss = 0.00607521
I0607 12:18:54.352854  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.0060752 (* 1 = 0.0060752 loss)
I0607 12:18:54.352874  2187 sgd_solver.cpp:106] Iteration 63500, lr = 0.0001
I0607 12:19:17.439462  2187 solver.cpp:228] Iteration 63600, loss = 0.00379063
I0607 12:19:17.439589  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00379062 (* 1 = 0.00379062 loss)
I0607 12:19:17.439606  2187 sgd_solver.cpp:106] Iteration 63600, lr = 0.0001
I0607 12:19:37.871995  2187 solver.cpp:228] Iteration 63700, loss = 0.00217946
I0607 12:19:37.872086  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00217945 (* 1 = 0.00217945 loss)
I0607 12:19:37.872102  2187 sgd_solver.cpp:106] Iteration 63700, lr = 0.0001
I0607 12:20:01.045717  2187 solver.cpp:228] Iteration 63800, loss = 0.00182767
I0607 12:20:01.045939  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00182766 (* 1 = 0.00182766 loss)
I0607 12:20:01.045959  2187 sgd_solver.cpp:106] Iteration 63800, lr = 0.0001
I0607 12:20:23.795281  2187 solver.cpp:228] Iteration 63900, loss = 0.00312948
I0607 12:20:23.795380  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00312946 (* 1 = 0.00312946 loss)
I0607 12:20:23.795397  2187 sgd_solver.cpp:106] Iteration 63900, lr = 0.0001
I0607 12:20:46.035740  2187 solver.cpp:337] Iteration 64000, Testing net (#0)
I0607 12:20:46.036144  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:20:47.611382  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9018
I0607 12:20:47.789744  2187 solver.cpp:228] Iteration 64000, loss = 0.00500048
I0607 12:20:47.789829  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00500047 (* 1 = 0.00500047 loss)
I0607 12:20:47.789849  2187 sgd_solver.cpp:106] Iteration 64000, lr = 0.0001
I0607 12:21:10.038558  2187 solver.cpp:228] Iteration 64100, loss = 0.00221909
I0607 12:21:10.038666  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00221907 (* 1 = 0.00221907 loss)
I0607 12:21:10.038686  2187 sgd_solver.cpp:106] Iteration 64100, lr = 0.0001
I0607 12:21:32.300653  2187 solver.cpp:228] Iteration 64200, loss = 0.0024342
I0607 12:21:32.300846  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00243419 (* 1 = 0.00243419 loss)
I0607 12:21:32.300865  2187 sgd_solver.cpp:106] Iteration 64200, lr = 0.0001
I0607 12:21:54.745811  2187 solver.cpp:228] Iteration 64300, loss = 0.00293255
I0607 12:21:54.745923  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00293254 (* 1 = 0.00293254 loss)
I0607 12:21:54.745962  2187 sgd_solver.cpp:106] Iteration 64300, lr = 0.0001
I0607 12:22:17.463819  2187 solver.cpp:228] Iteration 64400, loss = 0.00306288
I0607 12:22:17.464179  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00306287 (* 1 = 0.00306287 loss)
I0607 12:22:17.464223  2187 sgd_solver.cpp:106] Iteration 64400, lr = 0.0001
I0607 12:22:40.194535  2187 solver.cpp:228] Iteration 64500, loss = 0.00292815
I0607 12:22:40.194694  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00292814 (* 1 = 0.00292814 loss)
I0607 12:22:40.194715  2187 sgd_solver.cpp:106] Iteration 64500, lr = 0.0001
I0607 12:23:02.696739  2187 solver.cpp:228] Iteration 64600, loss = 0.00485654
I0607 12:23:02.697011  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00485653 (* 1 = 0.00485653 loss)
I0607 12:23:02.697058  2187 sgd_solver.cpp:106] Iteration 64600, lr = 0.0001
I0607 12:23:25.499379  2187 solver.cpp:228] Iteration 64700, loss = 0.00296905
I0607 12:23:25.499490  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00296904 (* 1 = 0.00296904 loss)
I0607 12:23:25.499507  2187 sgd_solver.cpp:106] Iteration 64700, lr = 0.0001
I0607 12:23:48.644814  2187 solver.cpp:228] Iteration 64800, loss = 0.00392248
I0607 12:23:48.645076  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00392247 (* 1 = 0.00392247 loss)
I0607 12:23:48.645094  2187 sgd_solver.cpp:106] Iteration 64800, lr = 0.0001
I0607 12:24:11.891103  2187 solver.cpp:228] Iteration 64900, loss = 0.00338925
I0607 12:24:11.891229  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00338924 (* 1 = 0.00338924 loss)
I0607 12:24:11.891247  2187 sgd_solver.cpp:106] Iteration 64900, lr = 0.0001
I0607 12:24:34.152230  2187 solver.cpp:337] Iteration 65000, Testing net (#0)
I0607 12:24:34.152770  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:24:35.737977  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9038
I0607 12:24:35.907747  2187 solver.cpp:228] Iteration 65000, loss = 0.0018614
I0607 12:24:35.907884  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00186139 (* 1 = 0.00186139 loss)
I0607 12:24:35.907907  2187 sgd_solver.cpp:106] Iteration 65000, lr = 0.0001
I0607 12:24:57.829206  2187 solver.cpp:228] Iteration 65100, loss = 0.00283493
I0607 12:24:57.829310  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00283492 (* 1 = 0.00283492 loss)
I0607 12:24:57.829326  2187 sgd_solver.cpp:106] Iteration 65100, lr = 0.0001
I0607 12:25:20.193351  2187 solver.cpp:228] Iteration 65200, loss = 0.00305618
I0607 12:25:20.193665  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00305617 (* 1 = 0.00305617 loss)
I0607 12:25:20.193711  2187 sgd_solver.cpp:106] Iteration 65200, lr = 0.0001
I0607 12:25:42.673589  2187 solver.cpp:228] Iteration 65300, loss = 0.00348464
I0607 12:25:42.673707  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00348463 (* 1 = 0.00348463 loss)
I0607 12:25:42.673727  2187 sgd_solver.cpp:106] Iteration 65300, lr = 0.0001
I0607 12:26:05.369199  2187 solver.cpp:228] Iteration 65400, loss = 0.00272193
I0607 12:26:05.369518  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00272192 (* 1 = 0.00272192 loss)
I0607 12:26:05.369554  2187 sgd_solver.cpp:106] Iteration 65400, lr = 0.0001
I0607 12:26:28.065559  2187 solver.cpp:228] Iteration 65500, loss = 0.00263025
I0607 12:26:28.065655  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00263024 (* 1 = 0.00263024 loss)
I0607 12:26:28.065672  2187 sgd_solver.cpp:106] Iteration 65500, lr = 0.0001
I0607 12:26:50.693791  2187 solver.cpp:228] Iteration 65600, loss = 0.00322287
I0607 12:26:50.694118  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00322286 (* 1 = 0.00322286 loss)
I0607 12:26:50.694162  2187 sgd_solver.cpp:106] Iteration 65600, lr = 0.0001
I0607 12:27:13.324072  2187 solver.cpp:228] Iteration 65700, loss = 0.00513187
I0607 12:27:13.324174  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00513186 (* 1 = 0.00513186 loss)
I0607 12:27:13.324201  2187 sgd_solver.cpp:106] Iteration 65700, lr = 0.0001
I0607 12:27:35.782821  2187 solver.cpp:228] Iteration 65800, loss = 0.0018349
I0607 12:27:35.783193  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00183489 (* 1 = 0.00183489 loss)
I0607 12:27:35.783238  2187 sgd_solver.cpp:106] Iteration 65800, lr = 0.0001
I0607 12:27:58.328866  2187 solver.cpp:228] Iteration 65900, loss = 0.00227129
I0607 12:27:58.328966  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00227128 (* 1 = 0.00227128 loss)
I0607 12:27:58.328985  2187 sgd_solver.cpp:106] Iteration 65900, lr = 0.0001
I0607 12:28:20.419886  2187 solver.cpp:337] Iteration 66000, Testing net (#0)
I0607 12:28:20.420534  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:28:21.988332  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9002
I0607 12:28:22.164639  2187 solver.cpp:228] Iteration 66000, loss = 0.002041
I0607 12:28:22.164773  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00204099 (* 1 = 0.00204099 loss)
I0607 12:28:22.164799  2187 sgd_solver.cpp:106] Iteration 66000, lr = 0.0001
I0607 12:28:44.434514  2187 solver.cpp:228] Iteration 66100, loss = 0.00318207
I0607 12:28:44.434617  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00318206 (* 1 = 0.00318206 loss)
I0607 12:28:44.434633  2187 sgd_solver.cpp:106] Iteration 66100, lr = 0.0001
I0607 12:29:06.777731  2187 solver.cpp:228] Iteration 66200, loss = 0.00225919
I0607 12:29:06.777942  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00225918 (* 1 = 0.00225918 loss)
I0607 12:29:06.777963  2187 sgd_solver.cpp:106] Iteration 66200, lr = 0.0001
I0607 12:29:29.032465  2187 solver.cpp:228] Iteration 66300, loss = 0.00291688
I0607 12:29:29.032572  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00291687 (* 1 = 0.00291687 loss)
I0607 12:29:29.032588  2187 sgd_solver.cpp:106] Iteration 66300, lr = 0.0001
I0607 12:29:51.595930  2187 solver.cpp:228] Iteration 66400, loss = 0.00198966
I0607 12:29:51.596303  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00198965 (* 1 = 0.00198965 loss)
I0607 12:29:51.596348  2187 sgd_solver.cpp:106] Iteration 66400, lr = 0.0001
I0607 12:30:14.689076  2187 solver.cpp:228] Iteration 66500, loss = 0.00241055
I0607 12:30:14.689213  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00241054 (* 1 = 0.00241054 loss)
I0607 12:30:14.689230  2187 sgd_solver.cpp:106] Iteration 66500, lr = 0.0001
I0607 12:30:38.537005  2187 solver.cpp:228] Iteration 66600, loss = 0.00345956
I0607 12:30:38.537322  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00345955 (* 1 = 0.00345955 loss)
I0607 12:30:38.537387  2187 sgd_solver.cpp:106] Iteration 66600, lr = 0.0001
I0607 12:31:02.201645  2187 solver.cpp:228] Iteration 66700, loss = 0.00307008
I0607 12:31:02.201815  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00307007 (* 1 = 0.00307007 loss)
I0607 12:31:02.201846  2187 sgd_solver.cpp:106] Iteration 66700, lr = 0.0001
I0607 12:31:23.132846  2187 solver.cpp:228] Iteration 66800, loss = 0.00369528
I0607 12:31:23.133164  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00369527 (* 1 = 0.00369527 loss)
I0607 12:31:23.136476  2187 sgd_solver.cpp:106] Iteration 66800, lr = 0.0001
I0607 12:31:45.089350  2187 solver.cpp:228] Iteration 66900, loss = 0.00608243
I0607 12:31:45.089452  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00608242 (* 1 = 0.00608242 loss)
I0607 12:31:45.089488  2187 sgd_solver.cpp:106] Iteration 66900, lr = 0.0001
I0607 12:32:07.587245  2187 solver.cpp:337] Iteration 67000, Testing net (#0)
I0607 12:32:07.587945  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:32:09.160446  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9026
I0607 12:32:09.338719  2187 solver.cpp:228] Iteration 67000, loss = 0.00322615
I0607 12:32:09.338806  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00322614 (* 1 = 0.00322614 loss)
I0607 12:32:09.338838  2187 sgd_solver.cpp:106] Iteration 67000, lr = 0.0001
I0607 12:32:31.847781  2187 solver.cpp:228] Iteration 67100, loss = 0.00385049
I0607 12:32:31.847885  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00385048 (* 1 = 0.00385048 loss)
I0607 12:32:31.847904  2187 sgd_solver.cpp:106] Iteration 67100, lr = 0.0001
I0607 12:32:54.415887  2187 solver.cpp:228] Iteration 67200, loss = 0.00194999
I0607 12:32:54.416283  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00194998 (* 1 = 0.00194998 loss)
I0607 12:32:54.416321  2187 sgd_solver.cpp:106] Iteration 67200, lr = 0.0001
I0607 12:33:17.134042  2187 solver.cpp:228] Iteration 67300, loss = 0.00483026
I0607 12:33:17.134138  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00483025 (* 1 = 0.00483025 loss)
I0607 12:33:17.134155  2187 sgd_solver.cpp:106] Iteration 67300, lr = 0.0001
I0607 12:33:39.452909  2187 solver.cpp:228] Iteration 67400, loss = 0.00290482
I0607 12:33:39.453119  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00290481 (* 1 = 0.00290481 loss)
I0607 12:33:39.453137  2187 sgd_solver.cpp:106] Iteration 67400, lr = 0.0001
I0607 12:34:01.864948  2187 solver.cpp:228] Iteration 67500, loss = 0.00378818
I0607 12:34:01.865072  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00378817 (* 1 = 0.00378817 loss)
I0607 12:34:01.865092  2187 sgd_solver.cpp:106] Iteration 67500, lr = 0.0001
I0607 12:34:24.154834  2187 solver.cpp:228] Iteration 67600, loss = 0.00384206
I0607 12:34:24.155117  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00384205 (* 1 = 0.00384205 loss)
I0607 12:34:24.155156  2187 sgd_solver.cpp:106] Iteration 67600, lr = 0.0001
I0607 12:34:46.416049  2187 solver.cpp:228] Iteration 67700, loss = 0.00224816
I0607 12:34:46.416152  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00224815 (* 1 = 0.00224815 loss)
I0607 12:34:46.416168  2187 sgd_solver.cpp:106] Iteration 67700, lr = 0.0001
I0607 12:35:08.756639  2187 solver.cpp:228] Iteration 67800, loss = 0.00214788
I0607 12:35:08.756928  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00214787 (* 1 = 0.00214787 loss)
I0607 12:35:08.756988  2187 sgd_solver.cpp:106] Iteration 67800, lr = 0.0001
I0607 12:35:31.032806  2187 solver.cpp:228] Iteration 67900, loss = 0.00252579
I0607 12:35:31.032909  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00252578 (* 1 = 0.00252578 loss)
I0607 12:35:31.032927  2187 sgd_solver.cpp:106] Iteration 67900, lr = 0.0001
I0607 12:35:53.477648  2187 solver.cpp:337] Iteration 68000, Testing net (#0)
I0607 12:35:53.478294  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:35:55.062894  2187 solver.cpp:404]     Test net output #0: accuracy = 0.901
I0607 12:35:55.241719  2187 solver.cpp:228] Iteration 68000, loss = 0.00439235
I0607 12:35:55.241808  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00439234 (* 1 = 0.00439234 loss)
I0607 12:35:55.241832  2187 sgd_solver.cpp:106] Iteration 68000, lr = 0.0001
I0607 12:36:18.198194  2187 solver.cpp:228] Iteration 68100, loss = 0.00353978
I0607 12:36:18.198357  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00353977 (* 1 = 0.00353977 loss)
I0607 12:36:18.198403  2187 sgd_solver.cpp:106] Iteration 68100, lr = 0.0001
I0607 12:36:40.753923  2187 solver.cpp:228] Iteration 68200, loss = 0.00311675
I0607 12:36:40.754083  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00311674 (* 1 = 0.00311674 loss)
I0607 12:36:40.754101  2187 sgd_solver.cpp:106] Iteration 68200, lr = 0.0001
I0607 12:37:01.623184  2187 solver.cpp:228] Iteration 68300, loss = 0.00270147
I0607 12:37:01.623288  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00270146 (* 1 = 0.00270146 loss)
I0607 12:37:01.623308  2187 sgd_solver.cpp:106] Iteration 68300, lr = 0.0001
I0607 12:37:25.052307  2187 solver.cpp:228] Iteration 68400, loss = 0.00307208
I0607 12:37:25.052556  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00307208 (* 1 = 0.00307208 loss)
I0607 12:37:25.052574  2187 sgd_solver.cpp:106] Iteration 68400, lr = 0.0001
I0607 12:37:48.673699  2187 solver.cpp:228] Iteration 68500, loss = 0.0021016
I0607 12:37:48.673791  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00210159 (* 1 = 0.00210159 loss)
I0607 12:37:48.673807  2187 sgd_solver.cpp:106] Iteration 68500, lr = 0.0001
I0607 12:38:10.985313  2187 solver.cpp:228] Iteration 68600, loss = 0.00241398
I0607 12:38:10.985642  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00241397 (* 1 = 0.00241397 loss)
I0607 12:38:10.985678  2187 sgd_solver.cpp:106] Iteration 68600, lr = 0.0001
I0607 12:38:33.246001  2187 solver.cpp:228] Iteration 68700, loss = 0.00296348
I0607 12:38:33.246101  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00296348 (* 1 = 0.00296348 loss)
I0607 12:38:33.246117  2187 sgd_solver.cpp:106] Iteration 68700, lr = 0.0001
I0607 12:38:55.748106  2187 solver.cpp:228] Iteration 68800, loss = 0.0026521
I0607 12:38:55.748569  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00265209 (* 1 = 0.00265209 loss)
I0607 12:38:55.748687  2187 sgd_solver.cpp:106] Iteration 68800, lr = 0.0001
I0607 12:39:18.615066  2187 solver.cpp:228] Iteration 68900, loss = 0.00496056
I0607 12:39:18.615169  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00496055 (* 1 = 0.00496055 loss)
I0607 12:39:18.615186  2187 sgd_solver.cpp:106] Iteration 68900, lr = 0.0001
I0607 12:39:41.402345  2187 solver.cpp:337] Iteration 69000, Testing net (#0)
I0607 12:39:41.402967  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:39:43.123234  2187 solver.cpp:404]     Test net output #0: accuracy = 0.8988
I0607 12:39:43.309175  2187 solver.cpp:228] Iteration 69000, loss = 0.00336065
I0607 12:39:43.309332  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00336064 (* 1 = 0.00336064 loss)
I0607 12:39:43.309370  2187 sgd_solver.cpp:106] Iteration 69000, lr = 0.0001
I0607 12:40:06.201395  2187 solver.cpp:228] Iteration 69100, loss = 0.00300418
I0607 12:40:06.201531  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00300417 (* 1 = 0.00300417 loss)
I0607 12:40:06.201550  2187 sgd_solver.cpp:106] Iteration 69100, lr = 0.0001
I0607 12:40:29.818150  2187 solver.cpp:228] Iteration 69200, loss = 0.00270385
I0607 12:40:29.818483  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00270384 (* 1 = 0.00270384 loss)
I0607 12:40:29.818521  2187 sgd_solver.cpp:106] Iteration 69200, lr = 0.0001
I0607 12:40:53.318300  2187 solver.cpp:228] Iteration 69300, loss = 0.00288034
I0607 12:40:53.318426  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00288033 (* 1 = 0.00288033 loss)
I0607 12:40:53.318452  2187 sgd_solver.cpp:106] Iteration 69300, lr = 0.0001
I0607 12:41:15.873992  2187 solver.cpp:228] Iteration 69400, loss = 0.00230895
I0607 12:41:15.875725  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00230894 (* 1 = 0.00230894 loss)
I0607 12:41:15.875766  2187 sgd_solver.cpp:106] Iteration 69400, lr = 0.0001
I0607 12:41:38.563877  2187 solver.cpp:228] Iteration 69500, loss = 0.00281705
I0607 12:41:38.563974  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00281704 (* 1 = 0.00281704 loss)
I0607 12:41:38.563992  2187 sgd_solver.cpp:106] Iteration 69500, lr = 0.0001
I0607 12:42:00.982589  2187 solver.cpp:228] Iteration 69600, loss = 0.00246167
I0607 12:42:00.982816  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00246166 (* 1 = 0.00246166 loss)
I0607 12:42:00.982836  2187 sgd_solver.cpp:106] Iteration 69600, lr = 0.0001
I0607 12:42:23.359125  2187 solver.cpp:228] Iteration 69700, loss = 0.00135752
I0607 12:42:23.359235  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00135751 (* 1 = 0.00135751 loss)
I0607 12:42:23.359252  2187 sgd_solver.cpp:106] Iteration 69700, lr = 0.0001
I0607 12:42:46.025717  2187 solver.cpp:228] Iteration 69800, loss = 0.00853488
I0607 12:42:46.026092  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00853487 (* 1 = 0.00853487 loss)
I0607 12:42:46.026142  2187 sgd_solver.cpp:106] Iteration 69800, lr = 0.0001
I0607 12:43:08.677623  2187 solver.cpp:228] Iteration 69900, loss = 0.0022316
I0607 12:43:08.677741  2187 solver.cpp:244]     Train net output #0: SoftmaxWithLoss = 0.00223159 (* 1 = 0.00223159 loss)
I0607 12:43:08.677758  2187 sgd_solver.cpp:106] Iteration 69900, lr = 0.0001
I0607 12:43:29.914784  2187 solver.cpp:454] Snapshotting to binary proto file snapshot/_iter_70000.caffemodel
I0607 12:43:29.939180  2187 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot/_iter_70000.solverstate
I0607 12:43:29.976418  2187 solver.cpp:317] Iteration 70000, loss = 0.00276204
I0607 12:43:29.976492  2187 solver.cpp:337] Iteration 70000, Testing net (#0)
I0607 12:43:29.977185  2187 net.cpp:684] Ignoring source layer SoftmaxWithLoss
I0607 12:43:31.408521  2187 solver.cpp:404]     Test net output #0: accuracy = 0.9016
I0607 12:43:31.408614  2187 solver.cpp:322] Optimization Done.
I0607 12:43:31.408632  2187 caffe.cpp:222] Optimization Done.
